thread_ts,ts,user,text,reactions,real_name
,1600949843.000600,UTTGJQS6M,"*#projects — канал для обсуждения проектов.*

В этом канале помогает работать преподаватель. Здесь можно задавать вопросы, возникшие по ходу работы над проектом; предполагаем, что они будут относиться в большей степени к логике, структуре, формулировкам, выводам, а также — к ревью.

Если вы хотите задать вопрос в канале projects, *коротко назовите свой тред*, обозначив сферу вопроса и *тегните нашего преподавателя по проектам.*

Например так:
```Вопрос о прорисовке boxplot на одном графике```
А уже *внутри треда задайте свой вопрос,* опишите способы, которые уже использовали, приложите скриншоты, коды и другие подробности.

_Также вы можете ставить реакцию-галочку, если ваш вопрос в треде решён_ :heavy_check_mark:

Соблюдая такие правила, вы проявляете уважение к другим пользователям, так как не всем удобно пролистывать длинные сообщения, чтобы найти тот самый нужный тред.

&gt; А ещё так мы спасём мир от внезапных спойлеров  :nyancat:

Немного жести:bangbang: *Неправильно оформленные треды подлежат удалению* :bangbang:

Когда вы задаёте вопросы здесь, это помогает в том числе и вашим одногруппникам.
Если у вас возникла трудность с заданием — проверьте переписку в треде, возможно, кто-то уже сталкивался с этой проблемой, и в чате есть полезные советы по её решению.
Удобно: не придётся ждать, когда придёт ответ:)",,Маргарита Минеева
,1601441444.024400,U0185Q2MK19,"Всем привет!

Меня зовут Олег и я буду помогать вам в решении вопросов с проектами :slightly_smiling_face:

Немного обо мне:
*Профессиональное:*
За последние 5 лет занимал управленческие должности в научно-производственных организациях космической отрасли, занимался IT-аудитом в банковской сфере. Везде применял инструменты data analysis. data science и process mining для улучшения процессов бизнеса :signal_strength:
Примерно столько же занимаюсь преподаванием различных IT-дисциплин – от Python до SQL :male-student:

*Хобби*:
Совмещаю приятное с полезным в увлечениях инвестициями :moneybag:и только приятное – настольными играми :game_die:

Жду от вас энтузиазма, упорства и взаимопомощи, всем добра :v:","[{'name': 'wave', 'users': ['U01C12GKE1E', 'U01BB72RSH0', 'U01AWENRANB', 'U01BB74HXGA', 'U01BBD8NUCT', 'U01BB72TAHG', 'U01B4EXCR7G', 'U019HNXQEA1', 'U01B84D31FF', 'U01BPRKQP9P', 'U01BB71BRD0', 'U01C12DPASC', 'U01BB72MR6E', 'U01C12DK324', 'U01C12H8HJL', 'U01C12JD9TJ'], 'count': 16}, {'name': 'drum-drumroll', 'users': ['U01BBD8R6N7'], 'count': 1}, {'name': 'grin', 'users': ['U01BB74BJ9G'], 'count': 1}, {'name': 'v', 'users': ['U01BBD8HKR9', 'U01BBD8GB7D', 'U01BBD8JS75', 'U01BBD8EYR1', 'U01C12EF41E', 'U019M1YCHKM', 'U01BHCPN8F6'], 'count': 7}, {'name': 'heart_eyes_cat', 'users': ['U01BB72P2HG'], 'count': 1}, {'name': 'happy-cat', 'users': ['U01BBD8L1DZ', 'U01BB72QDH8'], 'count': 2}]",Олег Булыгин
1601447838.026400,1601447838.026400,U019HNXQEA1,Продолжение работы над проектом,,Жуган Артём
1601447838.026400,1601447980.026600,U019HNXQEA1,"Как только нажимаю кнопку 'вперёд', сразу перехожу к заключению, а не к проекту.
Как продолжить делать проект?",,Жуган Артём
1601447838.026400,1601448818.027000,U01BBD8JS75,"<@U019HNXQEA1> слева в списке под звездочкой Проектная работа, выбираешь ее, потом нажимаешь Перейти к заданию",,Алексей Глазов
1601447838.026400,1601449241.027200,U019HNXQEA1,"видимо я случайно отправил им работу, и теперь не могу продолжить её :wink:",,Жуган Артём
1601447838.026400,1601451944.027600,U0185Q2MK19,Работу вернут с проверки и можно будет продолжить),,Олег Булыгин
1601447838.026400,1601452837.027900,U019HNXQEA1,благодарю за помощь :slightly_smiling_face:,,Жуган Артём
1601462593.029600,1601462593.029600,U01BBD8JS75,Вопрос по решению проблемы с аномальным значением  среднего стажа.,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75', 'U01BPRKQP9P'], 'count': 2}]",Алексей Глазов
1601462593.029600,1601463235.029700,U01BBD8JS75,"В ходе исследования я выявил, что у двух категорий клиентов средний стаж работы аномально высок. Теперь возник вопрос, а как можно эти данные отредактировать. Если предположить, что для всех остальных стаж исчислялся в днях, а для этих товарищей он был внесен в часах, все равно выходит, что их средний стаж равняется 366413 часов / 8 рабочих часов в день = 45801 день или 125 лет.  <@U0185Q2MK19> подкажи пожалуйста еще идеи в чем проблема была и как ее можно решить?",,Алексей Глазов
1601462593.029600,1601463904.030200,U0185Q2MK19,"<@U01BBD8JS75>, привет!

Эти аномальные значения могут быть связаны с техническими проблемами выгрузки информации. Мы можем только гадать о точных причинах. Возможно, аномально большие значения хранят стаж в часах, а не в днях.

Что с этим делать - решать тебе :slightly_smiling_face:
Можно игнорировать/удалить эти значения, если этот столбец нам не нужен для анализа.
Можно попробовать предположить природу ошибки и привести значения к адекватному виду.
Можно заменить эти выбросы на средние значения по столбцу в разрезе каких-то других показателей.

Главное – обосновать свое решение ревьюеру.","[{'name': '+1', 'users': ['U01BB72P2HG'], 'count': 1}]",Олег Булыгин
1601462593.029600,1601468699.030900,U01BBD8JS75,"<@U0185Q2MK19> Подскажи пожалуйста, как создать функцию, которой я бы передал таблицу, а она бы проверила: если категория пенсионер или безработный, тогда стаж делим на 24.
<https://pastebin.com/CwxWP9J8>",,Алексей Глазов
1601462593.029600,1601469392.031100,U0185Q2MK19,"<@U01BBD8JS75>, циклы для обработки датафреймов использовать не рекомендуется, лучше применять map/apply, примерно так:

```def conversion_days_employed(df):
    if df['income_type'] == 'безработный' or df['income_type'] == 'пенсионер':
        return df['days_employed'] / 24
    else:
        return df['days_employed']
df['days_employed'] = df.apply(conversion_days_employed, axis=1)```
","[{'name': 'happy-cat', 'users': ['U01BBD8JS75', 'U019HNXQEA1', 'U01AWEPC0SK'], 'count': 3}, {'name': 'all_the_things', 'users': ['U01AWEPC0SK'], 'count': 1}, {'name': 'exploding_head', 'users': ['U01C12HASTA'], 'count': 1}]",Олег Булыгин
1601471861.031700,1601471861.031700,U01BBD8JS75,Вопрос по замене пропусков,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75', 'U01BPRKQP9P'], 'count': 2}]",Алексей Глазов
1601471861.031700,1601472098.032200,U01BBD8JS75,"<@U0185Q2MK19> еще вопрос возник, я сгруппировал клиентов по типу их занятости и нашел медианное значение для каждой из групп
`days_employed_median = data.groupby('income_type')['days_employed'].median()`
Как правильно заменить пропуски на медианное значение в зависимости от того, к какой категории занятости относится клиент?
так же через группировку?",,Алексей Глазов
1601471861.031700,1601491051.032500,U01AWENQ0R5,"<@U01BBD8JS75> Осмелюсь предположить, что через loc и fillna",,Volkhin Roman
1601471861.031700,1601491294.032800,U01BBD8JS75,"<@U01AWENQ0R5> надо не просто пропуски заменить на медиану, а чтобы для каждой группы встали свои медианы...",,Алексей Глазов
1601471861.031700,1601534817.033000,U01AWENQ0R5,"<@U01BBD8JS75> ну вот, через loc передаешь группу для которой нужно заменить, а в fillna передаешь медиану этой группы",,Volkhin Roman
1601471861.031700,1601535078.033200,U01BBD8JS75,"<@U01AWENQ0R5> хм, вывести предварительно десяток медиан для каждой группы и записать их в отдельных переменных, а потом создать логическую индексацию типа если в этой строке группа занятости такая, присвой значение такое?",,Алексей Глазов
1601471861.031700,1601536444.033400,U0185Q2MK19,"Рекомендую использовать метод transform. Он позволит в одну строку все это сделать. Вот так:
```df['days_employed'] = df['days_employed'].fillna(df.groupby('income_type')['days_employed'].transform('median'))```
Можно даже по нескольким признакам делать группировку :slightly_smiling_face:","[{'name': '+1', 'users': ['U01BB72MR6E', 'U01C12H8HJL'], 'count': 2}]",Олег Булыгин
1601471861.031700,1601536758.033800,U01BBD8JS75,<@U0185Q2MK19> получается ваш код сразу группирует по типу занятости  и заменяет пропуски на медианы? Изящно :grin: мы правда на тренажере не проходили метод данный вроде как...,,Алексей Глазов
1601471861.031700,1601537081.034000,U0185Q2MK19,"<@U01BBD8JS75>, да, заменяет на медианы сразу в разрезе групп.
Ничего страшного, что не проходили :slightly_smiling_face: Если понятно, как применять инструмент и он применен правильно, то никто не запрещает использовать функционал сверх пройденного.
Можно, конечно, написать собственную функцию, которая будет делать группировку, для каждой группы высчитывать статистику и заполнять по ним, но это дольше)",,Олег Булыгин
1601554160.035700,1601554160.035700,U01AWENRANB,Вопрос по оформлению,,Ксения Ушакова
1601554160.035700,1601554509.040900,U01AWENRANB,"Доброго времени суток, <@U0185Q2MK19>! 
Случайно удалила часть полей, имеющихся в проекте, что там должно быть помню, но, конечно, не дословно. На сколько критично, если будет сделано не как в примере? Можно на каждый шаг,  например отработка дубликатов делать несколько полей с кодом и текстом?

Как оформить заголовки? Не могу найти, где настроить шрифты",,Ксения Ушакова
1601554160.035700,1601555305.041100,U0185Q2MK19,"<@U01AWENRANB>, привет!
Последовательность шагов (и вся структура работы) должна быть как в условии.
Несколько ячеек делать под каждый шаг - вообще не критично.
Все возможности разметки можно посмотреть в меню Help -&gt; Markdown.

Т.е. отступления возможны, если они не помешают проверке работы ревьюером.
На крайний случай можно попросить в поддержке восстановить исходную версию ноутбука (только сохрани тогда отдельно всю проделанную работу) :slightly_smiling_face:",,Олег Булыгин
1601554160.035700,1601556045.041600,U01AWENRANB,Спасибо! )),,Ксения Ушакова
1601471861.031700,1601558417.041800,U01AWENQ0R5,<@U0185Q2MK19> а мой рабоче-крестьянский метод теоретически бы сработал?,,Volkhin Roman
1601554160.035700,1601568918.042000,U01BB72RSH0,"<@U01AWENRANB> привет! Нашел еще вот такой <https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd|гайд>, быть может будет полезным :slightly_smiling_face:","[{'name': '+1', 'users': ['U01C12G0QNL', 'U0185Q2MK19', 'U019HNXQEA1', 'U01C12EF41E'], 'count': 4}]",Шилоносов Артём
1601554160.035700,1601570377.042600,U01AWENRANB,<@U01BB72RSH0> спасибо!!! :the_horns:,,Ксения Ушакова
1601572083.043000,1601572083.043000,U01BBD8L1DZ,Качество данных,,Екатерина Резанович
1601572083.043000,1601572266.043100,U01BBD8L1DZ,"Всем привет) Что означают минусы в столбце ""*days_employed*"" ? Их по задумке нужно оттуда убрать? Сорри, если вопрос не самый умный..",,Екатерина Резанович
1601572083.043000,1601582773.043500,U01BB72P2HG,"<@U01BBD8L1DZ> похоже на косяк в данных и видимо минус надо убрать)) интересно, что там есть пенсионер со стажем работы 900 лет :joy::+1: интересно, что за выброс и как с этим разобраться))):see_no_evil:",,Мария Пименова
1601572083.043000,1601607112.043800,U01C12GKE1E,"Мне кажется ""*days_employed*"" не используется при поиске ответов на вопросы поставленные в задаче и этот столбец надо или удалить или заменить пропуски на что-то нейтральное, например на среднее значение столбца. Столбец ""*days_employed*""  наверно интересен тем, что в нем значения отсутствуют в тех же строках, что и в ""*total_income*"". Это я заметил на небольшой выборке когда делал вырезку строк с пропусками и это надо исследовать дополнительно, т.к. это может дать ответ на причину появления пропусков.","[{'name': '+1', 'users': ['U01BB72P2HG', 'U01BB72RSH0', 'U01C12H8HJL'], 'count': 3}]",Гуменников Алексей
1601471861.031700,1601612710.044000,U0185Q2MK19,"<@U01AWENQ0R5>, да, конечно, вполне хороший вариант.

Можно даже не руками просчитывать средние для каждой группы, а написать цикл, внутри которого будет происходить расчет для каждой категории (их можно определить при помощи unique) в рамках столбца и сразу производить замену замена при помощи loc.",,Олег Булыгин
1601615709.045100,1601615709.045100,U01BBD8EYR1,Отправка на проверку неготового проекта.,,Евгения Батухтина
1601615709.045100,1601615764.045200,U01BBD8EYR1,"Подскажите, можно ли отправить на проверку не весь проект, а что пока получилось сделать?",,Евгения Батухтина
1601615709.045100,1601618325.053800,U0185Q2MK19,"<@U01BBD8EYR1>, добрый день!
Ревьювер недоработанный проект без проверки отправит на доработку, поэтому в этом нет особого смысла.
Лучше сразу отправлять готовый.",,Олег Булыгин
1601618382.054500,1601618382.054500,U01C12GKE1E,Изменение исходного датафрейма,,Гуменников Алексей
1601572083.043000,1601618456.054800,U0185Q2MK19,"Полностью согласен с <@U01C12GKE1E>.
В треде выше уже отвечал по этому поводу: <https://yandex-students.slack.com/archives/G01B461LV0E/p1601463904030200?thread_ts=1601462593.029600&amp;cid=G01B461LV0E>","[{'name': '+1', 'users': ['U01BB72P2HG', 'U01C12H8HJL'], 'count': 2}]",Олег Булыгин
1601618382.054500,1601618574.055100,U01C12GKE1E,"1. При исследовании таблицы внес изменения в исходный датафрейм. <http://joxi.ru/D2PN1OYHJpX9Nr>
2. Далее удалил код который вносит изменения <http://joxi.ru/brRq7X5tOJkZ0A>
3. При выполнении следующих кодов обнаружил, что они работают не так как должны <http://joxi.ru/DrlxLYoHyvQXwr>
4. После перезапуска строки, в которой формировался исходный датафрейм <http://joxi.ru/ZrJx3LYHn9ZdW2>, все исправилось <http://joxi.ru/vAWEg7KiO1EeWm>
<@U0185Q2MK19> подскажи что происходит?",,Гуменников Алексей
1601618382.054500,1601618901.055600,U0185Q2MK19,"<@U01C12GKE1E>, у тебя точно первые 3 скриншоты должны быть одинаковыми?
Немного не понимаю суть проблемы из-за этого.
1. Ты заполнил пропуски нулями
2. Потом удалил этот код?
3. Метод isnull после этого возвращал пустой датафрейм, что логично (пропуски ведь заменены).
4. Потом загрузил данные заново (кода для заполнения пропусков уже нет, он не исполнялся)
5. И код, который отображается пропуски вывел результат.
На каком этапе твои ожидания отличаются от результата?",,Олег Булыгин
1601618382.054500,1601619336.055800,U01C12GKE1E,"1. заполнил пропуски нулями
2. Метод isnull после этого возвращал пустой датафрейм, что логично (пропуски ведь заменены).
3. удалил код замены пропусков
4. а метод isnull все равно возвращает пустой датафрейм
5. загрузил данные заново, при этом кода замены пропуски на нули уже нет и получил понятный результат
после этапа 3 я думал что получу непустой датафрейм, т.к. я удалил код замены пропусков",,Гуменников Алексей
1601572083.043000,1601619421.056900,U01BBD8L1DZ,"Просто речь шла об аномально высоких значениях, а не об отрицательных, поэтому решила уточнить, спасибо) ",,Екатерина Резанович
1601618382.054500,1601619509.057100,U0185Q2MK19,"Удаление кода - это не отмена произведенных действий)
Изменения в переменных хранятся в памяти, именно поэтому действие отменилось после того, как ты заново загрузил данные в эту переменную.

После исполнения кода, чтобы выгрузить все из памяти нужно перезагрузить ядро (Kernel-Restart). Иначе в памяти все останется, даже если просто удалить код :)","[{'name': '+1', 'users': ['U01C12GKE1E'], 'count': 1}]",Олег Булыгин
1601618382.054500,1601619746.057300,U01C12GKE1E,"Так и предполагал. При написании кода много ошибок получается, соответственно в переменные записываются неверные значения, а когда с ними потом работаешь кажется что код не правильный, а на самом деле в переменных сохранились не верные значения.  <@U0185Q2MK19> Может подскажешь как с этим быть?",,Гуменников Алексей
1601618382.054500,1601619837.057600,U01C12GKE1E,а со скриншотами что-то не то сделал. первый блин комом!:grin:,,Гуменников Алексей
1601618382.054500,1601620452.057900,U0185Q2MK19,"Тут могут быть только такие рекомендации:

• всегда проверять результаты промежуточных действий
• правильно и полноценно именовать переменные, чтобы не путаться между ними и не перезаписывать уже созданные другой новой информацией
• при выявлении принципиальных ошибок перезапускать ядро и заново исполнять ячейки с кодом
С опытом таких ситуаций будет меньше)","[{'name': '+1', 'users': ['U01C12GKE1E'], 'count': 1}]",Олег Булыгин
1601615709.045100,1601621796.058700,U01BBD8EYR1,"<@U0185Q2MK19> понятно, спасибо","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгения Батухтина
1601624143.059400,1601624143.059400,U019HNXQEA1,Группировка по столбцу,,Жуган Артём
1601624143.059400,1601624242.059500,U019HNXQEA1,"как сгруппировать по столбцу income_type, если он ругается, что это тип не str или slices?",,Жуган Артём
1601624143.059400,1601624776.059900,U01C12G0QNL,"<@U019HNXQEA1> Привет. Попробуй передать функции, которые ты хочешь применить, одним списком: {'days_employed'}: ['count', 'mean']}","[{'name': '+1', 'users': ['U019HNXQEA1', 'U0185Q2MK19'], 'count': 2}]",Михаил Перцев
1601471861.031700,1601625558.060400,U01BBD8JS75,"<@U0185Q2MK19> скажи пожалуйста, а можно для полной радости в ваш код добавить условие для замены типа данных на int?",,Алексей Глазов
1601471861.031700,1601625744.060600,U0185Q2MK19,"<@U01BBD8JS75>, не совсем понял вопрос)
Изменение типа это отдельное действие, к импутации пропусков это не имеет отношения. Уточни, какой результат хочешь получить :slightly_smiling_face:",,Олег Булыгин
1601471861.031700,1601626036.060800,U01BBD8JS75,"<@U0185Q2MK19> хочу применить этот метод для замены возраста клиентов на среднее по группе занятости, но при хочу чтобы возраст был целым числом",,Алексей Глазов
1601471861.031700,1601626086.061000,U01BBD8JS75,"`data['dob_years'] = data['dob_years'].replace(0, data.groupby('income_type')['dob_years'].transform('mean'))`",,Алексей Глазов
1601471861.031700,1601626113.061200,U01BBD8JS75,или лучше не городить?,,Алексей Глазов
1601471861.031700,1601626781.061600,U0185Q2MK19,"<@U01BBD8JS75>, можно просто в конец добавить метод `.astype('int64')`",,Олег Булыгин
1601630601.063600,1601630601.063600,U01BBD8JS75,Вопрос по удалению строки при выполнении условия,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75', 'U01BPRKQP9P'], 'count': 2}]",Алексей Глазов
1601630601.063600,1601631168.063800,U01BBD8JS75,"<@U0185Q2MK19> подскажите пожалуйста, как выглядит код для удаления строки, при выполнении определенного условия.
Например в нашей задаче есть один клиент, у которого не указан пол, думаю исследование не сильно пострадает, если из 21525 наблюдений удалю одно.
Для удаления применяется метод `drop()`, необходимое условие `data[data['gender'] == 'XNA']`, мы удаляем строку, значит необходимо добавить `axis = 0`, и наверно для изменения структуры данных надо добавить `inplace = True`.",,Алексей Глазов
1601572083.043000,1601632076.068100,U01BBD8EYR1,"Вообще, если бы это было в реальности, можно было бы подойти к разработчикам и спросить, почему данные в таком формате: 
• во-первых, нецелочисленные, хотя название говорит о днях. Значит там видимо часы и минуты, но не факт.
• Во-вторых, почему значения в большинстве своём отрицательные. 
• В-третьих, почему в двух категориях они положительные и аномально высокие. 
Ну и про пропуски можно было бы с ними поговорить, а тут остаётся только гадать.",,Евгения Батухтина
1601636926.068500,1601636926.068500,U01BBD8JS75,Вопрос по изменению типа данных,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1601636926.068500,1601637120.068600,U01BBD8JS75,"<@U0185Q2MK19> хочу в одной строчке кода применить `<http://pd.to|pd.to>_numeric()` для двух столбцов.
`data[['days_employed', 'total_income']] = data[['days_employed', 'total_income']].apply(<http://pd.to|pd.to>_numeric(downcast ='signed'))`
у меня появляется сообщение ""to_numeric() missing 1 required positional argument: 'arg'. Что нужно указать с аргументом arg ?",,Алексей Глазов
1601636926.068500,1601637692.068800,U01BBD8JS75,"странно, но даже
`data['days_employed'] = <http://pd.to|pd.to>_numeric(data['days_employed'], downcast ='signed')`
не изменяет тип данных на int. Почему?..",,Алексей Глазов
1601636926.068500,1601637846.069000,U01BBD8JS75,"В нашей теории было написано:
&gt; Особенность метода `to_numeric()` в том, что при переводе все числа будут иметь тип данных _float_.
Но это же не совсем правда, да? можно же указать, что нам на выходе нужен int?",,Алексей Глазов
1601636926.068500,1601638265.069200,U01BB72P2HG,"<@U01BBD8JS75> у меня столбец 'days_employed' получилось перевести способом, как ты написал) а вот 'total_income' нет)) его перевела при помощи numpy",,Мария Пименова
1601636926.068500,1601639396.069600,U01BHCPPL2Y,`data['days_employed'] = data['days_employed'].astype(int)`,,Me_
1601636926.068500,1601639680.069800,U01BB72P2HG,"получается тут работает 3 способа:grinning: to_numeric() в int16, astype() в int32, а с помощью Numpy можно перевести и в 32 и в 64. Разница в размере хранения данных, но имеет ли это конкретно в этом случае важный смысл? <@U0185Q2MK19> подскажите пожалуйста ест ли тут разница)",,Мария Пименова
1601636926.068500,1601640040.070200,U01BBD8JS75,<@U01BB72P2HG> а как при помощи Numpy?:relieved:,,Алексей Глазов
1601636926.068500,1601642884.070400,U01BHCPPL2Y,`data['days_employed'] = data['days_employed'].apply(lambda x: float(x))`,,Me_
1601636926.068500,1601642925.070600,U01BHCPPL2Y,"способов сколько хочешь, это скорее вопрос вкуса и удобства","[{'name': '+1', 'users': ['U01BB72P2HG'], 'count': 1}]",Me_
1601643209.071100,1601643209.071100,U01BBD8JS75,Вопрос по поиску дубликатов,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1601643209.071100,1601643751.072100,U01BBD8JS75,"<@U0185Q2MK19> при помощи `duplicated().sum()` я выявил наличие и количество дубликатов. Решил взглянуть, как они выглядят, для этого ввел `data[data.duplicated(keep='first')]`  и получил такую картинку. Данные похожи, но похожи они из-за того, что до этого я стаж и доходы заменил на медианы. А вот возраст, количество детей, цель кредита могут быть разными (хотя иногда совпадают). Как быть аналитику данных в такой ситуации? Тоже на наше усмотрение, удалить или оставить?",,Алексей Глазов
1601646712.074300,1601646712.074300,U01C12GJCGY,вопрос по обозначению столбцов,,Миронов Владислав
1601646712.074300,1601646993.074600,U01C12GJCGY,"<@U0185Q2MK19> Здравствуйте, подскажите, total_income это доход заемщика или банка на кредит и в столбце debt обозначения 1 это долг а 0- это погашение долга?",,Миронов Владислав
1601572083.043000,1601647916.075100,U0185Q2MK19,"Полностью согласен с Евгенией)
Но в жизни бывает и так, что обратиться с такими проблемами не к кому и приходится принимать решение самому, это тоже надо уметь делать)",,Олег Булыгин
1601630601.063600,1601648019.075300,U0185Q2MK19,"<@U01BBD8JS75>, можно просто взять срез с обратным условием)
```data = data[data['gender'] != 'XNA']```
Либо так:

```data = data.drop(data[data['gender'] == 'XNA'].index)```
Во втором варианте можно применить inplace, чтобы сделать изменения в исходном наборе без переприсваивания",,Олег Булыгин
1601630601.063600,1601648275.076000,U01BBD8JS75,"<@U0185Q2MK19> в первом случае мы просто перезаписали нашу таблицу, но не включили в нее строку с с неизвестным полом?
а что во втором случае дает `.index`?",,Алексей Глазов
1601636926.068500,1601648282.076200,U0185Q2MK19,"<@U01BB72P2HG>, для наших задач это вообще не принципиально)

<@U01BBD8JS75>, получилось разобраться?",,Олег Булыгин
1601630601.063600,1601648373.076400,U0185Q2MK19,"<@U01BBD8JS75>, верно.
drop удаляет строки/столбцы именно по меткам (labels, имена индексов). С помощью index мы их и получаем :slightly_smiling_face:",,Олег Булыгин
1601636926.068500,1601648508.076700,U01BBD8JS75,"<@U0185Q2MK19> я решил эту задачку примитивным способом, для каждого столбца применил `.astype('int')`. Но все равно интересно, можно ли в одной строке через apply применить to_numeric или astype сразу к двум столбцам? и можно ли при помощи `to_numeric(data['column'], downcast ='signed')` преобразовать в формат int?",,Алексей Глазов
1601636926.068500,1601648793.077100,U0185Q2MK19,"<@U01BBD8JS75>, вот так: `df[['days_employed', 'total_income']].apply(<http://pd.to|pd.to>_numeric, downcast ='signed')`",,Олег Булыгин
1601646712.074300,1601648904.077300,U0185Q2MK19,"<@U01C12GJCGY>, привет!
total_income - доход заемщика
debt: 1 - имел задолженность, 0  -нет",,Олег Булыгин
1601636926.068500,1601649035.077500,U01BBD8JS75,"<@U0185Q2MK19> `to_numeric(data['column'], downcast ='signed')` не меняет тип данных на int",,Алексей Глазов
1601643209.071100,1601649155.077700,U0185Q2MK19,"<@U01BBD8JS75>, это нормально, если было принято верное и обоснованное решение по заполнению пропусков :slightly_smiling_face:
Удалять, что было именно так заполнено - точно нет смысла. Главное обосновать, что заполнение пропусков было осуществлено корректно.",,Олег Булыгин
1601636926.068500,1601649233.077900,U0185Q2MK19,"<@U01BBD8JS75>, если задача именно в этом, то нужно явно указать такой аргумент: `df[['days_employed', 'total_income']].apply(<http://pd.to|pd.to>_numeric, downcast ='integer')`","[{'name': '+1', 'users': ['U01BB72P2HG'], 'count': 1}]",Олег Булыгин
1601643209.071100,1601649492.078400,U01BBD8JS75,"<@U0185Q2MK19> тогда такой вопрос, допустим есть вот такая таблица с данными. Метод `duplicated()` скажет что это повторы?",,Алексей Глазов
1601643209.071100,1601649613.078800,U0185Q2MK19,"<@U01BBD8JS75>, по-умолчанию - нет.
Но аргументом subset можно регулировать в каких колонках искать дубликаты (если надо не по всем смотреть): <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated>",,Олег Булыгин
1601643209.071100,1601649766.079000,U01BBD8JS75,"<@U0185Q2MK19> а почему тогда в моем примере программа говорит, что эти строки дублируются, если некоторые колонки все-же разнятся?",,Алексей Глазов
1601636926.068500,1601649888.079200,U01BBD8JS75,<@U0185Q2MK19> спасибо)) а astype работает вместе с apply? или опять виной всему кривые рученки...,,Алексей Глазов
1601646712.074300,1601649910.079400,U01C12GJCGY,<@U0185Q2MK19> Спасибо большое,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Миронов Владислав
1601643209.071100,1601650002.079600,U01BBD8JS75,"конечно строка 20702 и 21032 очень похожи, там даже цель одна и та же, хоть сформулирована по разному, однако одному клиенту 64, а другому 60. Значит это все же разные люди",,Алексей Глазов
1601643209.071100,1601650176.079800,U0185Q2MK19,"<@U01BBD8JS75>, у тебя в датафрейме находятся только дубли) По одному вхождению. В исходном датафрейме таких записей несколько.",,Олег Булыгин
1601636926.068500,1601650292.080100,U0185Q2MK19,"<@U01BBD8JS75>, astype можно напрямую применить целиком к датафрейму (и к выборке из него), даже без apply.",,Олег Булыгин
1601643209.071100,1601650338.080300,U01BBD8JS75,"<@U0185Q2MK19> то есть`data[data.duplicated(keep='first')]`показал мне именно те строки, у которых есть полные стопроцентные дубликаты, а не сами дубликаты?",,Алексей Глазов
1601643209.071100,1601650486.080500,U0185Q2MK19,"<@U01BBD8JS75>, у нас есть  числа 1 1 1 2 2 3.
Метод показывает только повторы. Т.е. 1 1 2",,Олег Булыгин
1601643209.071100,1601650573.080700,U01BBD8JS75,<@U0185Q2MK19> А почему 1 он покажет два раза?,,Алексей Глазов
1601643209.071100,1601650621.080900,U0185Q2MK19,<@U01BBD8JS75> потому что это два повтора первого вхождения числа. Изначально их три.,,Олег Булыгин
1601643209.071100,1601650833.081100,U01BBD8JS75,<@U0185Q2MK19> в общем он указывает на все лишние элементы/строки,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Алексей Глазов
1601662564.081800,1601662564.081800,U01BB72P2HG,Вопрос по уровню дохода,"[{'name': 'heavy_check_mark', 'users': ['U01BB72P2HG'], 'count': 1}]",Мария Пименова
1601662564.081800,1601662677.082100,U01BB72P2HG,"<@U0185Q2MK19> какой доход считать средним, если ,например, по версии РБК средний доход в Москве от 120 000р, а в регионах от 60 000р? По другим версиям в мск от 70 000р, регионы от 50 000р. брать в среднем по стране?:slightly_smiling_face: тут было бы намного интереснее, если бы была колонка с указанием города:bongo_blob:",,Мария Пименова
1601636926.068500,1601663628.082900,U01C12GKE1E,"<@U0185Q2MK19> для чего вообще менять типы данных в нашем проекте? Мне кажется, что изменение типа данных ни как не влияет на решение поставленных вопросов. Если только для столбца с доходами, что бы красиво оформить итоговые таблицы.",,Гуменников Алексей
1601462593.029600,1601664050.083100,U019HNXQEA1,"<@U0185Q2MK19> Для пенсионеров и безработных решил, что время написано не в днях, а в минутах, тем самым получил значения по ≈ 550 дней, что вроде как мало для пенсионера и нормально для безработного.
Вопрос следующий:
Что же всё-таки делать с данными (безработными и пенсионерами)?)",,Жуган Артём
1601462593.029600,1601664336.083500,U019HNXQEA1,"<@U0185Q2MK19> Если всё же я хочу заменить на средние значения, то как лучше это провернуть? :slightly_smiling_face:",,Жуган Артём
1601462593.029600,1601664901.083700,U019HNXQEA1,"<@U0185Q2MK19> Всё, разобрался :slightly_smiling_face:
Там вероятно в часах, а не в минутах представлено время, так что всё сходится :slightly_smiling_face:",,Жуган Артём
1601665967.084400,1601665967.084400,U019HNXQEA1,Вопрос по нахождению NaN,,Жуган Артём
1601665967.084400,1601666032.084500,U019HNXQEA1,По какой причине не находит NaN?,,Жуган Артём
1601572083.043000,1601666870.084800,U019HNXQEA1,"Напомните, пожалуйста, как заменить отрицательные значения на положительные?:thinking_face:",,Жуган Артём
1601665967.084400,1601667405.085400,U01BB72TAHG,"Потому что их нет в данном столбце, но зато там есть нули ",,Николаенко Анастасия
1601665967.084400,1601667492.085700,U019HNXQEA1,"<@U01BB72TAHG> благодарю!
А их через логическую индексацию вывести?)",,Жуган Артём
1601665967.084400,1601667716.087200,U01BB72TAHG,Ну стандартно df[df[col_name]==0] )),"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Николаенко Анастасия
1601665967.084400,1601667751.087400,U019HNXQEA1,"Спасибо большое :slightly_smiling_face:
Там дальше нет подобных подвохов с данными?))",,Жуган Артём
1601665967.084400,1601667839.088200,U01BB72TAHG,Полным полно:grin:иначе нам бы нечего было делать,,Николаенко Анастасия
1601665967.084400,1601668017.088400,U019HNXQEA1,Верно-верно :wink:,,Жуган Артём
1601572083.043000,1601669980.088900,U01BB72P2HG,<@U019HNXQEA1> в уроке изменение типов данных мы такое делали:wink:,"[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12H8HJL'], 'count': 2}]",Мария Пименова
1601572083.043000,1601670850.089100,U019HNXQEA1,<@U01BB72P2HG> Благодарствую!),,Жуган Артём
1601665967.084400,1601701511.089300,U01BBD8JS75,"есть еще один метод полезный для начала анализа датафрейма: `df.describe()`. Данный метод выдаст вам по столбцам количество строк с данными, среднее, минимальное и максимальное значение и еще немного другой инфы.","[{'name': '+1', 'users': ['U01BB72RSH0', 'U019HNXQEA1', 'U0185Q2MK19', 'U01AWENRANB'], 'count': 4}]",Алексей Глазов
1601665967.084400,1601709613.090000,U019HNXQEA1,<@U01BBD8JS75> Благодарствую!),,Жуган Артём
1601662564.081800,1601712495.090600,U0185Q2MK19,"<@U01BB72P2HG>, подскажи, а для каких целей эта информация в рамках этого проекта? Зачем нам знать реальный средний доход?",,Олег Булыгин
1601636926.068500,1601713038.090800,U0185Q2MK19,"<@U01C12GKE1E>, верно, это больше техническая, а не аналитическая задача. На наши выводы это никак не повлияет, но это надо делать (и уметь делать).

Во многом это вопрос скорости и точности:
Рекомендую почитать вот эти статью и обсуждение, там все исчерпывающе:

<https://tirinox.ru/float-python/>
<https://coderoad.ru/36360688/%D0%9F%D1%80%D0%B5%D0%B8%D0%BC%D1%83%D1%89%D0%B5%D1%81%D1%82%D0%B2%D0%B0-%D0%B8-%D0%BD%D0%B5%D0%B4%D0%BE%D1%81%D1%82%D0%B0%D1%82%D0%BA%D0%B8-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D1%87%D0%B8%D1%81%D0%BB%D0%BE%D0%B2%D0%BE%D0%B3%D0%BE-float-%D1%82%D0%B8%D0%BF%D0%B0-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85>",,Олег Булыгин
1601462593.029600,1601713080.091100,U0185Q2MK19,"<@U019HNXQEA1>, да, вполне хорошая гипотеза)",,Олег Булыгин
1601719903.092200,1601719903.092200,U019HNXQEA1,Вопрос по замене отрицательных значений,,Жуган Артём
1601719903.092200,1601720177.092300,U019HNXQEA1,"Как с помощью try и except заменить отрицательные значения? (в голову никакие алгоритмы не лезут)
Когда проходил тренажёр понимал как работает  код, но к данным в таблице не могу ничего придумать :disappointed:",,Жуган Артём
1601719903.092200,1601720473.093600,U01BB72TAHG,"<@U019HNXQEA1> зачем использовать try, except? Можно просто взять модуль столбца
...apply(abs)","[{'name': '+1', 'users': ['U019HNXQEA1', 'U01BPRKQP9P'], 'count': 2}]",Николаенко Анастасия
1601719903.092200,1601720550.094000,U019HNXQEA1,"<@U01BB72TAHG> ой, и правда:heart_eyes:",,Жуган Артём
1601662564.081800,1601720906.094200,U01BB72P2HG,"<@U0185Q2MK19> у нас есть вопрос - Есть ли зависимость между уровнем дохода и возвратом кредита в срок?

т.е. нужно категоризировать людей по уровню достатка хотя бы на 3 категории: низкий, средний и высокий. зарплаты от 20к до 2 миллионов)) и мне интересно, банки учитывают регион или нет в реальности, потому что уровень зп и расходов в Москве и регионах очевидно разный:slightly_smiling_face: соответственно я бы уровень доходов тоже определяла по-разному:woman-shrugging::skin-tone-3: но понимаю, что в нашей задаче пока можно брать условно, так?)",,Мария Пименова
1601719903.092200,1601722221.094400,U01BPRKQP9P,"<@U019HNXQEA1> как вариант ещё можно проверить значения в столбце через условный оператор. и если значение будет меньше 0, домножать на -1, но лучше и правда взять модуль",,Никита Коптелов
1601719903.092200,1601722269.094700,U019HNXQEA1,"<@U01BPRKQP9P> Как вариант - неплох!
Но всё же по модулю намного проще :wink:",,Жуган Артём
1601662564.081800,1601725680.095200,U0185Q2MK19,"<@U01BB72P2HG>, ага, понял :slightly_smiling_face:
С уверенностью могу сказать, что в банках, конечно, учитывают доходы относительно региона. А в текущей задаче вы можете разделить на категории, как сами считаете нужным, все верно","[{'name': 'pray', 'users': ['U01BB72P2HG'], 'count': 1}]",Олег Булыгин
1601734132.095800,1601734132.095800,U01BB72P2HG,Проблема с бесконечностью,"[{'name': 'heavy_check_mark', 'users': ['U01BB72P2HG'], 'count': 1}]",Мария Пименова
1601734132.095800,1601734253.095900,U01BB72P2HG,"<@U0185Q2MK19> помогите пожалуйста разобраться:pray: я пытаюсь найти соотношение между категориями  и в одном из случаев (в ratio_1) у меня получается слишком длинное число в результате и выдает ошибку бесконечности(inf), остальное считает нормально. вот код <https://pastebin.com/DLrFcb3X>
что с этим можно сделать?

я возможно пойду немного другим путем в итоге)) я тут усложнила. но хотелось бы разобраться что делать в случае, когда появляются такие ошибки:slightly_smiling_face:",,Мария Пименова
1601736323.098900,1601736323.098900,U01BBD8EYR1,Вопрос по циклу for.,,Евгения Батухтина
1601736323.098900,1601736540.099000,U01BBD8EYR1,"Хочу добавить леммы в новый столбец по каждой строке по значениям из столбца purpose. Но получаю ошибку во время исполнения цикла, которая говорит, что у меня что-то не так с индексами:
<http://joxi.ru/L21xp63i0JqNgm>
Столбец для лемм я создала заранее. Заполнила его пробелом на всякий случай, чтобы было понятно, что столбец для строк:
<http://joxi.ru/bmo36EBuyW0nJm>
Для проверки работы цикла попробовала добавить значение с леммой в первую строчку, но получила предупреждение, про которое вообще ничего не поняла:
<http://joxi.ru/Y2LPpz8iEgGYM2>

<@U0185Q2MK19>, помогите разобраться, пожалуйста",,Евгения Батухтина
1601736323.098900,1601736748.099300,U01BBD8EYR1,"Вставляю строчки кода на всякий случай:
<https://pastebin.com/Z54maKSE>",,Евгения Батухтина
1601734132.095800,1601738046.099700,U0185Q2MK19,"Просьба всегда присылать скриншот ошибки, потому что я не могу в полной мере воспроизвести этот код с гарантированно таким же результатом, т.к. не знаю какие действия были сделаны до этого (или их долго воспроизводить) :slightly_smiling_face:",,Олег Булыгин
1601734132.095800,1601742205.100000,U01BB72P2HG,"<@U0185Q2MK19> поняла, спасибо!:slightly_smiling_face::pray: я к сожалению уже успела удалить этот код:joy::woman-facepalming: поэтому  не смогу прислать скриншот. в следующий раз обязательно сделаю. пока отмечу вопрос как решенный. возможно, если снова столкнусь с подобной проблемой, то снова спрошу)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Мария Пименова
1601719903.092200,1601749531.100300,U01C12GKE1E,"<@U0185Q2MK19> отрицательные значения пытался поменять методом replace ""-1"" на ""1"", но этот метод видимо не работает для типов данных int?",,Гуменников Алексей
1601736323.098900,1601790977.101100,U0185Q2MK19,"<@U01BBD8EYR1>, привет!
Я не рекомендую использовать циклы для обработки датафреймов. Это всегда дольше и менее эффективно. Почти все задачи можно решить через apply или map.
Вот так можно сделать лемматизацию.
```from pymystem3 import Mystem
m = Mystem()
df['lemmas'] = df.purpose.apply(m.lemmatize)```
Потом при необходимости аналогично в одну строку можно соединить списки в строки.

Обязательно отпишись, получилось ли :slightly_smiling_face:",,Олег Булыгин
1601719903.092200,1601791297.101300,U0185Q2MK19,"<@U01C12GKE1E>, в данном случае ты replace применяешь для строк, а надо именно числа заменять. Проще просто умножить отрицательные значения на -1 :slightly_smiling_face:
Или использовать функцию abs() к столбцу","[{'name': '+1', 'users': ['U01C12GKE1E'], 'count': 1}]",Олег Булыгин
1601736323.098900,1601791709.101800,U01BBD8EYR1,"<@U0185Q2MK19> спасибо, попробую!",,Евгения Батухтина
1601736323.098900,1601816548.102700,U01BBD8EYR1,<@U0185Q2MK19> все получилось! буду теперь знать как правильно =),"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгения Батухтина
1601827769.103300,1601827769.103300,U01C12GG1UG,Вопрос по лемматизации,"[{'name': 'heavy_check_mark', 'users': ['U01BPRKQP9P'], 'count': 1}]",Павел Катанов
1601827769.103300,1601828101.103400,U01C12GG1UG,"<@U0185Q2MK19> Через .apply(m.lemmatize) сделал лемматизацию столбца Purpose. Однако возникли проблемы с объединением списка в строку. Метод .apply(',' .join) работает не так, как хотелось бы, разделяя не слова, а буквы. Из-за чего не могу сгруппировать таблицу с условием по соответствию.
Объяснил не очень понятно, надеюсь скриншоты и код помогут:
<https://pastebin.com/jsjJW8V8>
Подскажите, пожалуйста, что не так делаю?",,Павел Катанов
1601827769.103300,1601828278.103600,U01C12GG1UG,Вот так отображается после .join,,Павел Катанов
1601827769.103300,1601836959.104300,U01BB72RSH0,"<@U01C12GG1UG> привет! А какую цель ты преследуешь при выполнении дальнейших операций со столбцом после лемматизации? По большому счету строки 6 и 8 в коде из сообщения выше, на мой взгляд, делу не особо помогают. Строкой 4 ты разбиваешь каждое значение столбца  `df['lemmas']` на словари, например, значение этого столбца в строке 0 будет равно: `[ 'покупка', '', 'жилье', '\n']` Дальше можно оценить частоту упоминаний значений новообразованного столбца с помощью `.value_counts()` и в зависимости от полученных результатов думать над тем, что делать дальше.",,Шилоносов Артём
1601827769.103300,1601839234.104500,U01C12GG1UG,"Да, возможно, я чутка не до конца понимаю, что я хочу сделать :))
Как я это вижу: после лемматизации я смогу по ключевому слову (например: ""автомобиль"") сгруппировать всех, у кого целью кредита являлся автомобиль. И также с остальными целями кредитов.",,Павел Катанов
1601827769.103300,1601847248.105000,U01C12GG1UG,"Получилось сделать без лемматизации, однако это потребовало много действий: <https://pastebin.com/660arztj>

Подскажите, пожалуйста, куда смотреть и что попробовать, дабы как-то упростить этот процесс и таки задействовать лемматизацию?",,Павел Катанов
1601827769.103300,1601862071.105300,U01BB72RSH0,<@U01C12GG1UG> можно было еще <https://pastebin.com/aC7UG9Jh|так> сделать (:,"[{'name': '+1', 'users': ['U01BBD8JS75'], 'count': 1}]",Шилоносов Артём
1601827769.103300,1601870975.105500,U0185Q2MK19,"<@U01C12GG1UG>, у <@U01BB72RSH0> очень хороший вариант.
Т.е. логика может быть такая:
1. делаем лемматезацию:
`df['lemmas'] = df.purpose.apply(m.lemmatize)`
2. Смотрим на словарь со всем спектрам целей:
`Counter(m.lemmatize(' '.join(df['purpose'])))` 
3. руками выделяем те категории, которые считаем нужным и пишем функцию, примерно как у Артёма.
Удалось разобраться?","[{'name': '+1', 'users': ['U01BBD8TXJ7', 'U01BPRKQP9P'], 'count': 2}]",Олег Булыгин
1601827769.103300,1601890661.106300,U01C12GG1UG,<@U0185Q2MK19> <@U01BB72RSH0> спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19', 'U01BB72RSH0'], 'count': 2}]",Павел Катанов
1601890815.107000,1601890815.107000,U019HNXQEA1,Вопрос по замене нулей на среднее значение,"[{'name': 'heavy_check_mark', 'users': ['U019HNXQEA1'], 'count': 1}]",Жуган Артём
1601890815.107000,1601891060.107200,U019HNXQEA1,"Прописал логическую индексацию, которая находит нули, а затем добавил fillna, чтобы заменить нули на ср. значения, но по итогу нашлись только нули :disappointed:
Что не так делаю?",,Жуган Артём
1601890815.107000,1601891315.107500,U019HNXQEA1,Вопрос решён методом replace :slightly_smiling_face:,,Жуган Артём
1601890815.107000,1601896515.111900,U01BBD8TXJ7,"Артём, у тебя получается такой результат, потому что ты метод fillna применяешь к датафрейму, который содержит только строки, где значение столбца dob_years==0(самая первая строка в твоём коде).
Примени его к полной таблице данных и должно получится то, что ты хочешь)
",,Андрей Черненко
1601890815.107000,1601897054.112100,U019HNXQEA1,"<@U01BBD8TXJ7> ой, точно, неправильно рассуждал тогда:grimacing::grin:",,Жуган Артём
1601890815.107000,1601903665.112800,U0185Q2MK19,"Ну и нужно помнить, что fillna заполняет NaN, а не нули  :slightly_smiling_face:
Нули - это не пропуски",,Олег Булыгин
1601890815.107000,1601905402.113000,U019HNXQEA1,<@U0185Q2MK19>  совсем забыл:grimacing::point_right::point_left:,,Жуган Артём
1601919232.116200,1601919232.116200,U01AWENRANB,Поиск NaN,,Ксения Ушакова
1601919232.116200,1601919454.119400,U01AWENRANB,"Вечер добрый!
Не понимаю, почему не работает логическая индексация типа 
df[df[‘total_income’] == ‘NaN’]
Как вывести строки с этими Нанами?  А ещё лучше
 df[(df[‘total_income’] == ‘NaN’) or (df[‘years_employed’] == ‘NaN’)]",,Ксения Ушакова
1601919232.116200,1601920473.119600,U01AWENQ0R5,"<@U01AWENRANB> Потому что тут ты в условии передаешь строку, а именно - слово NaN. У нас же ячейки просто пустые, то есть условие должно выглядеть так: df.total_income.isnull()","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12H8HJL'], 'count': 2}]",Volkhin Roman
1601919232.116200,1601920608.119900,U01AWENQ0R5,<@U01AWENRANB> только OR выражается как знак |,,Volkhin Roman
1601919232.116200,1601920671.120200,U01AWENRANB,Спасибо!,,Ксения Ушакова
1601930071.121300,1601930071.121300,U01C12GJCGY,Категоризация,,Миронов Владислав
1601930071.121300,1601930613.121400,U01C12GJCGY,"<@U0185Q2MK19> добрый вечер, не понимаю что нужно писать, и что требуется по категоризации и какую функцию писать, написал вот так <https://pastebin.com/WKjc78bv>  <http://joxi.ru/52aWpKXTk4JK4r>",,Миронов Владислав
1601930071.121300,1601956063.122000,U0185Q2MK19,"<@U01C12GJCGY>, обрати, пожалуйста, внимание, на вот этот мой коммент: <https://yandex-students.slack.com/archives/G01B461LV0E/p1601870975105500?thread_ts=1601827769.103300&amp;cid=G01B461LV0E>
Там написано, что надо делать)
Пиши, если не получится)",,Олег Булыгин
1601974763.122900,1601974763.122900,U019HNXQEA1,Вопрос по замене пропусков,"[{'name': 'heavy_check_mark', 'users': ['U019HNXQEA1'], 'count': 1}]",Жуган Артём
1601974763.122900,1601974881.123000,U019HNXQEA1,"Подскажите пожалуйста, что делать с ежемесячным доходом?)
Кроме как удалить доход у безработных и заменить пустые значения на средний доход, - ничего в голову не приходит :face_with_rolling_eyes:",,Жуган Артём
1601930071.121300,1601975264.123300,U01C12GJCGY,"<@U0185Q2MK19> лемматизацию я уже делал в предыдущем задании, просто я не понял как можно выделенные слова, которые в лемме, засунуть в функцию, я пытался писать так : if переменная == 'жилье ', не знаю правильно ли переменная должна быть равна row['purpose']?",,Миронов Владислав
1601974763.122900,1601979050.123800,U01C12GKE1E,<@U019HNXQEA1> я заменил на медианный доход в разрезе занятости и пола. А зачем удалять доход у безработных?:thinking_face:,,Гуменников Алексей
1601974763.122900,1601979210.124000,U019HNXQEA1,<@U01C12GKE1E> вообще незачем как оказалось :slightly_smiling_face:,"[{'name': '+1', 'users': ['U01C12GKE1E'], 'count': 1}]",Жуган Артём
1601980753.124700,1601980753.124700,U01C12GKE1E,Вопрос по клиентам с 20 детьми.,,Гуменников Алексей
1601980753.124700,1601980811.124800,U01C12GKE1E,Кто что делал с такими строками?,,Гуменников Алексей
1601980753.124700,1601981709.125000,U01BBD8JS75,"<@U01C12GKE1E> для ответа на вопрос о зависимости количества детей и возвратов по кредиту я делил на группы нет детей, 1-2 ребёнка и многодетные. Соответственно 20 детей просто отнеслись к многодетным)","[{'name': 'grin', 'users': ['U01C12GKE1E'], 'count': 1}]",Алексей Глазов
1601980753.124700,1601982144.125300,U01BB74BJ9G,<@U01C12GKE1E> я посчитал это ошибками при вводе данных и заменил на 2,,Владимир Саков
1601980753.124700,1601982208.125500,U01C12GKE1E,<@U01BB74BJ9G> тоже склоняюсь к этому мнению,,Гуменников Алексей
1601980753.124700,1601982460.126900,U01AWENRANB,"Я подумала, что это могут быть как 2, так и 0, и удалила эти строки. Их ведь не так много ","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01BB72MR6E'], 'count': 2}]",Ксения Ушакова
1601980753.124700,1601982691.127100,U01C12GKE1E,"<@U01AWENRANB> мне кажется нажимая на клавиатуре 2 проще зацепить 0, нежели наоборот. Хотя при таком подходе должны быть опечатки с 10. От того и вопрос. Видимо каждый сделает так как считает правильным, т.к. истину не определить.","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01BB72RSH0', 'U019HNXQEA1'], 'count': 3}]",Гуменников Алексей
1601974763.122900,1601982999.131200,U01AWENRANB,"<@U01C12GKE1E> и какая разница оказалась в зависимости от пола, просто любопытно, сама делала зависимость только от типа занятости. 
Может быть тогда объективнее было учитывать образование? ",,Ксения Ушакова
1601974763.122900,1601983444.131800,U01C12GKE1E,"<@U01AWENRANB> я не делал отдельно.  не думаю что результат от этого сильно зависит. разговор то только о замене пустых значений дохода на какие-то более менее достоверные сведения. можно сделать и от трёх значений: образование, пол, занятость. преподаватель в проекте показывал конструкцию которая позволяет это сделать.",,Гуменников Алексей
1601980753.124700,1601983959.132000,U01BPRN9VCH,"Я заменила 20 на 2, а -1 на один, решила, это ошибки при вводе данных, описки:woman-shrugging:","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01BB72RSH0', 'U01C12JD9TJ'], 'count': 3}]",Анна Шлёнская
1601974763.122900,1601984064.133800,U01AWENRANB,"<@U01C12GKE1E> просто было любопытно, а самой проверять не хочется пока. Не могу пока свой код докрутить и каждое лишнее движении затягивает меня в пучину ещё глубже :sweat_smile:",,Ксения Ушакова
1601974763.122900,1601984394.134000,U01C12GKE1E,<@U01AWENRANB> это точно. вначале нужно базовые вопросы дорешать. а вот когда ревьюер проект примет. вот тогда можно поэкспериментировать.:blush:,,Гуменников Алексей
1601930071.121300,1601985637.134400,U0185Q2MK19,"<@U01C12GJCGY>, после шага лемматизация у нас получается столбец со *списками*. Если ты не делал никаких доп. действий и там так же списки, то нужно проверять не на _равенство_, а на _вхождение_.
`if 'жилье' in ...` и пр.

Можно эти списки и в строки обратно слепить при помощи `join`, в этом случае все равно нам нужно не равенство, а вхождение слова в строку, так же надо применять `in`.","[{'name': 'heavy_check_mark', 'users': ['U01C12GJCGY'], 'count': 1}]",Олег Булыгин
1601980753.124700,1601988047.135100,U01BB72RSH0,"<@U01C12GKE1E>, согласен с <@U01BPRN9VCH> - делал абсолютно по этой же логике. Значение `20` - однозначно ошибка, поскольку таких значений много, а промежуточные между `5` и `20` отсутствуют совсем. `-1` так же заменяли на `1`.",,Шилоносов Артём
1601930071.121300,1601989380.135300,U01C12HASTA,"<@U0185Q2MK19>, хочу создать колонку с обобщенной целью кредита, но функция, проверяющая вхождение слова в столбец с леммами не работает. Можешь подсказать что не так?
<https://pastebin.com/HpttcAz7>",,Евгений Султанов
1601930071.121300,1601989778.135500,U0185Q2MK19,"<@U01C12HASTA>, функция написано верно, а вот применена не совсем :slightly_smiling_face:
apply мы применяем к датафрейму, а не к Series. И нужно указать аргумент axis=1.

```df.apply(purpose_category, axis = 1)```
Попробуй так, отпишись о результатах)",,Олег Булыгин
1601930071.121300,1601990383.135700,U01C12HASTA,"<@U0185Q2MK19>, а я был уверен, что нужно к Series применять(
Спасибо, теперь работает)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгений Султанов
1601974763.122900,1601994795.136900,U01AWENRANB,"<@U01C12GKE1E>, пролистала видео, но эту волшебную конструкцию так и не нашла, можете показать?",,Ксения Ушакова
1601974763.122900,1601995121.137100,U01C12GKE1E,"Не в видео. Тут 
<https://yandex-students.slack.com/archives/G01B461LV0E/p1601536444033400?thread_ts=1601471861.031700&amp;cid=G01B461LV0E|https://yandex-students.slack.com/archives/G01B461LV0E/p1601536444033400?thread_ts=1601471861.031700&amp;cid=G01B461LV0E>
И тут
<https://yandex-students.slack.com/archives/G01B461LV0E/p1601550526034500?thread_ts=1601550526.034500&amp;cid=G01B461LV0E|https://yandex-students.slack.com/archives/G01B461LV0E/p1601550526034500?thread_ts=1601550526.034500&amp;cid=G01B461LV0E>",,Гуменников Алексей
1601974763.122900,1601995331.137800,U01AWENRANB,"Крутяк! Спасибо, попустила","[{'name': '+1', 'users': ['U01C12GKE1E', 'U0185Q2MK19'], 'count': 2}]",Ксения Ушакова
1601980753.124700,1601998438.139100,U01B84JJ5L5,<@U01BB72RSH0> покажешь как реализовал функцию? ,,Ингвар Сильницкий
1601980753.124700,1601998873.139300,U01BB72RSH0,"<@U01B84JJ5L5> там <https://pastebin.com/9zrvYe3C|очень простая функция>: получает на вход массив, после чего каждое значение определенного столбца проверяет на соответствие условию `== 20` , если истина, то возвращает значение 2, если ложь - возвращает тоже самое значение, что получила на входе.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1601980753.124700,1601999097.140400,U01B84JJ5L5,"<@U01BB72RSH0> понял, спасибо",,Ингвар Сильницкий
1602064900.142400,1602064900.142400,U01C12DM2BA,Не знаю как начать проект :wall:<@U0185Q2MK19>,,Фарид Бабаев
1602064900.142400,1602065021.142700,U01C12DM2BA,"В тренажере было просто, потому что направляли, а с проектом как ёжик в тумане.",,Фарид Бабаев
1602064900.142400,1602065691.143300,U019HNXQEA1,"<@U01C12DM2BA> как я тебя понимаю :wink:
Для начала тебе очень поможет проанализировать в целом таблицу команда data.describe()",,Жуган Артём
1602064900.142400,1602065817.143500,U01C12DM2BA,"Я уже слишком долго смотрю и анализирую таблицу, что она стала смотреть на меня :slightly_smiling_face:
describe(), info() уже использовал, а на поиске и заполнении пропущенных значений ступор и все :wall:","[{'name': 'rolling_on_the_floor_laughing', 'users': ['U01C12H9MUY', 'U01BBD8HKR9'], 'count': 2}, {'name': 'wink', 'users': ['U01BBD50335'], 'count': 1}]",Фарид Бабаев
1602066225.144000,1602066225.144000,U019HNXQEA1,Вопрос по замене данных в таблице,,Жуган Артём
1602066225.144000,1602066316.144100,U019HNXQEA1,"Забыл как менять значения с помощью логической индексации  :face_with_rolling_eyes:
Подскажите пожалуйста, как заменить в столбце children число 20 на 2",,Жуган Артём
1602066225.144000,1602066668.144400,U01C12HDRUG,Вот здесь другой Артём уже отвечал на этот вопрос:  <https://yandex-students.slack.com/archives/G01B461LV0E/p1601998873139300?thread_ts=1601980753.124700&amp;cid=G01B461LV0E>,"[{'name': 'joy', 'users': ['U01BB72RSH0'], 'count': 1}]",Елена Угдыжекова
1602066225.144000,1602066896.144700,U019HNXQEA1,<@U01C12HDRUG> благодарствую! :slightly_smiling_face:,,Жуган Артём
1602066225.144000,1602068874.145100,U01BB72RSH0,"<@U019HNXQEA1>, <@U01C12HDRUG>, на самом деле все можно сделать намного проще и в <https://pastebin.com/MEzafZMh|одну строку>, используя `.replace()` .","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12JD9TJ'], 'count': 2}]",Шилоносов Артём
1602066225.144000,1602068948.145300,U019HNXQEA1,"<@U01BB72RSH0> тоже об этом подумал, но я предположил, что replace почему-то производит замену пропусков:open_mouth:",,Жуган Артём
1602066225.144000,1602071630.150100,U01BBD8TXJ7,"<@U019HNXQEA1>  можно ещё так:
Выведи строку на экран, запомни/запиши в переменную ее индекс, обратись к конкретной ячейке и поменяй в ней значение.
","[{'name': '+1', 'users': ['U0185Q2MK19', 'U019HNXQEA1'], 'count': 2}]",Андрей Черненко
1602064900.142400,1602072764.150400,U0185Q2MK19,"<@U01C12DM2BA>, привет!
Для этого и нужны проекты :slightly_smiling_face:
Чтобы научить применять полученные знания самостоятельно. Этапы реализации задачи прописаны, нужно теперь вспоминать, какие инструменты были использованы в тренажере для решения аналогичных задач.

Для начала примени info и describe и напиши выводы по ним.
Посчитать пропуски можно так:
```df.isnull().sum()```
Нужно выдвинуть гипотезы о пропусках в конкретных столбцах и принять решение о том, что с ними делать. Как их можно заполнить? Почему? На эти вопросы нет единственно правильного ответа, главное, чтобы ты обосновал свой подход ревьюеру)
Вот здесь я давал комментарий по удобной замене пропусков средними в разрезе каких-либо категорий:
<https://yandex-students.slack.com/archives/G01B461LV0E/p1601536444033400?thread_ts=1601471861.031700&amp;cid=G01B461LV0E>

Можно посмотреть, есть ли дубли в данных при помощи
```df.duplicated().sum()```
написать комментарий. И вот так поэтапно отвечать на поставленные вопросы)","[{'name': 'happy-cat', 'users': ['U01C12H8HJL'], 'count': 1}, {'name': 'sunny', 'users': ['U01BB72P2HG'], 'count': 1}]",Олег Булыгин
1602064900.142400,1602074328.151100,U01C12H8HJL,"<@U01C12DM2BA> как я тебя понимаю, сама весь понедельник смотрела на проект и видела вот эту вот картинку","[{'name': 'joy', 'users': ['U019HNXQEA1', 'U01BBD8DKM1', 'U01B4EYRJ5U', 'U01BB72MR6E', 'U01BB72RSH0', 'U01B84HU32R', 'U01C12DM2BA', 'U01C12HDRUG', 'U01BBD50335'], 'count': 9}]",Юлия Филоненко
1602064900.142400,1602074452.151500,U01C12H8HJL,"<@U01C12DM2BA> На самом деле, главное действительно начать. Мне очень помог просмотр вебинара, который вел Глеб в воскресенье, это просто не зря потраченные 2,5 часа. Столько идей по пути возникло! Пока смотришь, записывай все гипотезы и мысли, которые придут в голову.
Потом напиши себе план, какие взаимосвязи бы ты хотел проверить. И от этого прыгай...как зайчик :joy:

Еще вот тут почитай про пропуски <http://espressocode.top/working-with-missing-data-in-pandas/> и треды по заполнению пропусков. Там <@U0185Q2MK19> (спасибо тебе, добрый человек-препод) классный код подсказал с заменой значений на медианы, подобранные по нескольким признакам с помощью метода transform. Я с помощью этой штуки меняла значения в income_type.","[{'name': '+1', 'users': ['U01C12G0QNL', 'U01BB72RSH0', 'U01BB74F8GJ', 'U0185Q2MK19', 'U01C12DM2BA'], 'count': 5}]",Юлия Филоненко
1602096382.154700,1602096382.154700,U01BBD8R6N7,Получение данных из таблицы crosstab.,,Даша Свечкина
1602096382.154700,1602096497.154800,U01BBD8R6N7,"Я сделала сводную таблицу через crosstab: df_1 = pd.crosstab( df['debt'], df['family_status']). Получила результат как на картинке. Как мне строку debt 0 разделить на debt 1?",,Даша Свечкина
1602064900.142400,1602102627.155200,U01BB74F8GJ,"<@U01C12DM2BA> ты не один, я тоже испытываю трудности перед посадкой за проект, не уверен, что делаю достаточно для анализа и что вижу все, что должен увидеть, а также, что правильно обосновываю те или иные решения при работе с дата-сетом.","[{'name': 'cat-high-five', 'users': ['U01B84HU32R', 'U019HNXQEA1'], 'count': 2}, {'name': 'handshake', 'users': ['U01C12DM2BA'], 'count': 1}]",Митя Журавлев
1602064900.142400,1602103370.155600,U01C12H8HJL,<@U01BB74F8GJ>  ̶Н̶а̶с̶ ̶т̶к̶н̶у̶т̶ ̶м̶о̶р̶д̶о̶й̶ ̶в̶ ̶т̶а̶п̶к̶и̶  нам помогут увидеть ревьюеры!,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Юлия Филоненко
1602109401.156000,1602109401.156000,U01B84HU32R,Вопрос по замене типа данных в таблице,,Виктория Онучина
1602109401.156000,1602109467.156100,U01B84HU32R,"<@U0185Q2MK19> привет! Я тут пока делала замену пропусков в таблицах уже изменила тип данных на целочисленные. Если укажу это просто в пункте с заменой пропусков, то это будет засчитываться? Или нужно делать все поэтапно в идеале?",,Виктория Онучина
1601471861.031700,1602120800.156600,U01B84HU32R,"<@U0185Q2MK19> привет! Я тут пытаюсь разобраться в твоем коде с transform или найти информацию для чайников о функции в интернете, но все же есть вопросы.
Правильно я понимаю: функция берет наш df и определенный столбец, потом группирует этот столбец относительно другого столбца (или как правильно происходит), а после считает медиану и вставляет в пропуски?
Хочу углубиться, так как использовать функцию вслепую такое себе, не понимаю до конца последовательность. Возможно я слишком углубляюсь.. :baby-yoda-soup:",,Виктория Онучина
1602109401.156000,1602131600.156900,U0185Q2MK19,"<@U01B84HU32R>, привет!

Ничего страшного.
Но лучше структурировать работу согласно условию, чтобы ревьюерам было легче проверять и оставлять свои замечания, не перескакивая с блока на блок",,Олег Булыгин
1601471861.031700,1602131858.157100,U0185Q2MK19,"<@U01B84HU32R>, привет!
Вот тут есть хорошее объяснение: <https://pbpython.com/pandas_transform.html>
Функция transform сама по себе возвращает датафрейм с размерностью равной размерности исходного, но при этом делает какие-либо агрегированные вычисления (например, в рамках группировки)",,Олег Булыгин
1602096382.154700,1602132954.157500,U0185Q2MK19,"<@U01BBD8R6N7>, привет!

При помощи loc/iloc. Например, так:
```df_1.loc['%'] = df_1.iloc[0] / df_1.iloc[1]```
",,Олег Булыгин
1602096382.154700,1602135623.157800,U01B4EYRJ5U,"а можно просто поменять местами debt и family_status, и тогда debt станет столбцами и к ним применять деление","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Ольга Соколовская
1601471861.031700,1602143405.158100,U01B84HU32R,"<@U0185Q2MK19> спасибо, буду напрягать все свои знания английского и изучу материал :cattyping:","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1602153631.159000,1602153631.159000,U01AWENQ0R5,Ошибка в лемматизации,"[{'name': 'heavy_check_mark', 'users': ['U01AWENQ0R5'], 'count': 1}]",Volkhin Roman
1602153631.159000,1602153658.159100,U01AWENQ0R5,"<@U0185Q2MK19>, привет, подскажи, пожалуйста, где может быть ошибка? <https://pastebin.com/6RYD4MB2>",,Volkhin Roman
1602153631.159000,1602153712.159300,U01AWENQ0R5,"<@U0185Q2MK19> после данного кода при принте первых пяти строк, во второй строке выходит не верная инфа, не могу понять, как так",,Volkhin Roman
1602157427.160400,1602157427.160400,U01BPRKQP9P,"Вопрос по определению папки, в которой хранятся файлы",,Никита Коптелов
1602157427.160400,1602157589.160500,U01BPRKQP9P,"<@U0185Q2MK19>Добрый день! Пришлось перейти с локального юпитера на тот, что встроен в тренажёр практикума, потому что в локальном не выполнялся процесс лемматизации. Как определить папку, в которую сохраняются ipynb файлы из тренажёра, чтобы не переоформлять проект вручную, а просто открыть часть наработок в тренажёре?",,Никита Коптелов
1602064900.142400,1602158325.160800,U0185Q2MK19,"Коллеги, вам еще предстоит много проектов, а такую стену нужно пробить всего 1 раз)
Главное начать, а потом даже не будете стопориться перед выполнением)","[{'name': 'happy-cat', 'users': ['U01C12H8HJL', 'U019HNXQEA1', 'U01BBD8R6N7'], 'count': 3}]",Олег Булыгин
1602153631.159000,1602158469.161300,U0185Q2MK19,"<@U01AWENQ0R5>,
``` if 'жилье' or 'недвижимость' in lst:   
     return 'недвижимость'```
вот так условия писать нельзя в python.
Надо `if 'жилье' in lst or 'недвижимость' in lst: ...`
Отпишись, исправило ли это проблему)",,Олег Булыгин
1602157427.160400,1602158715.161500,U0185Q2MK19,"<@U01BPRKQP9P>, привет!

На счет лемматизации: кеширование обычно помогает, если проблема в том, что она исполняется жутко долго:  <https://stackoverflow.com/questions/16181419/is-it-possible-to-speed-up-wordnet-lemmatizer>

На счет пути - возможно, я не совсем понял вопрос, но нажми на лого Jupyter (слева сверху)  в открытом ноутбуке и перейдешь в папку хранения файлов. Там можно просто нажать Upload и загрузить свой.
А пути до файлов с данными указаны в описании проекта.

Это то, что нужно?","[{'name': 'heavy_check_mark', 'users': ['U01BPRKQP9P'], 'count': 1}]",Олег Булыгин
1602157427.160400,1602158981.161900,U01BPRKQP9P,"<@U0185Q2MK19> Да, спасибо, с upload разобрался. Но мой вопрос заключался немного в другом. Как узнать путь файла ipynb, сохранённого в тренажёре. Иными словами где этот файл на компьютере искать? Или он где-то на сервере хранится?",,Никита Коптелов
1602157427.160400,1602159081.162200,U0185Q2MK19,"<@U01BPRKQP9P>, он хранится на сервере, не на компе)
Можно его скачать на комп, зайдя в нотбук меню File -&gt; Download as...","[{'name': 'heavy_check_mark', 'users': ['U01BPRKQP9P'], 'count': 1}]",Олег Булыгин
1602157427.160400,1602159184.162500,U01BPRKQP9P,<@U0185Q2MK19> спасибо большое!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Никита Коптелов
1602096382.154700,1602164967.163000,U01BBD8R6N7,"<@U0185Q2MK19> Спасибо! Когда сама пыталась через loc, ничего не получилось","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Даша Свечкина
1602166742.164000,1602166742.164000,U01B84HU32R,Вопрос об удалении строчек в таблице,,Виктория Онучина
1602166742.164000,1602166822.164100,U01B84HU32R,"Всем привет! <@U0185Q2MK19>
Столкнулась с тем, что хочу удалить всю строчку таблицы, которая содержит определенное значение по определенному столбцу. Но нет идей как, совсем потерялась. Может кто даст подсказочку, но не готовый код. Может где-то в курсе было такое, но я не нашла..",,Виктория Онучина
1602166742.164000,1602167761.170200,U01BPRN9VCH,"Самое простое-через .drop(), он удаляет строку. Укажи в каком столбце и по какому слову/значению будет удалять ",,Анна Шлёнская
1602166742.164000,1602167805.170400,U01B84HU32R,"<@U01BPRN9VCH> спасибо! Я вот как раз об этом методе думала, надо пораскинуть как все записать правильно",,Виктория Онучина
1602166742.164000,1602168242.172700,U01BPRN9VCH,"У тебя должна получится команда
Из базы данных удали мне (из [‘столбца такого то’] все строчки, которые равны ‘такому то значению’)
Это если объяснять без кода :sweat_smile:",,Анна Шлёнская
1602166742.164000,1602168380.172900,U01B84HU32R,"<@U01BPRN9VCH> ахаха да, это понимаю, но еще иногда путаюсь когда использовать (), когда [], когда нужны '', а когда нет ахах. Но ничего, разберусь!",,Виктория Онучина
1602166742.164000,1602169819.173200,U01BPRKQP9P,"<@U01B84HU32R> Привет, здесь уже был ответ на этот вопрос. Не забудь при удалении обновить индексы строк. <https://yandex-students.slack.com/archives/G01B461LV0E/p1601648019075300?thread_ts=1601630601.063600&amp;cid=G01B461LV0E>","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Никита Коптелов
1602166742.164000,1602169873.173600,U01B84HU32R,"<@U01BPRKQP9P> вот это я слепая, спасибо! :porg:","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1602170429.173900,1602170429.173900,U01BBD8R6N7,pivot_table,,Даша Свечкина
1602170429.173900,1602170570.174000,U01BBD8R6N7,"Ребята, как построить сводную таблицу через пивот тэйбл как на картинке.  df.pivot_table(values = ""debt"",  index = ""children_category"", aggfunc=['count'])  - у меня выводит только общую сумму значений и не разбивает ее по категориям ""есть долг"", ""нет долга""",,Даша Свечкина
1602170429.173900,1602170730.174300,U01BHCPPL2Y,"порядок передаваемых аргументов имеет значение, передавай как в методичке - index, columns, values, aggfuc и тогда всё получится:+1:",,Me_
1602170429.173900,1602170979.174500,U01BBD8R6N7,<@U01BHCPPL2Y> я вот сейчас попробовала и результат не поменялся. Я же указываею именованные аргументы и их позиция не должна по идее иметь значение.,,Даша Свечкина
1602166742.164000,1602171175.175500,U01BPRN9VCH,"<@U01B84HU32R> Прости, объяснялкин из меня такой себе:joy:",,Анна Шлёнская
1602170429.173900,1602171507.175700,U01BHCPPL2Y,"точно, прошу прощения, упустил из виду что аргументы именованные, подумал что при перестановке применяются значения по умолчанию)",,Me_
1602170429.173900,1602171541.175900,U01BHCPPL2Y,"но у тебя нет аргумента ""columns"" - добавь его и тогда будет счастье)",,Me_
1602064900.142400,1602172619.176100,U01C12DM2BA,"После первичного осмотра таблицы с info() и describe(), выявил что
 В столбцах children и days_employed наблюдаются отрицательные значения, нужно будет взять их по модулю. 
 Count столбца days_employed меньше, чем все остальные (кроме total_income), а значит есть пропущенные значения. 
 В столбце dob_years еcть нулевые значения, которые можно заменить на среднее mean.
 В столбце education есть значения с верхним регистром, нужно будет привести всех к нижнему.
1.  Насчет отрицательных значений мне нужно изменить данные в имеющимся столбце или создать новый и добавить данные с abs()?
2. применив df.isnull().sum() получаем что в столбцах days_employed и total_income по 2174 пропусков, я просто меняю их на нули через df = df.fillna(0) , а потом на среднее значение?
3. Я прочитал инфу про метод transfrom в тредах, но все равно не пойму как его применить.
4. Подсчет дубликатов произвел так df.duplicated().sum(), выходит 54, после df.drop_duplicated().reset_index(drop=True) все равно df.duplicated().sum() = 54, почему?
5. Насчет категорий, мне в голову приходит только категоризировать по возрасту, больше ничего не надо?
6. Не понимаю зачем выделять леммы в столбце с целями получения кредита.",,Фарид Бабаев
1602153631.159000,1602176617.176300,U01AWENQ0R5,"<@U0185Q2MK19> да, что-то я проглядел этот момент. Помогло, спасибо","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Volkhin Roman
1602170429.173900,1602178968.176600,U01BBD8R6N7,"<@U01BHCPPL2Y> А что в данном случае должно быть в columns? Если добавляю debt, возникает ошибка",,Даша Свечкина
1602170429.173900,1602179146.176800,U01BHCPPL2Y,"Я уже на проверку отправил, посмотреть не могу :( один и тот же столбец не добавляй (само собой будет ошибка), поставь эксперимент) я посчитал оплаты (debt) в разрезе количества детей и целей на кредит, debt я суммировал","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Me_
1602170429.173900,1602179511.177000,U01BBD8R6N7,"<@U01BHCPPL2Y> Окей, получилось, спасибо)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Даша Свечкина
1602064900.142400,1602184964.177200,U01C12H8HJL,"<@U01C12DM2BA> пока Олег не на связи, я вставлю свои дружеские 5 копеек:
2. Я в days_employed поставила вместо пропусков 0, потому что минусовые значения могут значить что угодно: от технической ошибки до безработных дней. Кто-то менял на среднее значение по столбцу, а кто-то переводил в целочислтельные минуты, часы или дни. Тебе нужно принять решение и обосновать его в тексте, чтобы ревьюеры поняли.
3) Transform я применила к total_income (без предварительной замены нулями). Вот так:
df['total_income'] = df['total_income'].fillna(df.groupby('income_type')['total_income'].transform('median'))
там где я указала 'income_type' ты можешь применить любую другую величину, по которой хочешь найти среднее или медианное значение. Например, вдруг ты думаешь, что средний доход зависит от возраста или от семейного положения (и т.д.).
4) возможно ты не пересохранил таблицу после удаления дубликатов
5) отлично категоризируется еще доход  и наличие детей. Надо или нет опять же решать и объяснять тебе
6) С помощью выделения лемм как раз категоризируются цели

Надеюсь, я тебе хоть немного помогла","[{'name': 'handshake', 'users': ['U01C12DM2BA', 'U01BBD50335'], 'count': 2}]",Юлия Филоненко
1602064900.142400,1602193622.177600,U01B84HU32R,"Я тоже свои 5 копеек вставлю. Пища для размышления)) <@U01C12DM2BA> 
1/2. Я столбец с отрицательными (который стаж в днях) удалила, зачем он? Для ответы на вопросы он не требуется, лишняя работа. Также удалила неправильное в возрасте, там суммарно 150 строк, на фоне 20к не принесет большого изменения. Можно также оставить, но там уже тебе думать, как их менять. 
3. Там кидал Олег статью, я в английском не сильна, но что-то понять можно. 
4. drop_duplicateS. Вот он и ругает)
5. Ответить не могу, пока что не задумывалась об этом (видимо это категоризация данных)
6. Для удобства отвечать на следующий вопрос: связь цели и возврата кредита вовремя. Там некоторые повторяются, но смысл один: свадьба, организация свадьбы, празднование свадьбы.","[{'name': 'handshake', 'users': ['U01C12DM2BA', 'U01C12H8HJL'], 'count': 2}]",Виктория Онучина
1602064900.142400,1602224758.178700,U0185Q2MK19,"Виктория и Юлия дали очень хорошую рекомендации по всем вопросам :slightly_smiling_face:

<@U01C12DM2BA>, отпишись, какие еще вопросы или проблемы остались)",,Олег Булыгин
1602316155.181400,1602316155.181400,U01B4EXCR7G,Как указать путь к файлу в тренажере Jupiter,,Сергей Саранцев
1602316155.181400,1602316222.181500,U01B4EXCR7G,Подскажите как указать путь к датасету в команде pd.read_csv(…) из тренажера Jupiter,,Сергей Саранцев
1602064900.142400,1602316563.181800,U01C12DM2BA,"<@U0185Q2MK19> Так, следующая остановка ~тленность бытья~ лемматизация. Я вроде бы как удалил все пропуски и дубликаты. Получил список с леммами из столбца purpose. Я так понимаю нужно категоризировать через функцию по ключевым словам и заменить данные в таблице?",,Фарид Бабаев
1602316155.181400,1602317295.182000,U01BB72P2HG,"<@U01B4EXCR7G> если делаешь у себя на компьютере, то надо скачать датасет на комп и в скобках указать адрес к файлу именно на твоем компе:slightly_smiling_face:  если делаешь на платформе, то '/datasets/data.csv'",,Мария Пименова
1602316155.181400,1602317504.182200,U01B4EXCR7G,"<@U01BB72P2HG> У меня мак, поэтому не понимаю с какого раздела начинать путь. С:\ не катит...",,Сергей Саранцев
1602316155.181400,1602317721.182400,U01BB72P2HG,"<@U01B4EXCR7G> у меня не мак, поэтому не знаю как там правильно, но я на винде не писала диск, писала начиная с /Users",,Мария Пименова
1602316155.181400,1602318057.182600,U01B4EXCR7G,"<@U01BB72P2HG> Спасибо за помощь. Да, в итоге df = pd.read_csv(‘/datasets/data.csv’) на платформе помогло. Видимо с платформы  открыть локальный файл было плохой идеей -)","[{'name': 'sunny', 'users': ['U01BB72P2HG'], 'count': 1}]",Сергей Саранцев
1602316155.181400,1602323400.183000,U0185Q2MK19,"<@U01B4EXCR7G>, да платформа развернуто на сервере и все файлы находятся там же. Она не прочитает ваши локальные файлы)","[{'name': '+1', 'users': ['U01B4EXCR7G'], 'count': 1}]",Олег Булыгин
1602064900.142400,1602323575.183500,U0185Q2MK19,"<@U01C12DM2BA>, все верно, каждой заявке нужно присвоить конкретную категорию. Это удобно будет через написание функции с условиями.
Заменять данные не обязательно, можно просто добавить новый столбец.
Вот в этом треде сможешь найти подсказки по реализации: <https://yandex-students.slack.com/archives/G01B461LV0E/p1602153631159000>",,Олег Булыгин
1602064900.142400,1602334568.183800,U01C12DM2BA,"<@U0185Q2MK19> Почему у меня выходят значения NaN? Кроме того, я не понимаю  что мне добавить в аргументы df.pivot_table, чтобы рассчитывать то что мне нужно (например связь между наличием детей и долгами)",,Фарид Бабаев
1602064900.142400,1602334869.184100,U01B84HU32R,"<@U01C12DM2BA> привет! Я тут опять влезу)
Ты смотрел от Глеба вебинар? Мне кажется, что там была предложена крутая идея для того, чтобы оценить зависимость через groupby. Это примерно 30-я минута вебинара и дальше, точно уже не скажу. Может чем-то поможет :baby-yoda-soup:
Просто на скрине ты рассчитываешь связь количества детей и вида деятельности, а такого на моей памяти нет в задании","[{'name': '+1', 'users': ['U01C12DM2BA'], 'count': 1}]",Виктория Онучина
1602064900.142400,1602334891.184300,U01B84HU32R,"Я не знаю насколько корректно использовать через groupby, может Олег чего подскажет ещё)","[{'name': '+1', 'users': ['U01C12DM2BA'], 'count': 1}]",Виктория Онучина
1602064900.142400,1602334973.184700,U01C12H8HJL,"<@U01B84HU32R> ой, я что-то пропустила? Или ты про вебинар Паши?",,Юлия Филоненко
1602064900.142400,1602335124.184900,U01B84HU32R,"<@U01C12H8HJL> не, я именно о вебинаре Глеба, который был когда-то там рано утром, а у меня только руки дошли смотреть. Там был вот такой метод группировки для просмотра процентов должников. Мне кажется, что интересная штука и ее можно как-то по дсебя подстроить, я правда еще не экспериментировала",,Виктория Онучина
1602064900.142400,1602335203.185400,U01B84HU32R,"<@U01C12H8HJL> вебинар от Глеба, а не Олега... все, я уже в именах кураторов, наставников и прочих путаюсь :catshake:",,Виктория Онучина
1602064900.142400,1602335640.185600,U01C12H8HJL,"<@U01B84HU32R> да я не лучше, у меня Глеб в Пашу превратился :joy::joy::joy:",,Юлия Филоненко
1602337715.185900,1602337715.185900,U01B84HU32R,Вопрос по категоризации данных,,Виктория Онучина
1602337715.185900,1602337825.186000,U01B84HU32R,"<@U0185Q2MK19> и все остальные, привет! Не совсем понимаю, что требуют в этой части. В чек-листе нужно категоризировать и объяснить почему именно так. Как понимаю категоризировать - это сгруппировать по определенным значениям, которые считаю важными? Однако в шагах перед выполнением проекта в категоризации указано перечислить словари, которые я выбрала.. И я совсем запуталась. Что же все же надо.",,Виктория Онучина
1602337715.185900,1602338478.186200,U01BB72P2HG,"<@U01B84HU32R> почитай в описании проекта на какие вопросы мы будем отвечать после обработки данных, они помогут сориентироваться, какие категории тебе будут нужны:slightly_smiling_face:",,Мария Пименова
1602337715.185900,1602339476.189000,U01AWENRANB,"<@U01B84HU32R> привет, надо как бы упростить таблицу, убрав часто повторяющиеся и сложные в написании столбцы условными обозначениями, в примере id. Таблица в которой будет указано соответствие значения и условного обозначения будет словарем",,Ксения Ушакова
1602337715.185900,1602339760.189200,U01B84HU32R,Всем спасибо!,,Виктория Онучина
1602337715.185900,1602340430.189400,U01AWENQ0R5,"<@U01B84HU32R> я просто разбил доход и возраст на категории, например низкий, средний доход и тд.",,Volkhin Roman
1602337715.185900,1602345848.189600,U01BPRKQP9P,"<@U01B84HU32R> я категоризовал доход и количество детей. небольшая подсказка: для категоризации по кол-ву детей неплохо бы написать функцию, а для группировки по доходу отлично подойдёт метод qcut (смотри вебинар Глеба)",,Никита Коптелов
1602337715.185900,1602345911.190000,U01B84HU32R,"<@U01BPRKQP9P> да, по функции уже примерно поняла, подумала об этом. Про qcut тоже видела, слишком муторно правда, нужно сесть",,Виктория Онучина
1602337715.185900,1602346597.190200,U01BB74CMMG,"<@U01B84HU32R> Дело не в упрощении таблиц и т.д. Суть в составлении справочников(словарей). Например, справочник городов, справочник профессий, категорий магазинов и т.д. - Повторяющиеся, часто использупмые данные. Нужны для оптимизации архитектуры данных, скорости обработки и уменьшения их объема. Т.к. выделив справочники, мы не дублируем их в других таблицах, а используем индексы(идентификаторы записей справочников). Вот это в практикуме называют катеогорированием... Не пойму почему правда :grinning: ...",,Антон Дмитриев
1602337715.185900,1602346847.190500,U01B84HU32R,"<@U01BB74CMMG> теперь ещё больше запуталась))
Подожду что ещё Олег ответит",,Виктория Онучина
1602337715.185900,1602347015.190700,U01BB72P2HG,"<@U01B84HU32R> самый простой пример тут это распределить клиентов по уровню дохода) потом есть столбец с указанием целей на кредит, там черт ногу сломит:joy:  но после проведения лемматизации(этот пункт есть в инструкции пошаговой к проекту), становится понятно, что цели можно и нужно разбить на категории) а вообще если захотеть, там все можно на категории разбить))) вопрос, какие нам нужны конкретно для этого исследования и ответов на вопросы:wink:",,Мария Пименова
1602337715.185900,1602347182.190900,U01BB74CMMG,"Сейчас Вика еще больше запутается, пошлет всех и бросит учебу :grinning:",,Антон Дмитриев
1602337715.185900,1602347279.191100,U01B84HU32R,"<@U01BB72P2HG> ну, в лемматизации уже все сделано, там теперь лишь несколько категорий: недвижимость, автомобиль, свадьба и образование. Доход и так и так сортировать, иначе не вопрос не ответить.... Надо ещё детей тогда отсортировать)) 
При ответе на вопрос просто дети от 1 до 5 тоже удобны в рассмотрении, поэтому... Точно ли так надо их трогать)",,Виктория Онучина
1602337715.185900,1602347309.191300,U01B84HU32R,"<@U01BB74CMMG> да не, я не такая, не знаю с чего решил)) 
Просто углубляюсь, чтобы в будущем знать что да как",,Виктория Онучина
1601827769.103300,1602359278.191600,U01BB74F8GJ,"<@U0185Q2MK19>, подскажи, пожалуйста, почему `df['lemmas'] = df.purpose.apply(m.lemmatize)` purpose не в квадратных скобках, а с точками? Мы же apply применяем к столбцу датафрейма вроде как",,Митя Журавлев
1602395856.192000,1602395856.192000,U01B4EXCR7G,Вопрос о способах создания оглавления,,Сергей Саранцев
1602395856.192000,1602395906.192100,U01B4EXCR7G,"Друзья, подскажи пожалуйста кто и как создавал оглавление в проекте. Есть ли способы автоматического создания по уровням заголовков в тексте проекта?",,Сергей Саранцев
1602064900.142400,1602396388.193600,U0185Q2MK19,"<@U01C12DM2BA>, NaN  у тебя появляется потому, что таких записях в данных просто нет. То есть многодетных безработных в данных просто нету (если все остальное сделано правильно). Чтобы убрать эти NaN можно использовать параметр fill_value. Вот здесь подробнее: <https://stackoverflow.com/questions/39632277/pandas-nan-introduced-by-pivot-table>

Также убедись, что до этого действия решена проблема с отсутствующими значениями.

На счет использования самой функции - для аналитики по двум критериям лучше правда использовать groupby.",,Олег Булыгин
1602395856.192000,1602396459.195400,U01AWENRANB,"Привет,
я делала через якоря вручную, по этому же принципу в html оглавления строятся вроде, про автоматические я даже как то не задумалась :sweat_smile:
#step1
&lt;a name=“step1”&gt;&lt;/a&gt;
","[{'name': 'ok_hand', 'users': ['U01BB72RSH0', 'U01B4EXCR7G'], 'count': 2}]",Ксения Ушакова
1602064900.142400,1602396558.195700,U0185Q2MK19,"<@U01B84HU32R>, я бы тоже для таких задач предпочел использование `groupby`. На мой взгляд это проще и удобнее.

Но ревьюер в любом случае попросит вас в работе использовать pivot_table (не конкретно здесь, а вообще), чтобы убедиться, что вы умеете пользоваться этой функцией.",,Олег Булыгин
1602337715.185900,1602397397.196000,U0185Q2MK19,"<@U01B84HU32R>, категоризация нужна, чтобы сгруппировать признаки, которые принимать очень много значений, на разумное количество групп для упрощения анализа.
В нашей конкретной работе абсолютно точно нужно категоризовать цели кредита (при помощи лемматизации), также разумно будет категоризовать доходы. Может быть - количество детей.

Словарь тут скорее всего будет использоваться только при категоризации целей после шага лемматизации (через Counter) - просто для удобства.
Для простоты, чтобы не путаться в терминах скажу, что категоризация никакого отношения к словарям не имеет. Можно про словари в этом контексте не говорить. В условии подразумевается именно обоснование выбранных групп для категоризации.","[{'name': 'heavy_check_mark', 'users': ['U01B84HU32R'], 'count': 1}]",Олег Булыгин
1601827769.103300,1602398124.196300,U0185Q2MK19,"<@U01BB74F8GJ>, это абсолютно аналогичные действия :slightly_smiling_face:
К столбцу можно обратиться и так: `df['purpose']` и так `df.purpose`
У второго способа есть некоторые ограничения, но в целом это одно и то же)",,Олег Булыгин
1602395856.192000,1602398927.196600,U0185Q2MK19,"<@U01B4EXCR7G>, Ксения делает верно.
Автоматических способов создания оглавления лично я не знаю, думаю, есть какие-то дополнения для Jupyter, которые могут это упростить.  Например, нашел вот такое: <https://github.com/minrk/ipython_extensions>
Но не думаю, что сейчас надо в эту сторону смотреть.",,Олег Булыгин
1602400756.197100,1602400756.197100,U01C12DM2BA,Вопросы по выводам,,Фарид Бабаев
1602400756.197100,1602400908.197200,U01C12DM2BA,"<@U0185Q2MK19> Как мне правильно сгруппировать данные чтобы получить ответы на поставленные вопросы? `df.groupby('children_group')['debt'].count()`
вот например здесь что мне нужно изменить?Или мне нужно создать отдельную таблицу и только должников добавить?",,Фарид Бабаев
1602400756.197100,1602401574.197400,U0185Q2MK19,"Данное действие вполне полноценно отвечает на вопрос о том, как часто берут кредит люди с разным количеством детей :slightly_smiling_face:
Более интересно было бы посмотреть у кого больше долгов.
Для этого можно сделать так:

```df.groupby('children_group')['debt'].sum() / df.groupby('children_group')['debt'].count() * 100```
Так мы получим процент должников по каждой группе.

Еще можно получить пропорцию между должниками и теми, кто возвращает в срок.",,Олег Булыгин
1602406412.198400,1602406412.198400,U01B4EZSWHL,Вопрос по комментариям для ревьюера,,Лиза Толмачева
1602406412.198400,1602406466.198500,U01B4EZSWHL,"Ребят, добрый день) подскажите пожалуйста, как писать комментарии для ревьюера и выделять их каким-либо цветом?",,Лиза Толмачева
1602406412.198400,1602406650.198700,U01BB72P2HG,"<@U01B4EZSWHL> я делала новую ячейку для комментария, чтобы было удобно) и чтобы выделить цветом копировала кусок строки с таким выделением из первой ячейки, где ревьювер показал пример как это делать и заменяла на свой текст:slightly_smiling_face: чтобы скопировать текст надо на ячейку с примером нажать два раза, тогда там будут видны обозначения для выделения)",,Мария Пименова
1602406412.198400,1602406776.198900,U01C12G0QNL,"<@U01B4EZSWHL> Привет. Я делал так:
`&lt;h2&gt;&lt;span style='color:DarkCyan'&gt; Ответ на комментарий от ревьюера&lt;/span&gt;&lt;/h2&gt;`
`&lt;span style='color:DarkCyan'&gt;Текст комментария &lt;/span&gt;`","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Михаил Перцев
1602406412.198400,1602406829.199100,U01B4EZSWHL,"Хорошо, спасибо большое)",,Лиза Толмачева
1602406412.198400,1602407017.199300,U01BB72P2HG,"<@U01B4EZSWHL> выделить цветом: **&lt;font color=""orange""&gt;выделить цветом&lt;/font&gt;**
выделить жирным шрифтом: **жирным шрифтом**","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Мария Пименова
1602395856.192000,1602408020.199600,U01B4EXCR7G,"<@U01AWENRANB> Ксения, спасибо! Сделал как ты сказала и все получилось. Полный синтаксис вот такой:
#В оглавлении
[Описание данных проекта]#mark1
#В тексте
Описание данных проекта &lt;a name=“mark1”&gt;&lt;/a&gt;",,Сергей Саранцев
1602064900.142400,1602414786.200000,U01B84HU32R,"<@U0185Q2MK19> да, я прочитала потом об этом в каком-то из трейдов, поэтому сделала и так и так)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1602438822.200800,1602438822.200800,U01C12GJCGY,вопрос по установке jupyter,,Миронов Владислав
1602438822.200800,1602438952.200900,U01C12GJCGY,"<@U0185Q2MK19> добрый вечер, не получается установить jupyter, анаконда не запускает его, может есть какие то способы установить по другому?",,Миронов Владислав
1602452172.201600,1602452172.201600,U01C12ESRAL,Вопрос по установке pymystem3,,Науменко Марина
1602452172.201600,1602453079.201700,U01C12ESRAL,"<@U0185Q2MK19> добрый вечер, не получается установить пакет на свой компьютер. Делаю pip install pymystem3. Выдает ошибку <http://joxi.ru/Q2KwEMGsvbWw62|http://joxi.ru/Q2KwEMGsvbWw62>
Прошу помочь",,Науменко Марина
1602452172.201600,1602453968.202000,U01BPRKQP9P,"<@U01C12ESRAL> Добрый. Для того чтобы установить эту библиотеку и пользоваться ей в jupyter достаточно открыть сам jupyter и в первой ячейке прописать  `!pip install ИМЯ_БИБЛИОТЕКИ -U` . В нашем случае это будет выглядеть как: `!pip install pymystem3 -U` . Библиотека установиться и ты сможешь использовать её в jupyter. Что касается установки на компьютер и использования библиотеки в другой среде, попробуй написать `pip3 install ИМЯ БИБЛИОТЕКИ`  в командной строке",,Никита Коптелов
1602452172.201600,1602455012.202300,U01C12ESRAL,<@U01BPRKQP9P> у меня и jupyter такую же ошибка выводит <https://joxi.net/ZrJPOzEinl8LV2|https://joxi.net/ZrJPOzEinl8LV2>,,Науменко Марина
1602452172.201600,1602455336.202600,U01BPRKQP9P,"<@U01C12ESRAL> Рита скидывала в канал info ссылку на вспомогательные материалы в notion. Вот она: <https://www.notion.so/DA-f423ba820ae147789815bee6556801f8>. Вход по логину и паролю от практикума. Там есть разделы по установке jupyter и окружения во избежании конфликта версий библиотек. Возможно, стоит как раз таки настройку с окружением осуществить. Там всё достаточно подробно описано",,Никита Коптелов
1602452172.201600,1602455628.203000,U01BPRKQP9P,"<@U01C12ESRAL> Ещё есть мысль, что при установке python, не был установлен pip и в связи с этим не получается установить библиотеку:thinking_face:",,Никита Коптелов
1602438822.200800,1602475818.203200,U0185Q2MK19,"<@U01C12GJCGY>, jupyter можно установить без anaconda, но я бы не рекомендовал.

Надо понимать, в чем именно проблема, какая ошибка возникает, какой способ запуска используется. Jupyter можно запускать очень по-разному :slightly_smiling_face:",,Олег Булыгин
1602452172.201600,1602476978.203400,U0185Q2MK19,"Поддержку Никиту в рекомендациях.

Надо попробовать обновить pip и заново установить библиотеку. Если не получится - устанавливать Juyter и окружение по инструкции.",,Олег Булыгин
1602495071.204300,1602495071.204300,U019HNXQEA1,Вопрос по умножению,,Жуган Артём
1602495071.204300,1602495130.204400,U019HNXQEA1,"как мне умножить правильно значение ""mean"" на 100?
Как бы не экспериментировал, вылезает всё время ошибка :c",,Жуган Артём
1602495071.204300,1602496603.205100,U01BHCRMNGL,"можно попробовать поменять формат отображения, используя style:
status_pivot.style.format({'% невозврата': '{:.2%}'})

описание: <https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html>",,Дарья Баранкова
1602495071.204300,1602496739.205300,U019HNXQEA1,А проще точно нет способов?:grin:,,Жуган Артём
1602495071.204300,1602496754.205500,U019HNXQEA1,<@U01BHCRMNGL> как вариант :),,Жуган Артём
1602438822.200800,1602496788.205700,U01C12GJCGY,"<@U0185Q2MK19> пытался в командной строке выполнить команду jupyter notebook, также не открывался,  также копировал URL чтобы открыть в браузере, открывается но запрашивает пароль, устанавливал все по инструкции, что может быть не так?",,Миронов Владислав
1602438822.200800,1602505803.205900,U0185Q2MK19,"<@U01C12GJCGY>, почти уверен, что проблема в браузере/его настройках. Предлагаю попробовать другой, убедившись, что в системе он указан, как браузер по-умолчанию.
А до этого можно будет все открыть, если в поле token ввести то, что указано в консоли при запуске (там рядом с URL прямо по слову token можно найти ключ). После го ввода все должно открыться",,Олег Булыгин
1602495071.204300,1602505925.206100,U0185Q2MK19,"Можно же обратиться к столбцу `% невозврата` в *status_pivot* и просто умножить его на 100 :slightly_smiling_face:
```status_pivot['% невозврата'] = status_pivot['% невозврата'] * 100```",,Олег Булыгин
1602495071.204300,1602506541.206300,U019HNXQEA1,<@U0185Q2MK19> благодарствую :),"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Жуган Артём
1602452172.201600,1602517099.206600,U01C12ESRAL,"<@U0185Q2MK19> <@U01BPRKQP9P> спасибо большое, все получилось! Обновила pip (оказывается был старой версии) а дальше и библиотека удачно установилась )","[{'name': 'cat-high-five', 'users': ['U01BPRKQP9P', 'U0185Q2MK19'], 'count': 2}]",Науменко Марина
1602337715.185900,1602598027.207500,U017YK5MKJ9,<@U01AWENQ0R5> а по какому принципу разделял доходы на категории? Как определял уровень отсечения для низкого и для высокого дохода?,,Елена Помыкалова
1602337715.185900,1602599723.207700,U01AWENQ0R5,"<@U017YK5MKJ9> просто на свое усмотрение, первая группа до 100к, далее с шагом 50к",,Volkhin Roman
1602337715.185900,1602599795.207900,U017YK5MKJ9,<@U01AWENQ0R5> :thank_you:,,Елена Помыкалова
1602337715.185900,1602601567.208100,U0185Q2MK19,"<@U017YK5MKJ9>, еще один хороший вариант для категоризации - использовать квантили",,Олег Булыгин
1602337715.185900,1602601658.208300,U01BB74CMMG,Describe! :smile:,,Антон Дмитриев
1602337715.185900,1602601793.208500,U017YK5MKJ9,"<@U0185Q2MK19>, а у нас же квантили только сейчас начались, т.е. после первого проекта. Или я путаю?",,Елена Помыкалова
1602337715.185900,1602602041.208700,U01BB74CMMG,"Верно, но ничего не останавливает их использовать и в 1ом :grinning:",,Антон Дмитриев
1602337715.185900,1602602093.208900,U0185Q2MK19,"Конечно)
Их позволяет посмотреть метод describe, который упомянул Антон, это вообще незаменимый метод для знакомства с данными, рекомендую его применять всегда)",,Олег Булыгин
1602337715.185900,1602602107.209200,U017YK5MKJ9,<@U01BB74CMMG> тоже верно.,,Елена Помыкалова
1602337715.185900,1602602117.209400,U017YK5MKJ9,"<@U0185Q2MK19>, спасибо","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Елена Помыкалова
1602608911.210100,1602608911.210100,U01BB73EL10,Вопрос по расчету средних значений в зависимости от типа занятости,,Ksenia Varakina
1602608911.210100,1602608988.210200,U01BB73EL10,"Привет! В проекте для каждого типа занятости отдельно рассчитывала среднее значение стажа и ежемесячного дохода. И далее этими значениями последовательно заменяла NaN. Код-ревьюер попросил сделать это циклом, т.к. в реальной жизни групп может быть сотни. Но совсем не понимаю, как построить цикл(",,Ksenia Varakina
1602608911.210100,1602609576.210600,U01C12G0QNL,"<@U01BB73EL10> Привет. Не уверен, что использовать цикл для перебора df это хорошая идея. Можно написать функцию, которая будет возвращать среднее значение в зависимости от типа занятости и применить её через apply.",,Михаил Перцев
1602608911.210100,1602609663.210800,U01BPRKQP9P,"<@U01BB73EL10> Привет. Циклы во время работы с pandas лучше не использовать. Как нам рассказывали - это сжирает память и малоэффективно. На твой вопрос уже отвечали в треде выше. Для того, чтобы заполнить пропущенные значения по группам необходимо применить конструкцию, описанную здесь: <https://yandex-students.slack.com/archives/G01B461LV0E/p1601536444033400?thread_ts=1601471861.031700&amp;cid=G01B461LV0E>","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Никита Коптелов
1602608911.210100,1602611173.211100,U01BB73EL10,"спасибо, коллеги) пойду пробовать",,Ksenia Varakina
1602400756.197100,1602625448.211300,U01C12H8HJL,"<@U0185Q2MK19> , а как лучше наглядно изобразить эти пропорции (я про какие-нибудь графики или что-то подобное)? Или можно просто написать в выводе: ""Соотношение должников с детьми к заемщикам без долгов, но с детьми такое-то"". И то же самое написать в отношении категории заемщиков без детей?",,Юлия Филоненко
1602400756.197100,1602653536.211500,U0185Q2MK19,"<@U01C12H8HJL>, визуализации можно делать, главное, чтобы эти значения были рассчитаны в датафрейме. Ну и да, в выводе прокомментировать, есть ли какая-то разница между количество должников в разрезе групп.","[{'name': '+1', 'users': ['U01C12H8HJL'], 'count': 1}]",Олег Булыгин
1602608911.210100,1602653596.211800,U0185Q2MK19,"<@U01BB73EL10>, обязательно напиши, получилось ли)",,Олег Булыгин
1602608911.210100,1602667402.212100,U01BB73EL10,"<@U0185Q2MK19> да, получилось) Спасибо за помощь!","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Ksenia Varakina
1602751192.212900,1602751192.212900,U01B4EXCR7G,Вопрос по преобразованию object/string в date,,Сергей Саранцев
1602751192.212900,1602751247.213000,U01B4EXCR7G,Подскажите пожалуйста как преобразовать object/string вида “1 сентября 2020 г.” в формат datetime,,Сергей Саранцев
1602751192.212900,1602755591.213200,U01BHCPPL2Y,<https://stackoverflow.com/questions/466345/converting-string-into-datetime>,,Me_
1602751192.212900,1602758294.213500,U01B4EXCR7G,"<@U01BHCPPL2Y> Да, я видел эту справку, но все равно выдает ошибку <https://pastebin.com/q0RVQ4uy>",,Сергей Саранцев
1602751192.212900,1602758447.213700,U01BHCPPL2Y,"Ну так ошибка то здесь - *datetime.*datetime.strptime, раз ты сделал импорт *from datetime import datetime* то обращаться нужно напрямую к методу, без названия библиотеки (вот так - *datetime.strptime*)",,Me_
1602751192.212900,1602758576.213900,U01B4EXCR7G,"<@U01BHCPPL2Y> убрал, не помогает <https://pastebin.com/fdefy070>",,Сергей Саранцев
1602751192.212900,1602758881.214100,U01BHCPPL2Y,"Да, потому что эту функцию надо применить ко всем значениям, а у тебя в функцию передается последовательность элементов, а она умеет работать только с одним-единственным значением строки. Самый простой вариант - написать короткую функцию (либо лямбду) и применить её вот так: <https://pastebin.com/hGhhxnYr>",,Me_
1602751192.212900,1602758983.214300,U01BHCPPL2Y,"без отдельной функции - df['day'] = df['day'].apply(lambda x: datetime.strptime(x, '%d %B %Y'))",,Me_
1602751192.212900,1602759145.214500,U01B4EXCR7G,"<@U01BHCPPL2Y> А на вход именно df[’day].apply… или все же столбец с исходным значением подавать (df[‘day_of_время_создания_тикета’].apply…)?
Также выдает ошибку видимо из-за того, что в дате  есть ” г.” ValueError: time data ‘1 сентября 2020\xa0г.’ does not match format ‘%d %B %Y’",,Сергей Саранцев
1602751192.212900,1602759225.214800,U01BHCPPL2Y,конечный_результат = исходные_данные.apply(функция),,Me_
1602751192.212900,1602759247.215000,U01BHCPPL2Y,но есть вариант что питон может не знать русские названия месяцев,,Me_
1602751192.212900,1602759301.215200,U01BHCPPL2Y,тогда нужно сначала преобразовать все месяца в цифры (проще всего с помощью словаря) и после этого уже использовать strptime,,Me_
1602751192.212900,1602762365.215400,U0185Q2MK19,"datetime по-умолчанию не будет работать с русскоязычной локалью.

Вот тут есть примеры, как в такой ситуации быть: <https://ru.stackoverflow.com/questions/419321/%D0%9F%D1%80%D0%B5%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5-%D0%B4%D0%B0%D1%82%D1%8B-%D0%BC%D0%B5%D0%B6%D0%B4%D1%83-%D1%81%D1%82%D1%80%D0%BE%D0%BA%D0%BE%D0%B2%D1%8B%D0%BC%D0%B8-%D0%BF%D1%80%D0%B5%D0%B4%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D1%8F%D0%BC%D0%B8>","[{'name': '+1', 'users': ['U01B4EXCR7G'], 'count': 1}]",Олег Булыгин
1602778619.221000,1602778619.221000,U01BHCPKNG4,"Вопрос по подписям на графиках. 
<@U0185Q2MK19> Подскажи, возможно ли подписать оси и сам график, если я строила его так: df['total_income'].hist(bins=100)? Никак не могу найти...",,ElenaV
1602778619.221000,1602790770.221100,U01BB74F8GJ,"Лена, вот тут это обсуждалось
<https://app.slack.com/client/TPV9DP0N4/G01B7R0239B/thread/G01B7R0239B-1602534148.274000>",,Митя Журавлев
1602778619.221000,1602825149.221300,U0185Q2MK19,"<@U01BHCPKNG4>, привет!
Да, можно записать визуализацию в переменную,  а потом на нее вызывать функции:

```ax.set_xlabel(...)
ax.set_title(..)```
и пр.

Напиши, получилось ли)",,Олег Булыгин
1602778619.221000,1602829604.221500,U01BHCPKNG4,Большое всем спасибо. Получилось:happy-cat:,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",ElenaV
1602838305.222200,1602838305.222200,U01AWENRANB,Вопрос по исключаемым значениям,,Ксения Ушакова
1602838305.222200,1602838464.225100,U01AWENRANB,"Во втором проекте у многих параметров длинные хвосты, из задания не совсем поняла, бороться с этим надо в отношении всех таких параметров или только по времени продажи?",,Ксения Ушакова
1602838305.222200,1602845776.225500,U0185Q2MK19,"В задании есть пункт - *Уберите редкие и выбивающиеся значения. Опишите, какие особенности обнаружили.*

Надо по каждому конкретному столбцу смотреть по отдельности, что там за выбросы и что с ними делать :slightly_smiling_face:","[{'name': '+1', 'users': ['U01AWENRANB'], 'count': 1}]",Олег Булыгин
1602863940.226100,1602863940.226100,U01BBD8EYR1,Вопрос по замене пустых значений.,,Евгения Батухтина
1602863940.226100,1602864297.226200,U01BBD8EYR1,"Во втором проекте сказано, что можно в столбце с балконами заменить пропуски на нули. Но мне кажется, это не очень правильно. Я посмотрела на рапределение площадей квартир с балконами, без балконов, и там где вместо балкнов пропуски. Все распределения очень похожи между собой и по самой гистограмме, и по значениям. Просто так взять и заменить на ноль я не могу. Рука не поднимается. Может я конечно не самый правильный столбец выбрала, по какому распределение смотрела. Но если данные не заменять, тогда к этому столбцу нельзя применить смену типа данных.
<http://joxi.ru/zANPpzQijLZjJm>
<http://joxi.ru/8AnR5E3cy9RylA>
<http://joxi.ru/BA0Xn5aCp8VvvA>",,Евгения Батухтина
1602863940.226100,1602922512.226500,U0185Q2MK19,"<@U01BBD8EYR1> , привет!

А мы точно знаем, что указанная площадь включает балконы?) Если это не так, то на распределения смотреть нет смысла для ответа на этот вопрос.

Учитывая, что это архив объявлений Яндекс.Недвижимости, то вполне логично предположить, что если владелец не заполнил поле с балконами, то их нет (зачем ему скрывать их количество?)

Я бы тут не усложнял и произвел замену пропусков на 0.",,Олег Булыгин
1602863940.226100,1602927044.228500,U01BBD8EYR1,"<@U0185Q2MK19> я же смотрю по условию: есть балконы, нет балконов и неизвестно. Наверное, где отмечено наличие балконов, это уже точная информация)",,Евгения Батухтина
1602863940.226100,1602927591.228700,U0185Q2MK19,"Я немного не про то. Ты смотришь на распределение площадей. Если в указанные площади балконы не входят (указаны площади без их учёта, это вполне может быть),  то разница распределений нам ничего значимого не скажет",,Олег Булыгин
1602863940.226100,1602927927.232500,U01BBD8EYR1,"Я просто думала, что распределение площадей квартир с пропусками в балконах должно быть очень похоже на распределение площадей без балконов, тогда бы я была уверена, что да, действительно надо ставить ноль вместо пропусков. Но тут все распределения между собой похожи. Значит я либо не тот признак смотрю, либо наличие площадь квартиры не особо влияет на наличие балкона ",,Евгения Батухтина
1602863940.226100,1602942388.232800,U0185Q2MK19,"Я бы сказал, что именно второй вариант)
Не думаю, что в общем случае есть линейная зависимость между площадью квартиры и наличием балконов",,Олег Булыгин
1602863940.226100,1602962751.233100,U01BBD8EYR1,"Окей, не буду мудрить)",,Евгения Батухтина
1603021505.233800,1603021505.233800,U01C12G0QNL,Вопрос по отображению больших чисел на гистограмме.,"[{'name': 'heavy_check_mark', 'users': ['U01C12G0QNL'], 'count': 1}]",Михаил Перцев
1603021505.233800,1603021606.233900,U01C12G0QNL,"Всем привет.
<@U0185Q2MK19>, нужна твоя помощь. Пытаюсь построить гистограмму по столбцу ['last_price'], но все значения попадают в один столбец. Пробовал увеличить количество корзин до bins=100, но это не сильно помогло.
Мне кажется, такая гистограмма не очень информативна. Можно ли как-то настроить отображение больших чисел на гистограмме?",,Михаил Перцев
1603021505.233800,1603029838.235600,U01BB72MR6E," <@U01C12G0QNL> Я перевела в миллионы и сделала range, чтобы нагляднее было)","[{'name': '+1', 'users': ['U01C12G0QNL'], 'count': 1}]",Юлия Сова
1603021505.233800,1603033366.235800,U01C12G0QNL,"<@U01BB72MR6E> Спасибо ) Похоже, нужно чаще делать перерывы )",,Михаил Перцев
1603045894.237000,1603045894.237000,U01BBD8L1DZ,"""Выделите сегмент квартир в центре.""",,Екатерина Резанович
1603045894.237000,1603045902.237100,U01BBD8L1DZ,"""Выделите сегмент квартир в центре."" Проанализируйте эту территорию и изучите следующие параметры: площадь, цена, число комнат, высота потолков. Также выделите факторы, которые влияют на стоимость квартиры (число комнат, этаж, удалённость от центра, дата размещения объявления). Сделайте выводы. Отличаются ли они от общих выводов по всему городу?",,Екатерина Резанович
1603045894.237000,1603045962.237300,U01BBD8L1DZ,"<@U0185Q2MK19> Привет) имеется в виду Питер (исходя из предыдущего пункта) или все города (нелогично ввиду размера и получившейся центральной зоны по Питеру, но лучше уточню).",,Екатерина Резанович
1603021505.233800,1603082750.237500,U0185Q2MK19,"Да, это ведь просто из-за очень большого разброса значений и выбросов. Поэтому просто можно поменять порядок чисел)","[{'name': '+1', 'users': ['U01C12G0QNL'], 'count': 1}]",Олег Булыгин
1603045894.237000,1603083566.237700,U0185Q2MK19,"<@U01BBD8L1DZ>, привет!
Нужно изучить центр Питера и сравнить с общими данными по Питеру :slightly_smiling_face:",,Олег Булыгин
1603045894.237000,1603089013.238500,U01BBD8L1DZ,"Поняла, спасибо ))",,Екатерина Резанович
1603105216.239600,1603105216.239600,U01BBD8JS75,Замена пропусков жилой площади и площади кухни,,Алексей Глазов
1603105216.239600,1603106091.239800,U01BBD8JS75,кто чем заполнял эти пропуски?,,Алексей Глазов
1603105216.239600,1603106136.240000,U01BBD8JS75,Смотреть какую долю от общей площади занимают анализируемые площади и затем заполнять пропуски средним значением?,,Алексей Глазов
1603105216.239600,1603106196.240200,U01BBD8JS75,может кто придумал более элегантный маневр? В интернете нашел пример заполнения с помощью линейной регрессии,,Алексей Глазов
1603108164.241200,1603108164.241200,U01BPRN9VCH,Ошибка в построении boxplot,,Анна Шлёнская
1603108164.241200,1603108341.241700,U01BPRN9VCH,"Добрый день всем, может,кто знает, почему то, когда строю boxplot цены за кв метр от дня/месяца/года, вылезает непонятная ошибка, но сами графики строятся. Может я что не так делаю((",,Анна Шлёнская
1603105216.239600,1603108435.242000,U01BB72RSH0,"<@U01BBD8JS75>, я решил ничем не заполнять кроме случаев с балконами, водоемами и парками (в них NaN менял на 0). Те строки, где пропусков было в пределах 50-100 значений для столбца - удалял, если же пропусков было под 50 % - оставлял как есть, присваивая выпадам значения NaN. Решил в этом проекте делать так во многом для того, чтобы не искажать выводы по исследованию собственными допущениями. Семинар Глеба во многом подтвердил мои предположения:slightly_smiling_face:",,Шилоносов Артём
1603108489.242200,1603108489.242200,U01BHCRMNGL,Отображение таблицы в Jupyter,,Дарья Баранкова
1603108489.242200,1603108602.242300,U01BHCRMNGL,"Всем привет! Кто-нибудь знает, как в юпитере посмотреть таблицу целиком? Когда я вывожу таблицу содержащую например 300 строк он отображает несколько первых строк и несколько последних. Как быть, если я хочу посмотреть все 300 строк?",,Дарья Баранкова
1603108164.241200,1603109976.242500,U01AWENQ0R5,"<@U01BPRN9VCH> не знаю, но вижу, что у тебя  в конце нет закрывающей скобки, а после 10,10 две скобки вместо одной",,Volkhin Roman
1603108164.241200,1603110430.242700,U01BPRN9VCH,<@U01AWENQ0R5> но set_ylim пишется вне boxplot вроде :face_with_monocle:,,Анна Шлёнская
1603108164.241200,1603110647.242900,U01AWENQ0R5,"<@U01BPRN9VCH> тогда тем более не знаю :sweat_smile: наверно в set_ylim надо передать список [0, 200000]",,Volkhin Roman
1603108489.242200,1603113387.243200,U01BHCPLXHS,"Привет! stackoverflow такой способ подсказывает:
```pd.set_option('display.max_rows', 300)```
у меня так получилось вывести (<https://stackoverflow.com/questions/16424493/pandas-setting-no-of-max-rows>)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1603108489.242200,1603114102.243500,U01BHCRMNGL,"О, получилось)  <@U01BHCPLXHS> , спасибо!",,Дарья Баранкова
1603135390.244600,1603135390.244600,U01C12EF41E,Вопрос про аномальные выбросы,,Иван Гончаров
1603135390.244600,1603135860.244700,U01C12EF41E,"Подскажите пожалуйста, как удалить/убрать выбросы. К примеру в столбце с потолками, которые по 100м. Их надо заменить на среднее/медиану, это я понимаю, но для начала надо избавиться от выбросов. И вот тут я чет не соображу ни как :grimacing:",,Иван Гончаров
1603139426.245500,1603139426.245500,U01BBD8TXJ7,Категоризация этажей.,,Андрей Черненко
1603139426.245500,1603139664.250400,U01BBD8TXJ7,"Привет 
<@U0185Q2MK19>  подскажи, пожалуйста, как проще выделить категорию для последнего этажа.
Я пробовал и через функции плюс apply, проблема в необходимости сравнения столбцов этажа и макс.этажа. Также пробовал сравнение  столбцов через loс и присваивание значений, но не вышло. 
Можно, конечно, через цикл, но должен быть и другой метод?)",,Андрей Черненко
1603140356.251000,1603140356.251000,U01C12HDRUG,Вопрос по замене пропусков в _days_exposition_,,Елена Угдыжекова
1603140356.251000,1603140446.251100,U01C12HDRUG,"Ребята, подскажите, пожалуйста, что делали с пропусками в этом столбце. И в догонку: как изучали время продажи квартир, что там смотрели?",,Елена Угдыжекова
1601572083.043000,1603147052.251300,U01B4EYQADU,"У меня большой вопрос вызывает тип занятости ""компаньон"". Это вообще как?",,Мария Бучнева
1603139426.245500,1603168327.251500,U0185Q2MK19,"<@U01BBD8TXJ7>, привет!

Не уверен, что до конца понимаю проблему.

Можно написать функцию и применить через apply.

Например:

```def floor_category(row):
    if row['floor'] == 1:
        return 'первый'
    elif row['floor'] == row['total_floors_in_house']:
        return 'последний'
    else:
        return 'другой'```
`И потом: df['floor_category'] = df.apply(floor_category, axis=1)`

Или уточни в чем конкретно проблема)",,Олег Булыгин
1603105216.239600,1603168648.251700,U0185Q2MK19,"<@U01BBD8JS75>, решение заменить на средние отношения нужной площади к общей - весьма неплохое.
Есть и более сложные способы заполнение пропусков, но вы их пока не изучали)",,Олег Булыгин
1603108164.241200,1603168920.251900,U0185Q2MK19,"Не, в set_ylim передается точно не список.
Вроде эту штуку (это не ошибка, а предупреждение) пофиксили в последних версиях matplotlib. На сервисе стоит не последняя версия, поэтому так)

Если все работает как надо - не обращай внимания. Можно отключить вывод этого предупреждения командой
```np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) ```
",,Олег Булыгин
1603135390.244600,1603169710.252200,U0185Q2MK19,"<@U01C12EF41E>, а все-таки задача какая? Удалить выбросы или их заменить?)

Это 2 принципиально разные вещи, которые надо по разному реализовывать.

При помощи loc можно написать условие, все значения по которому не попадают в указанный диапазон будут заменены на то, что нужно",,Олег Булыгин
1603140356.251000,1603169825.252400,U0185Q2MK19,"А можно предположить, что если у объявления нету days_exposition, то оно не было снято",,Олег Булыгин
1601572083.043000,1603170122.252600,U0185Q2MK19,"<@U01B4EYQADU>, ну вот такая классификация в этом наборе данных) Думаю, не стоит на это обращать внимание. Работаем, с тем, что есть)",,Олег Булыгин
1603108164.241200,1603171153.253300,U01BPRN9VCH,<@U0185Q2MK19> спасибо) ,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Анна Шлёнская
1603139426.245500,1603173133.254600,U01BBD8TXJ7,"<@U0185Q2MK19>  все правильно понял, спасибо.
Уже под вечер тормозил и применял к элементу, а не строке:see_no_evil:",,Андрей Черненко
1603174615.255000,1603174615.255000,U01BBD8JS75,Вопрос по построению матрицы корреляции,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1603174615.255000,1603174742.255100,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, как построить матрицу корреляции не для всех колонок таблицы, а только для некоторых. У нас их там 22 колонки плюс мы сами добавляли еще несколько, а матрица будет только от 4 колонок.",,Алексей Глазов
1603174615.255000,1603174974.255300,U01BB72RSH0,"<@U01BBD8JS75>, можно <https://pastebin.com/Mv3E70ps|так> сделать.","[{'name': '+1', 'users': ['U01BBD8JS75', 'U0185Q2MK19'], 'count': 2}]",Шилоносов Артём
1603174615.255000,1603175093.255600,U01BBD8JS75,<@U01BB72RSH0> а для чего в конце copy?,,Алексей Глазов
1603174615.255000,1603175352.255800,U01BB72RSH0,"<@U01BBD8JS75>, чтобы изменения в столбцах df_for_matrix (если таковые будут) не отразились на столбцах оригинального датасета. Я у себя в проекте чтобы не заморачиваться с подписями на корреляционной матрице <http://joxi.ru/v29bMzRipYjL0A|переименовал эти столбцы в кириллицу>)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1603174615.255000,1603175553.256100,U01BBD8JS75,спасибо),,Алексей Глазов
1603180912.256800,1603180912.256800,U01BPRN9VCH,Вопрос по анализу сегмента в центе,,Анна Шлёнская
1603180912.256800,1603181143.256900,U01BPRN9VCH,"<@U0185Q2MK19> Здравствуйте, может вопрос глупый,но я что то не дойду никак сама. Я выделила сегмент в центе, записала в новый df, но когда хочу построить корреляцию, что б узнать, что влияет больше всего на цену, он выдает мне таблицу 25х25  и зависимости между всеми данными:white_frowning_face:я уверена, можно как то только одному столбцу отфильтровать. Подскажите пожалуйста",,Анна Шлёнская
1603180912.256800,1603181443.258000,U01BB72RSH0,"<@U01BPRN9VCH>, это делается довольно <https://pastebin.com/yY1NzstM|просто>. Только вместо `df` надо указать тот датасет, который представляет собой срез по объявлениям в центре.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1603180912.256800,1603181644.258800,U01BB72RSH0,"<@U01BPRN9VCH>, так мы же <http://joxi.ru/gmvMPD1i1MBwkr|это> и получаем)",,Шилоносов Артём
1603180912.256800,1603181696.259100,U01BPRN9VCH,"<@U01BB72RSH0> прости да, я затупила и не перешла по ссылке Просто, хотела незаметно удалить свой косяк, но ты уже ответил :sweat_smile::see_no_evil: спасибо",,Анна Шлёнская
1603180912.256800,1603181775.259400,U01BB72RSH0,"<@U01BPRN9VCH> ничего страшного, главное - разобраться с вопросом :ok_hand:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1603105216.239600,1603196133.261300,U01BB72MR6E,"<@U01BBD8JS75> я заменяла на среднее, но не в целом, а в зависимости от числа комнат в квартире","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01BB74HXGA', 'U01C12H8HJL', 'U01BBD8GB7D'], 'count': 4}]",Юлия Сова
1603135390.244600,1603196814.265000,U01BB72MR6E,"<@U01C12EF41E> я без loc делала. Просто выбираю по нужному условию данные. Пример: data = data[data[‘height’] &lt; 30] .reset_index() (если решила отрубить всё, что больше 30 м)",,Юлия Сова
1603203413.265900,1603203413.265900,U01BHCRMNGL,Добавить подписи данных в ящик с усами,,Дарья Баранкова
1603203413.265900,1603203485.266000,U01BHCRMNGL,Всем привет! Кто-нибудь знает как добавить подписи данных в Boxplot?,,Дарья Баранкова
1603135390.244600,1603204450.266200,U01C12EF41E,"<@U0185Q2MK19> а можете подсказать как задать такое условие?, с использованием .loc
что бы все значения которые в диапазоне остались, а все что False, менялось на заданную переменную.
не могу сообразить как.
мы это вроде делали, но вообще ни как не вспоминается, или ошибаюсь где то.",,Иван Гончаров
1603135390.244600,1603204875.266500,U01C12EF41E,"<@U01BB72MR6E> привет, я хочу выбрать определенный диапазон, к примеру потолок от/до, все что входит в этот диапазон оставить, а все что не входит, заменить на значение, допустим медианы.

Твой способ попробовал, но либо я криво его применил, либо он убирает вообще все строки, во всей таблице!, мне такое пока не подходит )",,Иван Гончаров
1603206799.266800,1603206799.266800,U01B84HU32R,Вопрос по оглавлению,,Виктория Онучина
1603206799.266800,1603206911.266900,U01B84HU32R,"В прошлом проекте оглавление не делала, а тут решила, что надо бы, да и порекомендовали. Почитала тут тред про оглавление, но что-то оно у меня не тыкается... Может кто объяснит такой глупый момент: как понять, что оглавление работает? Добавляла и в нужную строку &lt;a name=“mark1”&gt;&lt;/a&gt;, но все равно не понимаю...",,Виктория Онучина
1603208748.267300,1603208748.267300,U01AWENRANB,Поиск центра,,Ксения Ушакова
1603208748.267300,1603208857.269300,U01AWENRANB,"Чем дальше, тем менее реальными кажутся результаты, окончательно поставил в тупик график удалённости от центра от средней цены. Головой понимаю, что динамика должна быть обратная, или я ошибаюсь? 

<http://joxi.ru/eAOP0z5ikeER1r|http://joxi.ru/eAOP0z5ikeER1r>",,Ксения Ушакова
1603139426.245500,1603208934.270500,U01B84JJ5L5,"<@U0185Q2MK19> была та же проблема, а почему все же применять к строке, а не к элементу? Не совсем понимаю ",,Ингвар Сильницкий
1603139426.245500,1603208989.271900,U01B84JJ5L5,"То есть почему мы пишем row[‘floor’],а не df[‘floor’]",,Ингвар Сильницкий
1603206799.266800,1603209097.273700,U01AWENRANB,"Само оглавление же ты тоже составляешь в начале вручную, [заголовок](#mark1). Запустить этот шаг и он превратится в гиперссылку",,Ксения Ушакова
1603208748.267300,1603209231.273900,U01BPRN9VCH,"да, динамика у тебя обратная, должно быть по другому, странно, потому что удаленность от центра величина табличная,значит косяк в цене за кв метр, хотя, где там может быть косяк, тоже не понятно, один столбец на другой же просто :thinking_face:",,Анна Шлёнская
1603206799.266800,1603209268.274100,U01B84HU32R,"<@U01AWENRANB> он не нажимается... Может я что-то не так делаю :( то есть они кликабельные, но не переносят в нужное место.",,Виктория Онучина
1603135390.244600,1603209437.275600,U01C12EF41E,"<@U0185Q2MK19>, я видимо до конца так и не понял как работает метод .loc

height_min = 2.20
height_max = 3.12
height_median = 2.60

df.loc[(df['ceiling_height']&lt;height_min)&amp;(df['ceiling_height']&gt;height_max),'ceiling_height'] = height_median

как я это понимаю -  берем таблицу df, задаем ей логическое условие через .loc[ ], если удовлетворит(если будет True), то приравнять к  = height_median
в самом .loc[ ], два условия в ( ) через &amp;",,Иван Гончаров
1603206799.266800,1603209466.276600,U01B84HU32R,"<@U01AWENRANB> вот так, у других тоже но с mark2, mark3, дальше не делала еще, но хотя бы эти понять...",,Виктория Онучина
1603206799.266800,1603209501.278400,U01AWENRANB,"А те окна, куда должна быть ссылка, ты их запускала, также как окошки с кодом? ",,Ксения Ушакова
1603135390.244600,1603209504.278600,U01C12EF41E,"где у меня начинается каша? )
скиньте пожалуйста ссылку на материал, как правильно обращаться к .loc",,Иван Гончаров
1603135390.244600,1603209507.278800,U01BB72MR6E,"<@U01C12EF41E> да, мой способ всё, что не входит в указанный диапазон, вообще убирает.. если двойное условие, то я через query делала",,Юлия Сова
1603206799.266800,1603209545.279000,U01B84HU32R,"<@U01AWENRANB> да, я делала run all, после нажимала на свое оглавление и ничего :(",,Виктория Онучина
1603208748.267300,1603209637.281200,U01AWENRANB,"Спасибо, буду завтра искать косяк, может числитель и знаменатель перепутала уже в панике, пропусков там нигде нет. А ещё вопрос такие огромные значения для расстояния, даже если на 1000 разделить, получается многовато, что делали?",,Ксения Ушакова
1603208748.267300,1603209903.281400,U01BPRN9VCH,"Я делила столбец с расстоянием до центра на 1000 и все. Почему огромные? Если брать срез по городу, то не так уж много, Питер большой город",,Анна Шлёнская
1603206799.266800,1603210094.282700,U01AWENRANB,"[Шаг 1. Откройте файл с данными и изучите общую информацию](#step1)

# Шаг 1. Откройте файл с данными и изучите общую информацию. &lt;a name=""step1""&gt;&lt;/a&gt;

Вот это из первого проекта, рабочий вариант, попробуй скопипастить",,Ксения Ушакова
1603135390.244600,1603210304.282900,U01C12EF41E,"<@U01BB72MR6E> мне все равно не понятно:see_no_evil:, но спасибо за совет!

буду мучить глупыми вопросами Олега :grimacing:",,Иван Гончаров
1603206799.266800,1603210454.283100,U01B84HU32R,"<@U01AWENRANB> да, спасибо, так работает.. интересно, почему не работает у меня, хм. Но ладно, потом углублюсь!","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1603206799.266800,1603210484.283800,U01AWENRANB,Может например в коде a не латиницей? Ну как вариант,,Ксения Ушакова
1603206799.266800,1603210777.284000,U01B84HU32R,"<@U01AWENRANB> все оказалось куда смешнее и легче: все дело в кавычках ахах. Они с завитушкой, поэтому не работают))","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1603206799.266800,1603210976.284500,U01AWENRANB,"Слишком красивые, чтобы работать )))","[{'name': 'slightly_smiling_face', 'users': ['U0185Q2MK19'], 'count': 1}]",Ксения Ушакова
1603215212.285100,1603215212.285100,U01BBD8HKR9,Разделение исходной таблицы на столбцы,,Антонина Колб
1603215212.285100,1603215287.285200,U01BBD8HKR9,"Как разделить таблицу на столбцы, там еще \t??",,Антонина Колб
1603215212.285100,1603216276.285400,U01B4EZSWHL,"<@U01BBD8HKR9>, просто добавляешь еще аргумент) pd.read_csv('/datasets/real_estate_data.csv', sep='\t')","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Лиза Толмачева
1603215212.285100,1603216334.285900,U01BBD8HKR9,<@U01B4EZSWHL>  Спасибо!,,Антонина Колб
1603135390.244600,1603217302.286100,U01AWENQ0R5,"<@U01C12EF41E> я тоже пытаюсь вспомнить, где это было, чтобы можно было задать условие, а все, что туда не попадает заменялось на нужное значение..и блин не могу вспомнить, где это было :man-facepalming::skin-tone-2::man-facepalming::skin-tone-2:",,Volkhin Roman
1603220506.286600,1603220506.286600,U01BBD8L1DZ,Dead Kernel,,Екатерина Резанович
1603220506.286600,1603220634.289400,U01BBD8L1DZ,"<@U0185Q2MK19> привет! Делала проект на анаконде у себя на компе- все прекрасно работало и летало. Загрузила в Яндекс: код умирает на банальной гистограмме. И дальше ревьюер не может проверить работу. Комментарий «Установить ограничение по количеству экземпляров в графике» . Не совсем понимаю, что это значит. Подскажи, пожалуйста, что делать 🥺",,Екатерина Резанович
1603135390.244600,1603226189.289600,U01BHCPLXHS,"Может тут *where* вам поможет?

Выборочно изменяют значения методом where(). Ему передают 2 параметра: булев массив и новые значения. Если в булевом массиве True, соответствующее ему значение не изменится; а если False — значение поменяется на второй параметр метода. data['column'].where(s &gt; control_value, default_value)","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12EF41E'], 'count': 2}]",Вероника Гром
1603220506.286600,1603228292.289800,U01BBD8L1DZ,df['floor_id'].hist();,,Екатерина Резанович
1603220506.286600,1603228306.290000,U01BBD8L1DZ,"все крутит, кроме этого кода - умирает",,Екатерина Резанович
1603220506.286600,1603230312.290200,U01BBD8L1DZ,"Могу ли я вместо этого построить пай? все графики работают на floor_id, кроме гистограммы :catshake:",,Екатерина Резанович
1603220506.286600,1603260283.290400,U01BHCPPL2Y,bins=X сделай,,Me_
1603261104.291100,1603261104.291100,U01BB72MR6E,Библиотека seaborn,,Юлия Сова
1603261104.291100,1603261188.291200,U01BB72MR6E,"<@U0185Q2MK19> привет! Ревьюер посоветовал использовать метод heatmap из библиотеки seaborn. Подскажи, пожалуйста, где можно почитать про это, чтобы понять, что делать?",,Юлия Сова
1603261104.291100,1603262011.291400,U01BB72RSH0,"<@U01BB72MR6E>, у нас эта инфа в Notion есть) Например, через быстрый поиск по ключевому слову ""seaborn"" нашел вот <https://s3.us-west-2.amazonaws.com/secure.notion-static.com/126eb151-8af3-4d43-991f-5e0184a881cc/Python_Seaborn_Cheat_Sheet.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20201021%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20201021T063030Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=0106ddb964580af99fded881bb4c12198c8a3b60d47f6a1b19d859b44a25715c&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Python_Seaborn_Cheat_Sheet.pdf%22|такую> шпаргалку в ""полезных материалах"". В конспектах тоже быть должно (seaborn мы вроде дальше по ходу обучения проходить будем).","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12G0QNL', 'U01AWEPC0SK', 'U01BB72MR6E'], 'count': 4}]",Шилоносов Артём
1603139426.245500,1603262259.291600,U0185Q2MK19,"<@U01B84JJ5L5>, так работает apply. Нам требуется по сути сделать построчные сравнения (параметры каждой квартиры сравнить с нужными). apply перебирает все строки в данных (аргумент axis) и применяет к ним указанный функционал. Из каждой строки мы достаем нужный столбец и делаем сравнения.",,Олег Булыгин
1603261104.291100,1603262445.292100,U0185Q2MK19,"<@U01BB72MR6E>, вот здесь еще руководство по heatmap можно изучить: <https://likegeeks.com/seaborn-heatmap-tutorial/>","[{'name': '+1', 'users': ['U01BB72RSH0'], 'count': 1}]",Олег Булыгин
1603203413.265900,1603262517.292400,U0185Q2MK19,"<@U01BHCRMNGL>, привет!
Ты имеешь ввиду подписи осей?
Уточни, что требуется)",,Олег Булыгин
1603135390.244600,1603262552.292600,U01AWENQ0R5,"<@U01BHCPLXHS> да, точно! Спасибо большое :sweat_smile:",,Volkhin Roman
1603208748.267300,1603262967.293100,U0185Q2MK19,"<@U01AWENRANB>, проверь себя таким действием:
`df.groupby('cityCenters_nearest')['last_price'].mean().plot()`
Это расстояние до центра по всем данным и средняя цена. Сразу видно, что чем больше расстояние, тем цена убывает)",,Олег Булыгин
1603203413.265900,1603262996.293400,U01BHCRMNGL,"<@U0185Q2MK19>, я хочу что бы на диаграмме были подписи точек, по которым она строится (квартили и крайние точки)",,Дарья Баранкова
1603203413.265900,1603263150.293600,U01BHCRMNGL,"Края усов же показывают максимальные и минимальные статистически значимые значения, я хотела их получить что бы отбросить все, что выше из набора данных))",,Дарья Баранкова
1603203413.265900,1603263169.293800,U0185Q2MK19,"<@U01BHCRMNGL>, это весьма непростая задача) Можно посмотреть тут один из вариантов: <https://stackoverflow.com/questions/40470175/boxplot-outliers-labels-python>
Но, как правило, это просто не требуется (а что если выбросов очень много?). Главное понимать сколько их и где они. А конкретные значения можно подробнее изучить в датафреймах.

А чтобы отбросить лишнее, можно просто написать отбор по условию в датафрейме, для этого визуализация как таковая не нужна)",,Олег Булыгин
1603135390.244600,1603263915.294200,U0185Q2MK19,"<@U01C12EF41E>, если у тебя задача заменить выбросы на средние в разрезе групп, то я бы порекомендовал так:

`df.loc[(df.ceiling_height &gt; ...) &amp; (df.ceiling_height &lt; ...)] = np.nan`  - вот так заменяем на nan. То есть просто задаем условия отбора внутри loc

А потом заполняем пропуски тем методом, который я упоминал ранее:
<https://yandex-students.slack.com/archives/G01B461LV0E/p1601536444033400?thread_ts=1601471861.031700&amp;cid=G01B461LV0E>

Напиши, получится ли так)

Вот здесь кратко про отбор по loc можно прочитать: <https://www.kite.com/python/answers/how-to-select-rows-by-multiple-label-conditions-with-pandas-loc-in-python>

Ну и с where тоже хороший вариант)",,Олег Булыгин
1603220506.286600,1603264288.295200,U0185Q2MK19,"<@U01BBD8L1DZ>, привет!
Чтобы сказать почему так, надо понимать, что у тебя находится во floor_id.
Я специально сейчас попробовал построить гистограммы по этажам - все ок работает. Какие преобразования до этого ты сделала?",,Олег Булыгин
1603203413.265900,1603264309.295400,U01BHCRMNGL,"<@U0185Q2MK19>, я не хочу помечать выбросы. Мне нужно получить максимальное статистически значимое значение, выше которого все будет выбросом.",,Дарья Баранкова
1603220506.286600,1603264367.297000,U01BBD8L1DZ,"<@U0185Q2MK19> floor_id - это первый , последний или средний этаж. Строится через функцию к столбцу floor (на котором все работает нормально) . ",,Екатерина Резанович
1603203413.265900,1603264509.297300,U0185Q2MK19,"<@U01BHCRMNGL>, это можно сделать по формуле IQR (межквартильного размаха). Вот здесь есть много примеров: <https://stackoverflow.com/questions/34782063/how-to-use-pandas-filter-with-iqr>

Напиши о результатах :slightly_smiling_face:",,Олег Булыгин
1603220506.286600,1603264656.297700,U0185Q2MK19,"<@U01BBD8L1DZ> гистограмма предназначена для отображения распределения непрерывных величин. А ты пытаешься ее применить к категориальной (у тебя по сути 3 значения в этом столбце). Если ты просто хочешь отобразить частоту, то надо использовать value_counts и bar plot",,Олег Булыгин
1603220506.286600,1603264717.299100,U01BBD8L1DZ,"<@U0185Q2MK19> ну отлично, поняла, просто смутило то, что на анаконде на компе все работало. Спасибо большое ! ","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Екатерина Резанович
1603135390.244600,1603265235.299500,U01C12EF41E,"<@U01BHCPLXHS> Спасибо большое!, все получилось)) :hugging_face:",,Иван Гончаров
1603203413.265900,1603265249.299700,U01BHCRMNGL,"Супер, спасибо, это то, что нужно:pray:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Дарья Баранкова
1603135390.244600,1603265720.299900,U01C12EF41E,"<@U0185Q2MK19> все получилось с where, спасибо!
Ваш материал я обязательно изучу, так как обращение к loc я до конца так и не понимаю. Но сначала проект допилю)
А еще я понял что не всегда понимаю, что от запроса получаю, число, строчку, список, или булев массив, и из за этого часто туплю.

Можете посоветовать какую нибудь обобщающую информацию, статью по этому вопросу?!
(типы переменных, их сокращения, какие методы функции для кого чаще применяют, всякие исключения)",,Иван Гончаров
1603135390.244600,1603265856.300100,U0185Q2MK19,"<@U01C12EF41E>, я бы вот такую шпаргалку для начала порекомендовал: <https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf>",,Олег Булыгин
1603277242.301000,1603277242.301000,U01C12DM2BA,Регламент проверки проектной работы,,Фарид Бабаев
1603277242.301000,1603277262.301100,U01C12DM2BA,"<@UTTGJQS6M> А что если ревьюерам можно было проверять проектную работу по частям(по основным шагам например) ? Насколько я знаю, они недоделанную работу не проверяют и отправляют обратно на доработку. Было бы продуктивнее получать комментарии по мере работы, а не в самом конце.",,Фарид Бабаев
1603277242.301000,1603277413.301300,UTTGJQS6M,"Привет! Не совсем поняла, а почему на проверку отправлена недоделанная работа?",,Маргарита Минеева
1603277242.301000,1603277502.301500,U01C12DM2BA,Скажем я выполнил первые два шага и хочу быть уверен что там все ок.,,Фарид Бабаев
1603277242.301000,1603278123.301700,UTTGJQS6M,"Стоит призвать преподавателя и обсудить, оправляем ли мы проекты в таком виде.
Итоговый фидбек я отнесу команде на обсуждение)",,Маргарита Минеева
1603277242.301000,1603278180.301900,U01C12DM2BA,<@U0185Q2MK19> призвал :slightly_smiling_face:,,Фарид Бабаев
1603277242.301000,1603278267.302100,U0185Q2MK19,Ревьюерами проверяются только полные версии работ. Незавершенную работу ревьюер смотреть не будет и сразу отправить на доработку. Поэтому есть смысл отправлять только полностью доделанную версию.,,Олег Булыгин
1603277242.301000,1603278379.302300,U01C12DM2BA,"Это мы знаем уже, вопрос в том можно ли поменять эти правила.",,Фарид Бабаев
1603277242.301000,1603293163.302500,U01B84HU32R,"Вставлю свои 5 копеек размышления. Но мне кажется это не очень по ресурсозатратности (а именно времени). Кто-то сделает 2 кусочка кода, отправит и попросит проверить, а потом еще вот тут два кусочка, а вот тут я по-другому сделал, проверьте. Если дать людям свободу отправлять в любом виде, то многие будут слишком уж этим пользоваться... Но как студент я понимаю тебя и твое желание быть уверенным, что ты на правильном пути))
Потому что страшно, что что-от делаешь не так.",,Виктория Онучина
1603261104.291100,1603294099.303500,U01BB72MR6E,<@U01BB72RSH0> <@U0185Q2MK19> спасибо! Буду изучать:nerd_face:,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19', 'U01BB72RSH0'], 'count': 2}]",Юлия Сова
1601471861.031700,1603295943.303700,U01BB72MR6E,"<@U0185Q2MK19> ты писал выше, что метод transform таким образом можно применять и для группировки по двум признакам. Но я в скобках после groupby пишу через запятую 2 столбца - а в итоге получаю группировку практически по каждому единичному значению. Как сделать, чтобы это были именно группы? Для примера выше: как не только по типу дохода группировку делать, но и, скажем, по уровню среднемесячного дохода?",,Юлия Сова
1603277242.301000,1603296244.304000,U01C12DM2BA,"я поэтому предложил проверять на основных этапах,например первые да шага",,Фарид Бабаев
1603277242.301000,1603309481.304500,U01BB74F8GJ,"а в реальной жизни вы как себе это видите? у кого будете спрашивать на правильном вы пути или нет? интересуют результаты. иногда (довольно часто) делаешь рисеч, ставишь эксперименты, а результат не такой или понимаешь, что была ошибка. переделываешь, растешь, учишься на опыте.","[{'name': 'heavy_plus_sign', 'users': ['U01BB72RSH0', 'U01B84JDZ5K', 'U01C12H8HJL'], 'count': 3}]",Митя Журавлев
1601471861.031700,1603341168.304800,U0185Q2MK19,"<@U01BB72MR6E>, а у тебя уровень среднемесячного дохода разбит на категории? Если нет, то будучи непрерывной величиной он и будет за группу считать отдельно взятое значение :slightly_smiling_face:
Можешь добавить столбец с категорий дохода (например, низкий, средний, высокий) и добавить группировку именно по нему.

Но сразу скажу - не уверен, что заполнение пропусков какой-либо величины в разрезе группы дохода является осмысленным. Надо это логически для ревьюера обосновать",,Олег Булыгин
1601471861.031700,1603342305.306700,U01BB72MR6E,"<@U0185Q2MK19>  у меня 2 параметра, оба не разбиты на категории. Поняла, значит сначала категоризирую, потом делаю по ним группировку:+1::skin-tone-3:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Юлия Сова
1603277242.301000,1603357406.308500,U01BHCPLXHS,"Идея интересная, но по ходу работы можно столкнуться с тем, что первые 2 шага стоило иначе выполнять и понятно это становится только по дальнейшим шагам, графикам, исследованиям и тд",,Вероника Гром
1603357813.308800,1603357813.308800,U01BBD8JS75,Замена пропусков,,Алексей Глазов
1603357813.308800,1603357954.308900,U01BBD8JS75,"В проекте я пользовался логикой, раз не указано количество парков и водоемов поблизости, то скорее всего это из-за того что их нет. При этом ревьюер говорит заполнять эти данные медианнами, зачем? Ведь чтобы так поступить мы должны быть уверены, что парки равномерно распределены по всему населенному пункту, т.е. парки есть в центре, на севере, западе, юге и востоке. Тогда можно сказать, что где бы квартира не находилась, то где-то рядом с ней есть парк или пруд.",,Алексей Глазов
1603357813.308800,1603363234.309500,U01BB74HXGA,"Тоже ревьювер написал, что все картографические характеристики, по которым нет данных надо заменить медианными значениями - хотя логики в этом нет никакой...",,Анна Касьянова
1603357813.308800,1603363264.309700,U01BBD8JS75,"<@U0185Q2MK19> помоги пожалуйста, хочу заменить пропуски в расстоянии до центра на медианное значение для определенного населенного пункта, хоть я и не понимаю зачем. Как ты уже показывал ранее, я использовал метод transform:
`df['cityCenters_nearest'] = df['cityCenters_nearest'].fillna(df.groupby('locality_name')                                                           ['cityCenters_nearest'].transform('median'))`
Но у меня все равно остаются еще 5 тыс пустых строк, хотя пропуски в  `locality_name` я заполнил, почему еще может не происходить замена?",,Алексей Глазов
1603364123.311300,1603364123.311300,U01AWEPC0SK,"Ребят, а какой разделитель в данных? Я ставлю в read_csv “\”, а у меня все равно ерунда какая-то;(",,Ирина Дёмина
1603364123.311300,1603364203.311400,U01BB72RSH0,"<@U01AWEPC0SK>, во втором проекте разделитель данных - `'\t'`",,Шилоносов Артём
1603364123.311300,1603364234.311900,U01AWEPC0SK,:pray: а как вы поняли это?,,Ирина Дёмина
1603364123.311300,1603364468.312200,U01BB72RSH0,"<@U01AWEPC0SK>, если попробовать скормить в `.read_csv()` датасет без правильного разделителя, то при попытке его отобразить получается нечто <http://joxi.ru/1A5El0LIb13jXA|такое> - на скриншоте видно, что в каждой строке постоянно повторяется `\t` - это и есть тот самый разделитель :slightly_smiling_face:","[{'name': '+1', 'users': ['U01AWEPC0SK', 'U0185Q2MK19'], 'count': 2}]",Шилоносов Артём
1603364123.311300,1603364518.312900,U01AWEPC0SK,Спасибо :pray: <@U01BB72RSH0> ,"[{'name': 'cat-high-five', 'users': ['U01BB72RSH0'], 'count': 1}]",Ирина Дёмина
1603357813.308800,1603366263.313200,U01C12HDRUG,"<@U01BBD8JS75> Постою, послушаю, такая же проблема( Хотя в предыдущем проекте этот метод сработал без проблем.",,Елена Угдыжекова
1603357813.308800,1603366668.313400,U01BBD8JS75,"<@U01C12HDRUG> я и в этом проекте использовал этот метод для замены высоты потолков в зависимости от этажности дома, а вот с расстоянием почему-то не срабатывает, ни расстояния до центра, ни до аэропорта, ни до парков не заполнилось... Сама машина против этой идеи))",,Алексей Глазов
1603357813.308800,1603366962.313600,U01C12HDRUG,"<@U01BBD8JS75> есть предположение, что замены не происходят там, где по населенным пунктам одно объявление и по ним не было информации о расстоянии. Но не знаю, насколько это соответствует действительности.",,Елена Угдыжекова
1603357813.308800,1603367021.313800,U01BBD8JS75,<@U01C12HDRUG> как вариант...,,Алексей Глазов
1603357813.308800,1603367603.314600,U01BBD8JS75,"<@U0185Q2MK19> и еще вопрос, чем можно заменить кол-во дней продажи? так же медиана для населенного пункта?
я понимаю что раз данных нет, что объявление открыто. Но мой ревьюер просит заполнить все пропуски, а выкидывать 13% строчек... у меня таким темпом скоро от датасета ничего не останется)",,Алексей Глазов
1603357813.308800,1603367973.314900,U0185Q2MK19,"<@U01BBD8JS75>, привет!

По первому вопросу - скорее всего, есть группы (по locality name), в которых полностью не указано cityCenters_nearest. То есть рассчитывать медиану даже не из чего, там везде пропуски.

Я согласен, что заполнять геопризнаки таким способом не очень осмысленно. Может быть, ревьюер просто хочет, чтобы вы технически потренировались в способах заполнения значений.

По второму вопросу - я бы ничем не заполнял :sweat_smile: Но раз очень надо, взял бы локацию и ценовой сегмент.",,Олег Булыгин
1603357813.308800,1603368309.315200,U01BBD8JS75,<@U0185Q2MK19> а как в нашу конструкцию вставить второй столбец группировки?,,Алексей Глазов
1603368540.315600,1603368540.315600,U01BBD8NUCT,Оформление графиков: подписи осей?,,Арсалан
1603368540.315600,1603368645.315700,U01BBD8NUCT,<@U0185Q2MK19> Привет! Почему то не дает подписать ось у ? Выдает ошибку <http://dl4.joxi.net/drive/2020/10/22/0045/1012/2966516/16/896a25a956.jpg>,,Арсалан
1603368540.315600,1603368732.316000,U01BBD8NUCT,<https://pastebin.com/qf8Jr7sw>,,Арсалан
1603368540.315600,1603368762.316200,U01BBD8NUCT,как подписать все оси?,,Арсалан
1603368540.315600,1603369056.316400,U01BPRN9VCH,"Попробуй строить через hist, у меня все было норм
<https://pastebin.com/BmFUw5FR>","[{'name': '+1', 'users': ['U01BBD8NUCT'], 'count': 1}]",Анна Шлёнская
1603357813.308800,1603369699.318300,U01BB72MR6E,<@U01BBD8JS75> через запятую в скобках. Но непрерывные переменные должны быть сначала категоризированы,"[{'name': '+1', 'users': ['U01BBD8JS75', 'U0185Q2MK19'], 'count': 2}]",Юлия Сова
1603368540.315600,1603370057.318600,U01C12G0QNL,"Я подписывал через plt.xlabel(), plt.ylabel() и plt.title()","[{'name': '+1', 'users': ['U01BBD8NUCT'], 'count': 1}]",Михаил Перцев
1603368540.315600,1603370992.319000,U0185Q2MK19,"<@U01BBD8NUCT>, привет! У тебя синтаксис немного неверный. Попробуй так:
```ax= df.plot(y = 'total_area', kind = 'hist', bins = 100, grid=True, figsize = (7,3), range = (0,300), title='Площадь квартиры')
ax.set_xlabel('Кв.м.')
ax.set_ylabel('Кол-во объявлений')```","[{'name': 'pray', 'users': ['U01BBD8NUCT'], 'count': 1}]",Олег Булыгин
1603368540.315600,1603371402.319300,U01BBD8JS75,"<@U0185Q2MK19> подскажи как сделать так, что дни недели шли по порядку",,Алексей Глазов
1603368540.315600,1603372115.319600,U01BBD8NUCT,<@U0185Q2MK19> Да получается теперь. Всем большое спасибо!:+1:,,Арсалан
1603368540.315600,1603372526.320100,U01BBD8NUCT,"<@U0185Q2MK19> А без создания переменной, прямо в скобках, как например указали title, также можно как то подписывать оси? И есть ли еще какие варианты подписывания осей?",,Арсалан
1603357813.308800,1603374616.320300,U01BB74BJ9G,Я в картографических данных пропуски не убирал. Ревьюера все устроило.,,Владимир Саков
1603375729.320700,1603375729.320700,U01BPRKQP9P,Странности при создании оглавления,,Никита Коптелов
1603375729.320700,1603375851.320800,U01BPRKQP9P,"<@U0185Q2MK19> хотел сделать многоуровневое оглавление, но столкнулся с такой ""проблемой"", что при попытках сделать это подпункты теряют нумерацию и принимают буквенные обозначения. почему так получается? можно как-то исправить?",,Никита Коптелов
1603375729.320700,1603376024.321400,U01B84HU32R,"Подпишусь под тред. Я забила, использовала с А в итоге. Так и не нашла как сделать красиво, но и так сойдет))",,Виктория Онучина
1603375729.320700,1603376285.321600,U01BPRKQP9P,"<@U01B84HU32R> мне опытным путём удалось получить нечто похожее на желаемое, да и это не супер-проблема, конечно, но просто в многочисленных гайдах по markdawn оглавление создаётся так, как я пытался его реализовать на скриншотах выше, но в реальности почему-то не работает:thinking_face:",,Никита Коптелов
1603375729.320700,1603378156.322000,U01C12G0QNL,"Привет. Вот пример того, как я сделал оглавление. Похоже на то, что нужно?
Код <https://pastebin.com/D42Z1dmF>","[{'name': 'happy-cat', 'users': ['U01B84HU32R', 'U01BPRKQP9P'], 'count': 2}, {'name': '+1', 'users': ['U0185Q2MK19', 'U01BBD8EYR1'], 'count': 2}]",Михаил Перцев
1603375729.320700,1603378226.322500,U01BPRKQP9P,"<@U01C12G0QNL>, привет! да, даже больше, чем мой последний вариант. спасибо большое:+1:",,Никита Коптелов
1603368540.315600,1603382619.323000,U01BB72RSH0,"<@U01BBD8JS75>, я бы сводную таблицу сохранил в условный weekday_pivot, а потом в эту таблицу добавил столбец с числовыми значениями для дней (например, от 1 до 7), затем отсортировал бы возрастанию значений в этом столбце всю сводную таблицу и повторно вывел график для таблицы.",,Шилоносов Артём
1603368540.315600,1603383017.323200,U01BBD8JS75,"<@U01BB72RSH0> проблема в том, что ревьюер заставил вытаскивать именно названия дней недели и месяцев. У меня до этого было в цифрах, и все по порядку было.",,Алексей Глазов
1603368540.315600,1603383324.323400,U01BB72RSH0,"<@U01BBD8JS75>, а <http://joxi.ru/xAeZ9wyHXPkYKr|такой> вариант не подойдет? (+ <https://pastebin.com/zukN1Zp3|код> со скриншота)","[{'name': '+1', 'users': ['U01BBD8NUCT'], 'count': 1}]",Шилоносов Артём
1603368540.315600,1603383769.323800,U01BBD8JS75,"<@U01BB72RSH0> просто я изначально извлекал дни недели и месяца через month_name,  и мне сразу в колонку добавились названия месяцов.",,Алексей Глазов
1603368540.315600,1603384256.324000,U01BB72RSH0,"<@U01BBD8JS75>, тогда <https://pastebin.com/HHMcz77H|так> )",,Шилоносов Артём
1603368540.315600,1603384833.324200,U01BBD8JS75,"<@U01BB72RSH0> тогда я не понимаю смысл было извлекать дн. Недели, если для их фильтрации нужно столько дополнительных действий))",,Алексей Глазов
1603368540.315600,1603385056.324400,U01BB72RSH0,"<@U01BBD8JS75>, ну если сначала извлекать не буквенные обозначения, а цифровые, то сортировать потом сводную таблицу не надо будет (- 1 строка кода)) Ручное добавление буквенных названий дней в таком случае будет элементом оформления графика)",,Шилоносов Артём
1603140356.251000,1603391071.324800,U01BHCPKNG4,"<@U0185Q2MK19> можно ли делать такое предположение, если для этих строк в столбце last_price не пустые значения?",,ElenaV
1603391694.325700,1603391694.325700,U01BHCPKNG4,Вопрос по изменению типов данных для столбцов с NaN,,ElenaV
1603391694.325700,1603391755.325800,U01BHCPKNG4,"Подскажите, можно ли поменять тип данных для столбца, в котором есть NaN?",,ElenaV
1603368540.315600,1603426173.326400,U0185Q2MK19,"<@U01BBD8NUCT>, можно еще в сам метод plot передавать параметры xlabel и ylabel (<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.plot.html>), но это работает только в самых актуальных версиях библиотеки. Не уверен, что в среде Яндекса сработает, но можно попробовать.","[{'name': '+1', 'users': ['U01BBD8NUCT'], 'count': 1}]",Олег Булыгин
1603368540.315600,1603426280.326600,U0185Q2MK19,"<@U01BBD8JS75>, можно указать, что это упорядоченный категориальный тип еще, вот тут есть примеры: <https://stackoverflow.com/questions/53189216/sorting-pandas-dataframe-by-weekdays>

Но это в любом случае доп. действия)","[{'name': '+1', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1603140356.251000,1603428177.327500,U0185Q2MK19,"<@U01BHCPKNG4>, на самом деле мы только догадываться тут можем. В реальности я бы вообще эти пропуски не стал заполнять. Но если ревьюер настаивает(из тренировочных целей), то я бы выдвинул 2 гипотезы – что объявление было снято прямо в день публикации и тогда можно заменить нулями, либо заполнил бы по принципу ""текущая дата минус дата первой публикации"".",,Олег Булыгин
1603391694.325700,1603428415.327700,U0185Q2MK19,"Можно использовать `.astype('Float64')` или `.astype('Int64')`.
Вопрос скорее в том, зачем это надо :)",,Олег Булыгин
1603451447.330500,1603451447.330500,U019HNXQEA1,"До сих пор непонятно, когда отбрасывать данные или когда заменять, и вообще зачем мы всё это делаем:grimacing: Есть ли книги, которые помогают разобраться в аналитике данных в целом? Буду очень благодарен, если поможете разобраться с данными вопросом:pray:",,Жуган Артём
1603451447.330500,1603457472.330900,U0185Q2MK19,Рекомендую почитать вот этот материал: <https://loginom.ru/blog/missing>,"[{'name': '+1', 'users': ['U01C12G0QNL', 'U019HNXQEA1', 'U01C12H8HJL'], 'count': 3}]",Олег Булыгин
1603451447.330500,1603459366.331300,U019HNXQEA1,<@U0185Q2MK19> Благодарствую:pray:,,Жуган Артём
1603135390.244600,1603459928.331500,U01B84D31FF,<@U0185Q2MK19> Привет! А можешь рассказать подробнее про использование метода *where?* Не совсем понял как можно им воспользоваться,,Кирилл Солодков
1603472892.332800,1603472892.332800,U01C12DM2BA,Функция для определения этажа,,Фарид Бабаев
1603472892.332800,1603472942.333100,U01C12DM2BA,"<@U0185Q2MK19> Как записать формулу для категоризации этажей? Я пытаюсь придумать что-то такое, но не понимаю как передать второй аргумент
`def floor_cat(floor, floors_total):`
    if floor == 1:
        return 'первый'
    if floor == floors_total:
        return 'последний'
    else:
        return 'другой'",,Фарид Бабаев
1603472892.332800,1603475127.334500,U01BB74BJ9G,<@U01C12DM2BA> Ответ есть в треде выше,,Владимир Саков
1603472892.332800,1603475136.334700,U01C12G0QNL,<@U01C12DM2BA> привет. Лучше передавать в функцию df и уже внутри функции обращаться к значениям.,"[{'name': 'heavy_check_mark', 'users': ['U01C12DM2BA'], 'count': 1}]",Михаил Перцев
1603476629.335700,1603476629.335700,U01B4EZSWHL,Вопрос по подсчету средней цены за квадратный метр в выбранных городах,,Лиза Толмачева
1603476629.335700,1603476771.335900,U01B4EZSWHL,"<@U0185Q2MK19>, помоги пожалуйста разобраться. Не совсем понимаю как реализовать данную задачу ? я выбрала города с наибольшим количеством объявлений, как можно посчитать среднюю цену за квадрат именно этих городов ?",,Лиза Толмачева
1603476629.335700,1603477336.336100,U01AWENQ0R5,"<@U01B4EZSWHL> можно сделать срез по этим городам, а потом сделать сводную таблицу",,Volkhin Roman
1603476629.335700,1603477382.336300,U01B4EZSWHL,Спасибо большое) Что-то я совсем не в ту сторону начала думать),,Лиза Толмачева
1603135390.244600,1603516368.337000,U0185Q2MK19,"<@U01B84D31FF>, это лишь один из нескольких способов ""доставать"" данные из датафрейма на основе какого-либо условия. Аналогичные действия можно сделать и при помощи `loc` и при помощи `[ ]`  и другими способами.
Вот здесь можно посмотреть примеры: <https://kanoki.org/2019/07/17/pandas-how-to-replace-values-based-on-conditions/>
Вот здесь документация: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.where.html>",,Олег Булыгин
1603472892.332800,1603516601.337300,U0185Q2MK19,"<@U01C12DM2BA>, все в итоге получилось?",,Олег Булыгин
1603476629.335700,1603516615.337500,U0185Q2MK19,"<@U01B4EZSWHL>, все получилось?",,Олег Булыгин
1603472892.332800,1603525923.337700,U01C12DM2BA,"Да, спасибо",,Фарид Бабаев
1603472892.332800,1603529289.338200,U01C12DM2BA,"<@U0185Q2MK19> Подскажи пожалуйста с чего начать 4 шаг. Я так понимаю надо взять срезы данных с  площадью, ценой и т.д.,посмотреть на их графики и оттуда уже отталкиваться?",,Фарид Бабаев
1603476629.335700,1603531880.338400,U01B4EZSWHL,"<@U0185Q2MK19>, не могу разобраться...  data_top_10 = data['locality_name'].value_counts().head(10). Вот так я выделила топ 10 с наибольшим числом объявлений. Как теперь посчитать среднее за квадрат относительно этих городов.... Я совсем не могу разобраться",,Лиза Толмачева
1603476629.335700,1603543880.338600,U01AWENQ0R5,"<@U01B4EZSWHL> теперь тебе нужно сделать срез из всей таблицы так, чтобы осталась таблица, где только эти 10 городов. Это можно сделать через .query . Названия крупнейших населенных пунктов у тебя хранятся теперь как индексы в data_top_10.index 
После того, как получишь этот срез данных, примени к нему groupby, чтобы сгруппировать по названию и получить средний кв.м.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Volkhin Roman
1603476629.335700,1603543937.339200,U01B4EZSWHL,"Спасибо , так и сделала )","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Лиза Толмачева
1603476629.335700,1603544176.339400,U01AWENQ0R5,<@U01B4EZSWHL> :+1:,,Volkhin Roman
1603552576.340500,1603552576.340500,U01AWENRANB,"Сообщения об ошибках в .loc и .astype
",,Ксения Ушакова
1603552576.340500,1603552790.342600,U01AWENRANB,"Не понимаю, почему выползают ошибки, код работает, но ошибки напрягают. Вроде все как в тренажере, но нет видимо. <@U0185Q2MK19> объясни пожалуйста

<https://pastebin.com/jWcjJh3P|https://pastebin.com/jWcjJh3P>
<http://joxi.ru/ZrJPOzEin8oqW2|http://joxi.ru/ZrJPOzEin8oqW2>


<https://pastebin.com/0UZxTUuT|https://pastebin.com/0UZxTUuT>
<http://joxi.ru/brRPEzdiODoa02|http://joxi.ru/brRPEzdiODoa02>


<https://pastebin.com/jZPVtKbP|https://pastebin.com/jZPVtKbP>
<http://joxi.ru/bmo36EBuye5anm|http://joxi.ru/bmo36EBuye5anm>",,Ксения Ушакова
1603552576.340500,1603554534.342800,U01AWENQ0R5,"<@U01AWENRANB> насчёт ошибок не знаю, но первый код можно проще реализовать, у формата datetime метод есть специальный)
df['weekday'] = df['date'].dt.weekday_name",,Volkhin Roman
1603552576.340500,1603554665.343400,U01AWENRANB,<@U01AWENQ0R5> спасибо! Возьму на заметку )),,Ксения Ушакова
1603556241.345000,1603556241.345000,U01C12GKE1E,Вопрос как сохранить проект на свой комп.,,Гуменников Алексей
1603556241.345000,1603556361.345100,U01C12GKE1E,Подскажите как сохранить блокнот с проектом из тренажера на свой комп.  Хочу сделать более совершенным.,,Гуменников Алексей
1603556241.345000,1603565525.346400,U01BB72RSH0,"<@U01C12GKE1E>, File -&gt; Download as -&gt; notebook (.ipynb)","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12GKE1E'], 'count': 2}]",Шилоносов Артём
1603451447.330500,1603573557.346700,U01C12H8HJL,<@U0185Q2MK19> большое спасибо за такую наводку! Только после прочтения статьи возник вытекающий (немного странный) вопрос С чего начать вспоминать математику? Может тренажеры какие сейчас есть? Или просто учебники школьные перелистать?,,Юлия Филоненко
1603472892.332800,1603601625.348000,U0185Q2MK19,"<@U01C12DM2BA>, первый пункт - да. Просто строим гистограммы на основе указанных столбцов и комментируем. Считаем меры центральной тенденции.
Потом переходим к работе с выбросами.
Ну и далее по пунктам)",,Олег Булыгин
1603451447.330500,1603604393.348200,U0185Q2MK19,"<@U01C12H8HJL>, тренажеры вряд ли какие-то есть. Я бы даже сказал, что нужна не только математика как таковая (линейная алгебра в первую очередь), но и статистика (+ теорвер).
Простых и популярных книг достаточно много (можно их обсуждать в канале library). Статистика и котики, Статистка в комиксах и пр. А так да, вузовские учебники никто не отменял)",,Олег Булыгин
1603552576.340500,1603604702.348400,U0185Q2MK19,"<@U01AWENRANB>, привет!

Это не ошибки, а предупреждение, что не так страшно :slightly_smiling_face:
На самом деле их можно просто игнорировать.
Рекомендую почитать вот эти источники, где подробно описывается, почему они возникают и что с этим делать:

<https://medium.com/@maxminicherrycc/setting-with-copy-warning-pandas-short-story-11e99c760e45>
<https://medium.com/@lengyi/dont-overlook-the-settingwithcopywarning-in-python-51e52b282891>",,Олег Булыгин
1603552576.340500,1603604839.348900,U01AWENRANB,<@U0185Q2MK19> спасибо! )),,Ксения Ушакова
1603613629.349600,1603613629.349600,U01C12DM2BA,Интерпретация гистограмм,,Фарид Бабаев
1603613629.349600,1603613739.349700,U01C12DM2BA,"<@U0185Q2MK19> Я не понимаю какие выводы мне надо делать по гистограммам, например вот тут что?",,Фарид Бабаев
1603613629.349600,1603613780.350000,U01C12DM2BA,"Для другого примера, в столбце rooms я сделал так, но опять таки не понимаю о чем это мне в целом говорит",,Фарид Бабаев
1603613629.349600,1603613868.350300,U01C12DM2BA,С days_exposition тоже не понимаю что делать,,Фарид Бабаев
1603613629.349600,1603617281.350600,U01BBD8JS75,"<@U01C12DM2BA> у меня ход мыслей примерно такой (на примере дней продажи):
На гистограмме видим пик примерно на 100 днях, это значит что большинство квартир продавалось в этот срок. Однако у гистограммы очень длинный хвост, некоторые квартиры не могли продать аж до 1600 дней. Но таких значений не очень много по сравнению с основной массой, так что они не типичны для нашей выборки из диаграммы размаха видно, чтл в среднем квартира продавалось за (ну примерно 30-210 дней, не вижу точных цифр, лучше добавь еще describe() и посмотри значения 25% и 75%), медиана 100 (тоже из describe лучше будет видно). Верхний ус лежит на примерно 500 с чем-то дней, это граница, за которой все остальное считаем выбросами","[{'name': '+1', 'users': ['U01C12GKE1E', 'U0185Q2MK19', 'U01BBD8GB7D'], 'count': 3}]",Алексей Глазов
1603620814.351000,1603620814.351000,U01BB74CMMG,"Проект принимается только, если код работает в тренажере, где старые версии pandas.",,Антон Дмитриев
1603620814.351000,1603620848.351100,U01BB74CMMG,"Вчера случился интересный казус, когда ревьюер не принял проект по причине ошибок в коде.
В итоге оказалось, что в тренажере версия pandas не поддерживает некоторый функционал.

Например,
• groupby не поддерживает аргумент dropna, 
• а plot не поддерживает текстовые значения для аргумента Y. 
Заданий 5 для проекта было выполнено с использованием данных возможностей... Однако, пришлось подстроиться под тренажер и переделать их.

Имейте в виду, когда будете сдавать проекты на проверку :happy-cat:

Может быть, после такого казуса Яндекс обновит библиотеки в тренажере? <@U0185Q2MK19> Техподдержке я уже написал, ответили: Используйте то, что есть в тренажере (""и не надо кричать в библиотеке!"" :hyperkitty: - это я уже сам домыслил )))))

На собеседовании работодателю также скажу: я учился в Яндекс, а в его тренажере старая библиотека pandas. И вообще, не придирайтесь ко мне - берите такого, какой есть:laughing:",,Антон Дмитриев
1603451447.330500,1603630115.352400,U01C12H8HJL,"<@U0185Q2MK19> про статистику да, уже видела, что ее надо подтягивать, список литры составлен) За уточнения по поводу линейной алгебры спасибо большое","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Юлия Филоненко
1603139426.245500,1603635507.353100,U01B4EZSWHL,"<@U0185Q2MK19> Объясните пожалуйста, откуда у нас  row['total_floors_in_house'], не совсем понимаю...",,Лиза Толмачева
1603645391.353700,1603645391.353700,U01BB74F8GJ,Вопрос про отображение шага на осях,,Митя Журавлев
1603645391.353700,1603645430.353800,U01BB74F8GJ,"<@U0185Q2MK19> подскажи, пожалуйста, как менять отображение подписей на осях",,Митя Журавлев
1603139426.245500,1603656198.355300,U01BBD8TXJ7,<@U01B4EZSWHL>  в наших данных это столбец row[‘floors_total’],"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Андрей Черненко
1603552576.340500,1603657014.355500,U01B4EXCR7G,"<@U0185Q2MK19> Очень странно, что предупреждения начали вылезать именно сегодня и именно при  создании новых столбцов в датафрейме. Мой пример <https://pastebin.com/WD0FTBtu>",,Сергей Саранцев
1603552576.340500,1603689909.357500,U01AWENRANB,<@U01B4EXCR7G> у меня они сразу появлялись в большей или меньшей степени :woman-shrugging: ,,Ксения Ушакова
1603613629.349600,1603689972.357700,U0185Q2MK19,"В дополнение к хорошему ответу Алексея я бы порекомендовал почитать материалы о том, как вообще стоит интерпретировать гистограммы:

<http://sixsigmaonline.ru/baza-znanij/22-1-0-228>
<https://habr.com/ru/post/267123/>",,Олег Булыгин
1603139426.245500,1603690194.358100,U0185Q2MK19,"<@U01B4EZSWHL>, да, Андрей верно подсказывает. Это просто общее количество этажей из исходных данных.",,Олег Булыгин
1603645391.353700,1603690800.358400,U0185Q2MK19,"<@U01BB74F8GJ>, привет!

Зависит от того, как и какую визуализацию ты строишь :slightly_smiling_face:
Предположу пока такой вариант:
```ax = код для построения визуализации

# это подписи осей
ax.set_xlabel('подпись')
ax.set_ylabel('подпись')

# это точки по осям
ax.set_xticks(значения)
ax.set_yticks(значения)```
<https://www.tutorialspoint.com/matplotlib/matplotlib_setting_ticks_and_tick_labels.htm>",,Олег Булыгин
1603552576.340500,1603691035.358600,U0185Q2MK19,"Тут надо не только на loc все изменения переписать, но и каждое изменение сохранять в новом датафрейме, а не менять исходный. Тогда предупреждения  быть не должно.

Ну а на крайняк просто отрубите его:
```import warnings
warnings.filterwarnings('error')```
",,Олег Булыгин
1603620814.351000,1603691918.359000,U0185Q2MK19,"<@U01BB74CMMG>, привет!

В целом согласен, что желательно, чтобы всегда все было самое актуальное.

Но

В реальной жизни далеко не всегда будет возможность использовать актуальные версии. Часто надо поддерживать уже написанные решения, которые легче (дешевле) именно поддерживать, а не переписывать с нуля на актуальных версиях библиотек.

А если в компании все очень строго с политикой безопасности, то обновления библиотек может быть той еще эпопеей.  У меня есть много личных примеров, когда в очень крупных технологически продвинутых компаниях (которые все знают) невозможно просто поставить нужные пакеты или их обновить (легче написать на том, что есть, а не пробиваться через бюрократию).

Поэтому в реальной жизни вы придете в компанию, вам дадут тестовое задание, а вы прифигеете от того, что у них версии всего будут еще старее, чем на тренажере в яндексе.

Поэтому правда надо уметь и так, и так. Тем более это не сложно.",,Олег Булыгин
1603704824.359700,1603704824.359700,U01C12DM2BA,Столбец с расстоянием до центра в километрах,,Фарид Бабаев
1603704824.359700,1603704844.359800,U01C12DM2BA,Что я не так делаю?,,Фарид Бабаев
1603704824.359700,1603705082.360100,U01C12GJCGY,"<@U01C12DM2BA> Привет, во второй строчке там где piter, замени его на df, у меня точно такая же проблема была и все ушло",,Миронов Владислав
1603704824.359700,1603705150.360300,U01C12DM2BA,<@U0185Q2MK19> то есть я не могу оперировать срезом как отдельным датафреймом?,,Фарид Бабаев
1603704824.359700,1603707699.360500,U01BHCRMNGL,Piter = df.query(...).copy(),"[{'name': '+1', 'users': ['U01BHCPPL2Y'], 'count': 1}]",Дарья Баранкова
1603704824.359700,1603707740.360700,U01BHCRMNGL,"Попробуй добавить copy(), что бы создать новую таблицу",,Дарья Баранкова
1603704824.359700,1603708499.361000,U01BHCPPL2Y,"без copy() твой срез ссылается на исходный датафрейм, если ты хочешь работать со срезом как с отдельной таблицей - нужно добавлять сору()",,Me_
1603712467.362100,1603712467.362100,U01BHCPLXHS,Заголовки для графиков в библиотеке seaborn,,Вероника Гром
1603712467.362100,1603712619.362200,U01BHCPLXHS,"<@U0185Q2MK19>, подскажи, пожалуйста, как добавить заголовки графиков (например, для sns.boxplot). В документации не получается найти, а если указывать plt.title, то новый график рисуется пустой с установленным заголовком",,Вероника Гром
1603712467.362100,1603712732.362400,U01BB72RSH0,"<@U01BHCPLXHS>, на Stack Overflow <https://stackoverflow.com/questions/42406233/how-to-add-title-to-seaborn-boxplot|пишут> про использование метода `.set_title()`. Он не подходит?","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1603712467.362100,1603712871.362700,U01BHCPLXHS,"<@U01BB72RSH0>, спасибо! на самом деле поторопилась с вопросом, достаточно было указать plt.title до графика, а я указывала после и не получалось","[{'name': 'ok_hand', 'users': ['U01BB72RSH0'], 'count': 1}, {'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1603704824.359700,1603720436.363100,U0185Q2MK19,"Всем привет!

На самом деле это не ошибка, а предупреждение, что не так страшно)

Про него можно почитать здесь:
<https://www.dataquest.io/blog/settingwithcopywarning/>
<https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas>

В целом мысль такая, что все изменения лучше записывать в новые датафреймы, а не работать с исходным. Для всех изменений рекомендуются использовать loc.

А можно просто эти предупреждения отключить, если ты уверен, что результат получается верным)",,Олег Булыгин
1603801947.365300,1603801947.365300,U01C12JD9TJ,"Установка окружения, работа с локальным Jupyter Notebook",,Алиса Ручкина
1603801947.365300,1603802037.365400,U01C12JD9TJ,"<@U0185Q2MK19>, привет, возникли сложности с установкой окружения, после скачивания anaconda  . И пара маленьких сопутствующих вопросов. В notion было написано обратиться к куратору, но меня отправили к тебе",,Алиса Ручкина
1603801947.365300,1603802062.365600,U01C12JD9TJ,,,Алиса Ручкина
1603801947.365300,1603808427.366100,U0185Q2MK19,"<@U01C12JD9TJ>, привет!
Не знаю, почему ко мне, ну да ладно :sweat_smile:

2) Jupyter по умолчанию открывается в директории пользователя на ПК. Соответственно, ты видишь все файлы и папки, которые у тебя там находятся. Если ты их удалишь, то они удаляться из системы. Если они тебе нужны - их не надо удалять)
3) Можно нажать на квадратик слева от названия файла. Появятся опции с его удалением/перемещением/переименованием и пр. А еще можно зайти в этот файл, нажать сверху на имя - и можно будет его поменять.
1. Я, если честно, не сталкивался с такой проблемой. Убедись, что путь к файлу прописан верно. Не исключаю, что это что-то специфичное именно для mac, но у меня не mac :disappointed:","[{'name': '+1', 'users': ['U01C12JD9TJ'], 'count': 1}]",Олег Булыгин
1603801947.365300,1603808776.366400,U01C12JD9TJ,"<@U0185Q2MK19>, спасибо! Попробую разобраться.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Алиса Ручкина
1603620814.351000,1603844744.367100,U01BB74CMMG,"Это конечно замечательно, но вебинары проходят обычно на колабе, а там ребята показывают примеры и учат нас на основе этих методов,которые в итоге тренажер не воспринимает в дефолтном состоянии. 

И тут возникает противоречие. Берешь знания, полученные на вебинаре, применяешь, отправляешь  файл абсолютно рабочего проекта, а ревьюер их не принимает, т.к. тренажер ошибку выдает...  А крайний остаюст я, т.к. должен был догадаться, о том, что мы должны уметь работать на всех версиях подключаемых модулей, а перед отправкой файла проекта - проверить эти версии (где тех усовия?), на которых он работает, сравнить с тренажером и отправить <@UTTGJQS6M>. Зачем тогда дали возможность загружать файлы своих блокнотов, а тех условия проверки и версионность мобулей не указали? В итоге, море потраченного времени...

И про несложно: это не сложно, - абсолютно согласен. Но весь наш день тратится на решения несложных задач, которыми бы хотелось управлять, знать о них заранее и строить свой тайминг, а не решать внезапные задачи, просто потому, что это несложно.
Плюс 'Не сложно и нужно' или 'несложно и входит в курс обучения (разным версиям модулей)' - абсолютно разные вещи.

Спасибо за понимание.",,Антон Дмитриев
1603620814.351000,1603861429.368000,U0185Q2MK19,"<@UTTGJQS6M>, привет! Мы можем как-то оставить команде запрос на актуализацию версий библиотек на сервере?",,Олег Булыгин
1603620814.351000,1603869462.368200,UTTGJQS6M,"Привет! Да, сейчас подсвечу команде. Спасибо!",,Маргарита Минеева
1603620814.351000,1603871026.368400,UTTGJQS6M,"Чтобы не было таких казусов стоит просто установить себе практикумовское окружение в Анаконду (в доп. материалах есть информация, как это сделать).
Так ты сразу будешь понимать что сработает у ревьюера.

Вообще, обновлять библиотеки на платформе достаточно сложно. Знаю, что ребята думают, как это сделать правильно и чтобы ничего не перестало работать. Так что запрос в работе :paw:",,Маргарита Минеева
1603620814.351000,1603874894.368600,U01BB74CMMG,"Ураааа!!!! Спасибо)) а можно заодно и модуль с расширениями, включив там навигацию по заголовкам и редактор горячих клавиш - будет огонь :catshake:",,Антон Дмитриев
1603645391.353700,1603914381.372900,U01BB74F8GJ,"Олег, спасибо","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Митя Журавлев
1603368540.315600,1603963109.373200,U01B84D31FF,"<@U0185Q2MK19> Привет! Ревьюер тоже попросил меня сделать подписи, с этим все в порядке, столкнулся с другой проблемой, у меня в проекте строится 4 гистограммы подряд одинаковым кодом, а нужно сделать через функцию. не понимаю как сделать функцию так чтобы добавить описание к каждому графику. <https://pastebin.com/GYE68wHF>",,Кирилл Солодков
1603368540.315600,1603976744.373600,U0185Q2MK19,"<@U01B84D31FF>, привет!

На примере гисторамм:
если все визуализации одинаковые по параметрам - просто в цикле перебираем столбцы и применяем к каждому нужный метод для построения  графика. Примерно так:

```for column in df[['total_area', 'rooms', 'ceiling_height']]:
    df[column].hist()
    plt.show()```
б) если у визуализации параметры разные, то можно сделать так:
```d = {'m_price': 30,
'rooms': 30}

for key, value in d.items():
    flats_info[key].hist(bins=value)```
Т.е формируем словарь из столбцов-параметров и так же в цикле применяем это к каждому столбцу.",,Олег Булыгин
1603368540.315600,1603977170.373900,U01B84D31FF,"<@U0185Q2MK19> Спасибо, а как в таком случае для каждого графика добавить подпись?",,Кирилл Солодков
1603368540.315600,1604036874.374300,U0185Q2MK19,"<@U01B84D31FF>, под подписью имеешь ввиду заголовок или подписи осей x и y? Подписи осей можно так:

```
for key, value in d.items():
    ax = flats_info[key].hist(bins=value)
    ax.set_xlabel(подпись)
    ax.set_ylabel(подпись)```
Сами подписи так же можно поместить в словарь параметров (значениями, например, можно сделать списки)",,Олег Булыгин
1603620814.351000,1604061723.374800,U01BB72P2HG,"<@U0185Q2MK19> столкнулась в проекте с проблемой, на компе у меня в юпитере рассчитывается корреляция (corr) без проблем. тот же код копирую и вставляю на платформу - выдает ошибку TypeError: 'float' object cannot be interpreted as an integer :pensive: код не меняла, просто из своего черновика копипастю. может ли это быть связано с тем, что платформа не поддерживает какие-то функции??",,Мария Пименова
1603620814.351000,1604061800.375000,U01BB74CMMG,"Конечно моежт, я даже целый тред об этом написал ))",,Антон Дмитриев
1603620814.351000,1604061894.375400,U01BB72P2HG,<@U01BB74CMMG> я сейчас буду плакать:sob::joy: у меня так красиво табличка все показывает без 100500 графиков)))) а теперь что делать то)))),,Мария Пименова
1603620814.351000,1604061952.375900,U01BB74CMMG,У меня проблемы были с plot и groupby ))  Смысл тот же )),,Антон Дмитриев
1603620814.351000,1604062625.376300,U01BB74CMMG,"<@U01BB72P2HG> часто бывает, что предыдущий код в ячейках не выполнен, соответственно DF имеет значения не тех форматов или вообще пустой. Или пропуски есть (поля с которыми можно во float перевести) .Выдели ячейку с кодом, где ошибка, нажми на значок клавиатуры, на панели меню, там выбери run...above, потом попробуй запустить... И ссылку на исходник нужно прицепить сюда ) иначе никто не поймет в чем дело )",,Антон Дмитриев
1603620814.351000,1604063066.376500,U01BB72P2HG,"код на компе: <https://yadi.sk/i/m_AWYq2NzT1XLA>
код на платформе: <https://yadi.sk/i/J0UAikNk6eE6nw>

<@U0185Q2MK19>",,Мария Пименова
1603620814.351000,1604063315.376800,U01BB74CMMG,"а на 2ом
скрине не все строки",,Антон Дмитриев
1603620814.351000,1604063345.377000,U01BB72P2HG,"<@U01BB74CMMG> выдает ошибку TypeError: 'float' object cannot be interpreted as an integer :pensive: код не меняла, просто из своего черновика копипастю.",,Мария Пименова
1603620814.351000,1604063396.377200,U01BB72P2HG,"т.е. на компе корреляции с float рассчитывает, а на платформе нет. перевести в int не получается, потому что отказывается переводить в int столбцы где есть Nan:+1::woman-facepalming:",,Мария Пименова
1604072968.378300,1604072968.378300,U01AWENRANB,Помесячный расчёт ,,Ксения Ушакова
1604072968.378300,1604073058.380400,U01AWENRANB,"Привет <@U0185Q2MK19>, 
подскажи пожалуйста, расчёт количества звонков и прочего трафика надо рассчитывать помесячно, то есть январь, февраль и тд, или все-таки отталкиваясь от даты регистрации пользователя? ",,Ксения Ушакова
1603620814.351000,1604076749.380600,U0185Q2MK19,"<@U01BB72P2HG>, да, тут проблема абсолютно аналогичная. Все из-за версии seaborn в окружении Практикума. Просто не меняй цветовую схему, это самый безболезненый вариант",,Олег Булыгин
1604072968.378300,1604076979.380800,U0185Q2MK19,"<@U01AWENRANB>, привет!

Именно по календарным месяцам",,Олег Булыгин
1604072968.378300,1604077058.381200,U01AWENRANB,Спасибо! )),,Ксения Ушакова
1604134182.385000,1604134182.385000,U01C12GKE1E,вопрос по расчету выручки,,Гуменников Алексей
1604134182.385000,1604134552.385300,U01C12GKE1E,"Привет <@U0185Q2MK19>! При вычислении выручки от расходования интернета сверх лимита тарифа округление видимо нужно делать до гигабайта, т.к. дана ""стоимость дополнительного гигабайта интернет-трафика сверх тарифного пакета""? То есть, если дополнительно израсходовано 5 мб, то дополнительная  выручка на тарифе smart будет 200 руб?",,Гуменников Алексей
1604148676.386700,1604148676.386700,U01C12HG4QY,"Изучить следующие параметры: площадь, цена и т.д
Что имеется ввиду под словом ""изучить""?",,Маргарита К
1604148676.386700,1604148864.386800,U01C12G0QNL,"<@U01C12HG4QY> Привет. Нужно построить гистограммы для этих параметров и оценить, есть ли выбросы, средние значения и т.п.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Михаил Перцев
1604148676.386700,1604149144.387000,U01C12HG4QY,"Привет! Поняла, спасибо",,Маргарита К
1604134182.385000,1604149391.387200,U0185Q2MK19,"<@U01C12GKE1E>, не округлять не нужно)

В гигабайте 1024 мегабайта, исходим из этого",,Олег Булыгин
1604134182.385000,1604150875.387500,U01C12GKE1E,<@U0185Q2MK19> то есть 200 руб делим на 1024 мегабайта  и умножаем на каждый мегабайт сверхтрафика?,,Гуменников Алексей
1604161861.388400,1604161861.388400,U01B84HU32R,Замена пропусков в living\kitchen area,,Виктория Онучина
1604161861.388400,1604161961.388500,U01B84HU32R,"<@U0185Q2MK19> и остальные привет! Я тут затянула проект, сейчас активно засела. Пытаюсь заменить пропуски в жилой площади и в площади кухни. Хотела заменить таким образом: категоризировать квартиры по комнатам (однокомнатная, двухкомнатная и т.д.), а потом, как мы делали в прошлом проекте к заработной платой, ставить среднее значение. Но незадача: есть квартиры, где комнат по 8+, их малое количество, но не знаю могу ли я их удалить, потому что это уже 4 шаг.... Кто как заменял? Может подскажете чего..",,Виктория Онучина
1604162584.389000,1604162584.389000,U01BBD515GB,Оформление проекта по статистическому анализу данных,,Владимир Кабанов
1604162584.389000,1604162682.389100,U01BBD515GB,"<@U0185Q2MK19>, добрый день. Подскажи, в этом проекте нет предзаполненной структуры проекта в юпитере как в предыдущих проектах и ее надо создать самостоятельно, или у меня что-то проглючило?",,Владимир Кабанов
1604134182.385000,1604164258.389300,U01BB72RSH0,"<@U01C12GKE1E>, я исходил из того, что операторы обычно продают сверхлимитный трафик пакетами. То есть если при превышении лимита по мегабайтам у абонента не отключается интернет, то ему обычно автоматом подключают дополнительный пакет (например, тот же гигабайт) - в итоге в проекте я итоговый траффик абонента в гигабайтах за месяц округлял принудительно вверх. Пример: у абонента на тарифе ""Смарт"" за месяц набежало `18,37` гигабайт - плату за сверхлимитный интернет я считал в данном случае как `(19 - 15) * 200 = 800 ₽`",,Шилоносов Артём
1604161861.388400,1604164648.394200,U01BHCPLXHS,"<@U01B84HU32R>, привет! Я удаляла все значения более 7 комнат, признавала их выбросами. Замены не делала в площади, так как посчитала, что это самый главный параметр при покупке квартиры и если его не указали в объявлении, значит там что-то мутное и замена средним может исказить выводы",,Вероника Гром
1604161861.388400,1604164805.394400,U01B84HU32R,"<@U01BHCPLXHS> спасибо! Как понимаю ты именно в 4 шаге удаляла значения? Я вот тоже думаю с 7 оставить, а 8+ удалить. По поводу того, чтобы оставить... Наверное имеет смысл, но общая-то площадь указана, я просто по себе сужу, что сначала выбирала по общей площади, а там уже рассматривала глубже куда как распределяют, хмм. Буду думать))",,Виктория Онучина
1604134182.385000,1604164995.395200,U01C12GKE1E,<@U01BB72RSH0> так и думаю сделать. <@U0185Q2MK19> так правильно или нет?,,Гуменников Алексей
1604161861.388400,1604165234.398900,U01BHCPLXHS,"<@U01B84HU32R>, да удаляла на 4 шаге. По поводу жилой и кухни - я исходила из того, что сложно судить по соотношению, так как может быть перепланировка, свободная планировка и тд у квартир с любым количеством комнат. И опять же раз такую важную инфу утаили - то вопросики, почему. Я анализировала дальше соотношение суммы жилой и кухни на общую. И там уже искала явные не состыковки",,Вероника Гром
1604162584.389000,1604165270.399100,U01C12GKE1E,"<@U01BBD515GB> структуры действительно нет. В предыдущем проекте ревьюер указал мне, что её обязательно нужно сделать.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Гуменников Алексей
1604161861.388400,1604165317.399400,U01B84HU32R,"<@U01BHCPLXHS> хм, имеет смысл быть, спасибо. Я правильно понимаю, что ты просто заменяла на NaN? Ну чтобы они не считались как пустые, а были со значением.",,Виктория Онучина
1604162584.389000,1604165380.399600,U01BBD515GB,"<@U01C12GKE1E> понял, спасибо",,Владимир Кабанов
1604161861.388400,1604169230.399800,U01C12G0QNL,"<@U01B84HU32R> привет. Я заменял на медианные значения по количеству комнат. Ещё вариант - найти среднее соотношение с общей площадью среди известных данных и заполнять пропуски, отталкиваясь от этих средних.","[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Михаил Перцев
1604161861.388400,1604172783.400100,U01B84HU32R,<@U01C12G0QNL> а комнаты категоризировали? или по срезам заменяли?..,,Виктория Онучина
1604178981.400900,1604178981.400900,U019E3T5678,Среднее значение стоимости жилья в зависимости от удаленности от центра,,Ольга
1604178981.400900,1604179036.401000,U019E3T5678,"Не могу понять, как отсортировать по медиане значение после группировке
Ожидаемый код не работает
<http://pastie.org/p/225m49pPe4tcSkSiAEapUI>",,Ольга
1604178981.400900,1604180680.402000,U01C12H8HJL,<@U019E3T5678> вот в этом треде вроде есть ответ на твой вопрос <https://yandex-students.slack.com/archives/G01B461LV0E/p1603208748267300>,,Юлия Филоненко
1604178981.400900,1604180681.402200,U019E3T5678,"И похожий чем-то вопрос: я хочу построить график по сгруппированной таблице. Но не пойму, как правильно вызвать медиану по цене
<https://pastebin.com/8MLwruts>",,Ольга
1604178981.400900,1604180907.402900,U019E3T5678,<@U01C12H8HJL> спасибо большое! ответ на второй вопрос нашла:),,Ольга
1604178981.400900,1604180991.403100,U01C12H8HJL,"<@U019E3T5678> не за что, товарищ-полуночник)",,Юлия Филоненко
1604134182.385000,1604207566.403300,U0185Q2MK19,"Оба варианта допустимы, главное обоснуйте свое решение ревьюеру)",,Олег Булыгин
1604161861.388400,1604207710.403500,U0185Q2MK19,"Я бы сказал, что хорошим вариантом является именно вычисление отношения площади кухни/жилой к общей в разрезе каких-то других признаков (например, количества комнат)",,Олег Булыгин
1604178981.400900,1604208122.403800,U0185Q2MK19,"<@U019E3T5678>, по первому вопросу - у тебя кавычки не там стоят, надо вот так: `.sort_values(('price_m2', 'median'), ascending = False)`",,Олег Булыгин
1604161861.388400,1604208206.404000,U01C12G0QNL,"<@U01B84HU32R> нет, я сделал через группировку и transform",,Михаил Перцев
1604210798.404500,1604210798.404500,U01BB72MR6E,Создание цикла для подсчета минут сверх тарифа,,Юлия Сова
1604210798.404500,1604211284.404600,U01BB72MR6E,"<@U0185Q2MK19> Привет! Помоги, пожалуйста, понять, что делаю не так. Хочу написать цикл, чтобы в новой колонке писать, сколько экстра минут потратил пользователь в мес (сверх своего тарифа). Пишу цикл, но выдает ошибку KeyError: 'user_id'. <https://pastebin.com/GDqpSxQx>
tariffs тут - это табличка, которая дана изначально. general_data - я собрала по юзерам и месяцам все их минуты-сообщения и пр.",,Юлия Сова
1604210798.404500,1604212097.404900,U0185Q2MK19,"<@U01BB72MR6E>, привет!

Тут цикл вообще не нужен. Надо написать функцию и применять ее к датафрейму.

Я бы предложил примерно такой вариант (исходя из того, что предварительно должны быть рассчитаны все показатели сверх тарифа):

```def get_revenue(row):
    if row['minutes_overrun'] &gt; 0:
        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']

    if row['messages_overrun'] &gt; 0:
        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']

    if row['mb_overrun'] &gt; 0:
        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']

    return revenue_by_min + revenue_by_messages + revenue_mb ```
То есть мы считаем перерасход для каждой услуги и умножаем на стоимость. Потом через apply применяем это к таблице.  А потом прибавляем доходы по самому  тарифу.

Напиши, понятно ли :slightly_smiling_face:",,Олег Булыгин
1604210798.404500,1604215413.405100,U01BB72MR6E,"<@U0185Q2MK19> В целом понятно, но на этапе применения функции к таблице опять ошибка..
general_data['get_revenue'] = general_data.apply(get_revenue, axis=1)
```UnboundLocalError: (""local variable 'revenue_by_min' referenced before assignment"", 'occurred at index 0')```
",,Юлия Сова
1604161861.388400,1604217224.405300,U01B84HU32R,"<@U0185Q2MK19> а подскажи, вроде нельзя transform использовать к числам. В прошлом проекте мы использовали столбец по типу занятости, он был object. Я просто где-то в тредах здесь читала, что он ругаться будет, если работать с float и transform..

Или по поводу вычисления отношения ты имел в виду, что писала Вероника? Но это уже, вроде, следующий пункт, следовательно оставить пропуски.... Хм, буду думать!",,Виктория Онучина
1604161861.388400,1604217255.405500,U01B84HU32R,"<@U01C12G0QNL> спасибо, да, пока что в терминологии путаюсь. Понимаю о чем пишу, но объясняю криво. Моя мысль была как раз об этом. Спасибо!",,Виктория Онучина
1604210798.404500,1604229730.406000,U01BHCPPL2Y,"Цикл пиши так:
for i in range(df.shape[0]):
    if df['col'][i] - df['col2'][i]...",,Me_
1604134182.385000,1604230743.406200,U01BB72RSH0,"<@U01C12GKE1E>, <@U0185Q2MK19>, ревьюер сказал в обязательном порядке месячный траффик приводить к гигабайтам и округлять в большую сторону)",,Шилоносов Артём
1604239257.407000,1604239257.407000,U01BHCRRVNG,Объединение таблиц,,Валерия Круглова
1604239257.407000,1604239606.413000,U01BHCRRVNG,"<@U0185Q2MK19> Привет!
Никак не могу сообразить как мне обьединить несколько датафреймов, перепробовала кучу способов, то тетрадь крашится, то просто ошибки. Пробовала и merge() и join(). Причём при помощи join() можно объединить сразу несколько датафреймов, везде написано «передайте списком», однако нигде нет примера. 2 таблицы получается соединить, а дальше никак. Подскажи, пожалуйста ",,Валерия Круглова
1604134182.385000,1604239793.413200,U0185Q2MK19,"<@U01BB72RSH0>, не факт, что у другого ревьюера будет такой же подход)",,Олег Булыгин
1604161861.388400,1604239975.413400,U0185Q2MK19,"<@U01B84HU32R>, в transform для нашего случая передается агрегирующая функция ведь (mean, meadian и пр.). Они без проблем работают с float. никаких проблем быть не должно.
Я как раз имел ввиду, что можно заполнить пропуски исходя из среднего соотношения площади кухни к общей площади в разрезе такого же количества квартир)",,Олег Булыгин
1604210798.404500,1604240029.413600,U0185Q2MK19,"<@U01BB72MR6E>

забыли учесть пользователей, которые не пользовались какой-то из услуг:sweat_smile:
```def get_revenue(row):
    revenue_by_min = 0
    revenue_by_messages = 0
    revenue_mb = 0

    if row['minutes_overrun'] &gt; 0:
        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']

    if row['messages_overrun'] &gt; 0:
        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']

    if row['mb_overrun'] &gt; 0:
        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']

    return revenue_by_min + revenue_by_messages + revenue_mb ```
","[{'name': '+1', 'users': ['U01BB72MR6E'], 'count': 1}]",Олег Булыгин
1604161861.388400,1604240167.413800,U01B84HU32R,"<@U0185Q2MK19> агааа, поняла твою мысль! Буду думать как реализовывать такое)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604239257.407000,1604241340.414200,U0185Q2MK19,"<@U01BHCRRVNG>, я бы всегда рекомендовал использовать merge, он удобнее, чем join. То, что каждую таблицу нужно будет присоединять отдельным действием - ничего страшного.

Я подозреваю, что ты пытаешься объединить несгруппированные таблицы (где есть одинаковые значения в столбце, по которому объединяем), поэтому возникают проблемы, но надо смотреть на сам код.

Уточни, что с чем конкретно  у тебя не получается соединить?",,Олег Булыгин
1604210798.404500,1604241997.418300,U0185Q2MK19,"<@U01BB72MR6E> (напиши, получилось ли в итоге :slightly_smiling_face: ) и для всех - опишу примерный поэтапный алгоритм этой задачи:

1. формируем сначала объединенный датафрейм абсолютно со всей информацией (данные по всем пользователям за каждый месяц, где сразу есть потраченные мб, минуты, смс и ограничения тарифа).
2. В этом датафрейме считаем перерасход по каждой услуге каждого пользователя в каждом месяце. Это просто делаем вычитанием значений по столбцам, примерно так
```costs['minutes_overrun']  = costs['minutes'] - costs['minutes_included']
costs['messages_overrun'] = costs['messages'] - costs['messages_included']
costs['mb_used_overrun']  = costs['mb_used'] - costs['mb_per_month_included'] ```
3. считаем доход примерно по такой функции:
```def get_revenue(row):
    revenue_by_min = 0
    revenue_by_messages = 0
    revenue_mb = 0

    if row['minutes_overrun'] &gt; 0:
        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']

    if row['messages_overrun'] &gt; 0:
        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']

    if row['mb_overrun'] &gt; 0:
        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']

    return revenue_by_min + revenue_by_messages + revenue_mb```
Циклы тут не нужны нигде)","[{'name': '+1', 'users': ['U01C12JD9TJ', 'U01C12H8HJL'], 'count': 2}]",Олег Булыгин
1604239257.407000,1604242807.428400,U01BHCRRVNG,"<@U0185Q2MK19> Да, не сгруппированные :grimacing:
Думала сделать так: создать единый датафрейм, где будет объедение данных о пользователях, звонках, сообщениях и интернете. Наверное плохо поняла работу методов, предполагала, что раз, например, в таблице «calls» user-id повторяется много раз, то если ее обьединить с данными о пользователях, то конечная таблица будет содержать в себе повторяющиеся строки данных о пользователях столько раз, сколько он совершил звонков. 

Теперь хочу уточнить, получается мы группируем таблицы со звонками, сообщениями и интернетом по user_id, объединяем с таблицей, которая содержит данные о пользователе (туда будет включена сумма минут, например), а для расчёта «количество сделанных звонков по месяцам» все равно используем первоначальную таблицу со звонками, где есть дата звонка? 

Код сейчас загрузить не могу, да и загружать там нечего, все переписано много раз)) ","[{'name': 'heavy_plus_sign', 'users': ['U01C12H8HJL'], 'count': 1}]",Валерия Круглова
1604239257.407000,1604243019.428800,U0185Q2MK19,"<@U01BHCRRVNG>, да, мы сначала группируем таблицы по пользователям (и месяцам!), а потом их объединяем. То есть мы сразу можем рассчитать количество звонков через агрегацию, группирую по двум столбцам.",,Олег Булыгин
1604239257.407000,1604243063.429300,U01BHCRRVNG,<@U0185Q2MK19> Спасибо! ,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Валерия Круглова
1604210798.404500,1604246278.429600,U01BB72MR6E,"<@U0185Q2MK19> да, круто, так получилось!","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Юлия Сова
1604239257.407000,1604249250.429900,U01C12GJCGY,"<@U0185Q2MK19> привет, подскажи пожалуйта, а как можно месяцы по звонкам, сообщениям и сессиям инета объединить?",,Миронов Владислав
1604265487.432400,1604265487.432400,U01B84HU32R,Обнуление индексов с процентным содержанием,,Виктория Онучина
1604265487.432400,1604265532.432500,U01B84HU32R,"<@U0185Q2MK19> привет! В прошлом проекте ревьюер написал, что обнуление индексов при удаление строк - круто, но было бы хорошо показать процентное содержание удаленных строчек. А как это сделать и зачем это делать?",,Виктория Онучина
1604268766.433300,1604268766.433300,U01B84HU32R,"0 комнат, но не студия",,Виктория Онучина
1604268766.433300,1604268999.433400,U01B84HU32R,"<@U0185Q2MK19> прям полно вопросов по таблице. Изучала я тут данные, крутила. Заменила на медиану площадь кухни в зависимости от количества квартир. Глянула: 194 пропуска, 0 комнат - тоже 194 штуки. Супер, думаю, студии значит, там же указывают лишь жилую площадь. Но не тут-то было. Начала смотреть так ли это, сделала срез по studio==True, а там 146... Начала смотреть studio==False, там тоже 0 комнат (только почему-то их дам 59, а не 58, не очень понимаю... 146+59 - это 195, а у меня 194, если смотреть value_counts по столбцу rooms в датафрейме).

Короче, пока все это смотрела, запуталась. И вот вопрос: что делать с 0 комнат, но не студия. Удалять? Заменить false на true, если комнат 0? И, наверное, самое главное: а в какой момент мне поставить, что я нашла такой косяк?...  Можно ли это проделать в предобработке или лучше делать в шаге 4, когда все углубленно изучаем.",,Виктория Онучина
1604239257.407000,1604290095.433800,U0185Q2MK19,"<@U01C12GJCGY>, тут надо объединять не месяцы сами по себе, а исходные таблицы сгруппированные по пользователям и месяцам.
Т.е.:

1. Группируем таблицы звонков, смс, интернета по пользователям и месяцам
2. объединяем их между собой при помощи merge
3. сюда же добавляем таблицы пользователей и тарифов
4. в итоге у нас есть одна общая таблица с данными для всех нужных вычислений",,Олег Булыгин
1604265487.432400,1604290307.434000,U0185Q2MK19,"<@U01B84HU32R>, привет!

Не уверен, что до конца понимаю вопрос. Процентное соотношению пропусков к общему количеству строк в столбце, может быть? Это я понимаю :slightly_smiling_face:
А что такое процентное соотношение удаленных строчек сходу не соображу, уточни)",,Олег Булыгин
1604268766.433300,1604290591.434200,U0185Q2MK19,"<@U01B84HU32R>, тут не может быть единственно правильного ответа, но я бы поступил так:
1. где 0 комнат и студия - не трогал бы
2. где 0 комнат и это явно не студия - сделал бы замену нулей и обосновал ревьюеру подход
3. я бы отразил это в предобработке ",,Олег Булыгин
1604268766.433300,1604291563.434400,U01BB74BJ9G,"<@U01B84HU32R> 0 комнат у квартир- студий и квартир с открытой планировкой., Поэтому я везде менял 0 на 1",,Владимир Саков
1604265487.432400,1604297351.434600,U01BB72RSH0,"<@U01B84HU32R>, <@U0185Q2MK19>, если правильно понял вопрос, то я бы требуемый процент считал <https://pastebin.com/db0QitDh|так>, где `df_before` - датафрейм до удаления строк, `df_after` - после.",,Шилоносов Артём
1604265487.432400,1604302158.434900,U01AWENQ0R5,"<@U01B84HU32R> можно сохранить в какую-нибудь переменную количество строк начального датафрейма, вытащив это число из .shape , а потом в другую переменную таким же образом - оставшееся кол-во строк. И поделить их",,Volkhin Roman
1604265487.432400,1604307247.435100,U01B84HU32R,"<@U0185Q2MK19> ага, да, я про процентное соотношение пропусков к общему количеству строк в столбце. Но там ребята ниже написали, буду думать, если есть какой-то ещё вариант, то круто)) 

Объяснять в терминологии на пальцах явно не мое..",,Виктория Онучина
1604268766.433300,1604307326.435300,U01B84HU32R,"<@U0185Q2MK19> спасибо! <@U01BB74BJ9G> ещё ниже написал про открытые планировки, видимо я как-то упустила этот показатель, нужно будет глянуть.",,Виктория Онучина
1604265487.432400,1604308587.435500,U0185Q2MK19,"<@U01B84HU32R>, самое простое - использовать вот такое действие:

```for col in df.columns:
    pct_missing = df[col].isnull().mean()
    print(f'{col} - {pct_missing :.1%}')```
Так мы получим процент пропусков в каждом столбец.",,Олег Булыгин
1604265487.432400,1604312470.435700,U01B84HU32R,"<@U0185Q2MK19> а если, к примеру, я делаю `df.isnull().sum()`, после которого видео сколько где пропусков, то зачем делать процент пропусков? Просто чтобы знать? Я вот плохо понимаю пока что для чего эти процентные показатели.
И ещё, например, в прошлом проекте я оставляла только то, где возраст был не равен 0. Пропусков там не было, лишь возраст 0. Ревьюер написал, цитирую, ""Все отлично и молодец, что обнуляешь индексы. Здесь хорошо бы выводить процент удаленных значений"". А зачем? Для чего? Я выводила сколько каких уникальных значений в строке, 0 оказалось в размере 101, не так много, решила удалить, вроде все описывала, а просили процент этих значений...",,Виктория Онучина
1604265487.432400,1604316058.435900,U01AWENQ0R5,"<@U01B84HU32R> просто для того, чтобы понимать, сколько строк от исходного датафрейма осталось после предобработки, т.е. какой процент от исходных данных мы будем использовать для анализа, я так это понимаю",,Volkhin Roman
1604265487.432400,1604316184.436100,U01B84HU32R,"<@U01AWENQ0R5> хм, просто если там какие-то большие проценты (как, например, в этом проекте мы оставляем какие-то данные с пропусками, а там их по 6-8к может быть), то я ещё могу понять, но когда из 21к строк убираем лишь 101... там даже процента не будет...",,Виктория Онучина
1604265487.432400,1604317562.436300,U01AWENQ0R5,"<@U01B84HU32R> ну видишь, это ты знаешь, сколько их, потому что ты это ты делала) а руководитель, к примеру, не будет же в код вчитываться, ему надо посмотреть на вывод и увидеть сколько)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Volkhin Roman
1604265487.432400,1604319361.436500,U01B84HU32R,<@U01AWENQ0R5> тоже верно),,Виктория Онучина
1604239257.407000,1604323589.436700,U01C12GJCGY,<@U0185Q2MK19> спасибо большое,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Миронов Владислав
1604239257.407000,1604330412.438600,U01B84JJ5L5,"<@U0185Q2MK19> привет! есть 2 таблицы и я хочу объединить их по столбцу tariff, что бы в таблице al содержалась информация по тарифному плану, как это сделать? что-то не могу додуматься",,Ингвар Сильницкий
1604210798.404500,1604340025.438900,U01BB72RSH0,"<@U0185Q2MK19>, а не лучше ли считать перерасход по минутам внутри функции и там же его перемножать на стоимость дополнительной минуты/сообщения/гигабайта? У нас все же разный лимит в зависимости от тарифа по всем трем показателям будет:thinking_face:",,Шилоносов Артём
1604342920.439600,1604342920.439600,U01963FA11V,Проверка гипотез,,Елена Беспалова
1604342920.439600,1604343170.443400,U01963FA11V,"<@U0185Q2MK19> привет) у меня считает р-значение: 4.4309654556е-302 :see_no_evil: Где может быть ошибка подскажи пжл. Код раньше: results=st.ttest_ind(sm,ul,equal_var=False)",,Елена Беспалова
1604348955.443800,1604348955.443800,U019E3T5678,Заполнение медианой после группировки,,Ольга
1604348955.443800,1604349014.443900,U019E3T5678,Я хочу заполнить медианой пропущенные значения по площади.,,Ольга
1604348955.443800,1604349055.444100,U019E3T5678,"Сделала вот такую группировку <https://pastebin.com/3mG2CsNs>
И хочу этими значениями заполнить.
Но не понимаю, как. Тут же нет индексов, чтобы использовать merge",,Ольга
1604348955.443800,1604349259.444300,U019E3T5678,<@U0185Q2MK19>,,Ольга
1604348955.443800,1604349366.444600,U019E3T5678,,,Ольга
1604348955.443800,1604349415.444900,U01B84HU32R,"<@U019E3T5678> Вы пытаетесь, как понимаю, заполнить пропуски в площади жилой? Лучше это делать через transform. Это есть вот в этом треде: <https://yandex-students.slack.com/archives/G01B461LV0E/p1601471861031700>
Я сама через него заменяю, да и в первом проекте через него заменяла значения как раз благодаря треду. Необязательно даже категоризировать, спасибо Олегу за подсказку, transform работает и с float.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604348955.443800,1604352639.445700,U019E3T5678,<@U01B84HU32R> Спасибо большое :hugging_face:,,Ольга
1604354255.448400,1604354255.448400,U01B84HU32R,Большая площадь кухни при маленькой общей площади,,Виктория Онучина
1604354255.448400,1604354459.448500,U01B84HU32R,"<@U0185Q2MK19> и еще раз здравствуй ахах. Так, столкнулась с тем, что у квартир большая площадь кухни, но маленькая общая площадь. Есть квартиры, где кухня 18 метров, а общая площадь 40. Хочу отсортировать данные, но как правильно отсортировать кухню не понимаю. Думаю, что с жилой площадью будет такая же история, потому что видела данные, где площадь 40 и жилая 18 и при кухня 18...
Есть мысли, что нужно узнать какой-то примерный максимальный процент, который кухня может занимать от площадь квартиры. И если этот процент меньше, то удовлетворяет. Естественно это еще и при условии, что площадь кухни мы тоже обработаем (я решила оставить значения больше 5,5, но не выбрала еще меньше какого, так как застряла на таких приколюхах с большой кухней).",,Виктория Онучина
1604354255.448400,1604354768.448700,U01B84HU32R,"<@U0185Q2MK19> и еще вопрос к тебе такой, как правильно поступить. Вот у нас в шаге 4 есть ""исследуйте площадь"", но ей Богу, не могу я спокойно заменять значения кухни, не исследуя все. Даже если опираться на то, что нужно найти какой-то определенный процент.. Не брать же его в интернете, ведь там тоже от типа квартиры зависит. Брать какой-то средней процент по всем данным в зависимости от количества комнат? Тоже странно, ведь есть двухкомнатные квартиры с площадью 20 квадратных метров, что не может быть правдой... А обрабатывать площадь не могу, если делать по шагам...",,Виктория Онучина
1604342920.439600,1604374065.451700,U01BB72MR6E,"<@U01963FA11V> у меня похожее значение - это просто оочень маленькое число, близкое к 0. Вроде это не ошибка - ревьюер засчитал как верное",,Юлия Сова
1604239257.407000,1604377412.452000,U0185Q2MK19,"<@U01B84JJ5L5>, привет!

Нужно использовать метод merge с указанием аргумента on (on='tarrif')",,Олег Булыгин
1604210798.404500,1604377780.452200,U0185Q2MK19,"<@U01BB72RSH0>, на мой взгляд тут достаточно простейших действий со столбцами. Они ведь учитывают разницу между тарифами.
Условно говоря, если у нас строка с пользователем по тарифу ультра, то в minutes_included у него будет цифра именно по тарифу ультра, аналогично по мб и смс. Поэтому и нужно перед этими действиями присоединить к нашей таблице данные по tariffs",,Олег Булыгин
1604342920.439600,1604377942.452400,U0185Q2MK19,"Да, в таком значении нет ничего необычного, это число близкое к нулю.",,Олег Булыгин
1604348955.443800,1604378675.452800,U0185Q2MK19,"<@U01B84HU32R>, хотел бы все же поправить на счет категоризации. Конечно, ее делать не обязательно, группировка все равно сработает, но надо смотреть на сколько это осмысленно.

Когда мы группируем данные, как правило, мы хотим делать группы по каким-то осмысленным категориям. Делать группировку по столбцу с непрерывной величиной без предварительной категоризации может не дать результата. Но тут надо смотреть на конкретный кейс",,Олег Булыгин
1604354255.448400,1604379134.453000,U0185Q2MK19,"<@U01B84HU32R>, мне кажется, ты ищешь подвох там, где его нет :slightly_smiling_face:

Почему думаешь, что таких квартир не может быть?
В нашем конкретном кейсе заполнять пропуски, конечно, надо осмысленно. Выбросы тоже стоит найти, когда они действительно находятся за пределами разумных значений.

Но искать в данных фактические ошибки исходя из того, что ""кухня такой большой быть не может"", на мой взгляд, не стоит)

На счет пропуска по кухням - как я уже и писал, вариант заполнения средним соотношением площади кухонь к общей площади в разрезе количество комнат  - вполне хороший. Естественно, мы используем исключительно наши данные.
Не уверен, что нас должны смущать двухкомнатные квартиры в 20 квадратов. Я специально сейчас зашел на Циан и сходу нашел двухкомнатные квартиры в 22-23 квадрата. Значит такое бывает)",,Олег Булыгин
1604239257.407000,1604383179.455700,U01B84JJ5L5,"<@U0185Q2MK19> я пробовал так миллион раз, но ничего не выходило, а потом понял, что я забыл сохранить таблицу al в новую переменную в прошлом действии и когда я пытался замержить, то в al у меня не было столбца tariff :tired_face::tired_face:",,Ингвар Сильницкий
1604354255.448400,1604389230.455900,U01B84HU32R,"<@U0185Q2MK19> так, хорошо. Вот кухни я заменила, допустим. Я просто немного (а видимо много) не понимаю, когда значения выбивающиеся, когда нет, если мы рассматриваем несколько взаимосвязанных. Наверное разумно сделать какую-то отдельную сводную таблицу или посмотреть на графиках. Или просто сделать срез, где общая площадь будет меньше суммарной площадь жилой и кухни (а такое в данных тоже есть). Или, когда исследуем значения, просто отдельные столбцы рассмотреть, независимо от того, какую часть кухня занимает от общей площади?.. :catshake:",,Виктория Онучина
1604342920.439600,1604391423.456300,U01963FA11V,спасибо :slightly_smiling_face:,,Елена Беспалова
1604348955.443800,1604397140.458000,U019E3T5678,"<@U0185Q2MK19> Олег, а как можно без трансформ решить задачу? Вот я посчитала медиану в отдельной таблице. Хочу использовать эти данные для заполнения. Как это можно сделать?",,Ольга
1604178981.400900,1604397288.458400,U019E3T5678,"<@U0185Q2MK19> спасибо, точно",,Ольга
1604354255.448400,1604405406.458600,U0185Q2MK19,"<@U01B84HU32R>, да, найти позиции, где суммарная площадь кухни+жилая больше общей - разумное решение. Если в изначальных данных такое есть, то с этим надо что-то сделать.

Всегда стоит изучать распределения (по гистограммам и боксплотам, которые еще и выбросы покажут), смотреть на основные метрики через describe. Как правило, этого достаточно. По категориальным признакам можно смотреть распределение через value_counts()

Если тебя смущает то, что ты не всегда можешь понять, является ли значение выбросом - это нормально. В реальных бизнес-ситуациях в таком случае нужно уточнять эти моменты у коллег, которые отвечали за формирование данных и лучше понимают, почему так может быть. Когда таких коллег нет - твоя задача выдвинуть предположения и обосновать свои решения. Если ты готова доказать ревьюеру, что не бывает маленьких квартир с такими огромными кухнями - можно попробовать, но я не думаю, что в данных есть такие подвохи)",,Олег Булыгин
1604348955.443800,1604405513.458900,U0185Q2MK19,"<@U019E3T5678>, тогда все замены делать можно делать, например, через loc, указывая по какой группе производить замену и на какое конкретно значение. Вот здесь можно посмотреть возможные способы: <https://kanoki.org/2019/07/17/pandas-how-to-replace-values-based-on-conditions/>",,Олег Булыгин
1604239257.407000,1604405561.459200,U0185Q2MK19,"<@U01B84JJ5L5>, ничего страшного, бывает)",,Олег Булыгин
1604419475.459700,1604419475.459700,U01AWENRANB,Функция для столбца дф,,Ксения Ушакова
1604419475.459700,1604421163.462700,U01AWENRANB,"<@U0185Q2MK19>, привет!
Подскажи пожалуйста как можно написать функцию, которая будет расчитывать например среднее по некоему столбцу датафрейма, при указании названия столбца?
В тренажере применяли функцию apply, но она работала как бы по горизонтали, а я хочу по вертикали :smiley:",,Ксения Ушакова
1604419475.459700,1604422296.462900,U01C12G0QNL,"<@U01AWENRANB> Привет. Если в apply не передавать аргумент axis, то по умолчанию функция будет применяться к столбцу, а не строке.",,Михаил Перцев
1601665967.084400,1604426500.463100,U01BBD50335,"<@U0185Q2MK19> , Здравствуйте! Скажите пожалуйста если я превращу данные двух столбцов с NaN(у которых есть значение в первоначальной таблице) в нули, будет правильно?",,Гогу Зинаида
1601665967.084400,1604426981.463500,U01BBD50335,<@U0185Q2MK19> Прикрепляю ссылки,,Гогу Зинаида
1604072968.378300,1604428347.463900,U01AWENQ0R5,"<@U0185Q2MK19> а если бы нужно было считать именно от регистрации? Т.е. если бы месяц считался с 25 числа по 25, например? Какие бы тогда нужно было предпринимать действия? Что-то задумался об этом и ничего в голову не приходит",,Volkhin Roman
1604431490.464600,1604431490.464600,U019E3T5678,Что смотреть в диаграмме рассеивания?,,Ольга
1604431490.464600,1604431602.464700,U019E3T5678,"Ревьюер написал мне следующее. Хотелось больше узнать об этом. Я правильно понимаю, что теоретически, если я нарисовала эту диаграмму и не вижу там условно какой-то линейной функции (ну грубо), то корреляции быть не должно.",,Ольга
1604419475.459700,1604466966.466700,U0185Q2MK19,"Все верно. А еще есть функция map, которая работаем именно с Series, а не датафреймами, ее тоже можно использовать.",,Олег Булыгин
1604431490.464600,1604467063.466900,U0185Q2MK19,"<@U019E3T5678>, привет!

Да, по scatter plot очень удобно выдвигать первичные гипотезы о взаимосвязи величин. Если в ней не проглядывается взаимосвязь (не обязательно линейная, по диаграмме будут видны и другие формы зависимости), то ее скорее всего и нет.  Если коэффициент линейной корреляции большой, а форма зависимости явно нелинейная - то коэффициент корреляции ничего нам не скажет.


Как именно читать такие диаграммы можно почитать, например, здесь: <https://datavizcatalogue.com/RU/metody/diagramma_rassejanija.html>",,Олег Булыгин
1604419475.459700,1604467521.468200,U01AWENRANB,Спасибо! ,,Ксения Ушакова
1601665967.084400,1604467638.468400,U0185Q2MK19,"<@U01BBD50335>, привет!

Скорее нет, чем да. Мы по таблице видим, что у многих людей с NaN в стаже указана форма занятости (как можно быть сотрудником компании, с нулевым стажем?) Ну и плюсом к этому есть и доход и образование. Очень маловероятно, что у этих людей нулевой стаж. Скорее его надо попытаться восстановить по каким-либо другим признакам.

Аналогично с доходом. Скорее всего, это какая-то техническая проблема и данные надо попытаться восстановить",,Олег Булыгин
1604072968.378300,1604468431.468600,U0185Q2MK19,"<@U01AWENQ0R5>, тогда я бы составил промежуточную таблицу, где у каждого пользователя были свои собственные периоды оплаты.

Т.е. в индексе user_id и периоды по месяцам от даты регистрации до текущей. И заполнил бы эту таблицу исходя из дат звонков/смс/трафика. Но вопрос тогда в том, как считать доход. Для каждого пользователя по его периоду тарифа? А зачем это бизнесу, бизнес живет по своим отчетным месяцам",,Олег Булыгин
1604419475.459700,1604475228.470500,U01AWENRANB,"<@U0185Q2MK19> не понимаю, почему не получается, уже все что можно перепробовала, вот этот вариант кажется самым рабочим, но нет 

<http://joxi.ru/DmBb187T4o3nam|http://joxi.ru/DmBb187T4o3nam>
<https://pastebin.com/WdyJCSm0|https://pastebin.com/WdyJCSm0>

Объясни пожалуйста, почему не работает? ",,Ксения Ушакова
1604483003.471300,1604483003.471300,U01BBD8R6N7,Шаг 3 в проекте про Мегалайн. Непонятно задание,,Даша Свечкина
1604483003.471300,1604483116.471400,U01BBD8R6N7,"В задании написано: посчитайте среднее количество, дисперсию и стандартное отклонение. Постройте гистограммы. Опишите распределения. - <@U0185Q2MK19>, добрый день. Подскажи, пожалуйста, здесь имеется в виду по месяцам по тарифам или общие показатели по тарифам? И что за гистограммы?",,Даша Свечкина
1604489000.472000,1604489000.472000,U01C12GJCGY,проверка гипотезы,,Миронов Владислав
1604489000.472000,1604489301.472100,U01C12GJCGY,"<@U0185Q2MK19> привет, подскажи пожалуйста, никак не могу понять, если у меня распределения отличные от нормального, нужно их как то приводить к нормальному, чтобы провести t- тест, а то получается что p-value = 0, мне кажется не должно быть так, ни как не могу сообразить?",,Миронов Владислав
1604483003.471300,1604494245.472400,U01BBD8EYR1,"Я тоже не поняла это задание. Я построила сводную таблицу с нужными статистиками по месяцам по агрегированным данным, где уже была посчитана сумма по месяцам для каждого пользователя. Но ревьюер попросил построить такую таблицу по неагрегированным данным. И я не понимаю, что мне нужно сделать. Если строить такую таблицу по неагрегированным данным, тогда все статистики будут по отдельному звонку/сообщению/сессии, а нужно же по месяцу и по пользователю. Я могу посчитать сумму помесячно и количество пользователей помесячно и поделить одно на другое - получу среднее, но это будет то же самое что и было.
Вот тут таблица по пользователям smart по агрегированным данным:
<http://joxi.net/Q2KPDzjiv8YPdA>
А это таблица по неагрегированным данным:
<http://joxi.ru/KAg67gETKqQWz2>
Или вообще нужно сделать расчет без разбивки по месяцам, но с агрегацией по пользователям и сумме их звонков в месяц?
<http://joxi.ru/J2bPNgJiVaPZ7r>",,Евгения Батухтина
1604134182.385000,1604495959.472700,U01BBD8EYR1,"Тоже вопрос  по округлению - в условии не четко сказано: нужно конкретный разговор/сессию округлять до целого значения или уже сумму? Была бы я оператором, я бы каждый разговор/сессию приводила бы к целому значению. Мой ревьюер пишет, что нужно сумму округлять за месяц,  но мне так не кажется верным.",,Евгения Батухтина
1604483003.471300,1604499034.472900,U01BB72RSH0,"<@U01BBD8R6N7>, перед этой фразой там имеется вопрос, в котором сказано: ""Опишите поведение клиентов оператора, исходя из выборки. Сколько *минут разговора*, сколько *сообщений* и какой *объём интернет-трафика* требуется пользователям *каждого тарифа* в *месяц*?"". Соответственно, среднее, дисперсию и стандартное отклонение необходимо считать для этих трех параметров - сначала минуты, сообщения и трафик для пользователей одного тарифа в месяц, а затем то же самое для другого. По этим же шести параметрам (3 + 3) необходимо построить диаграммы (например, гистограммы с корзинами).","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12H8HJL'], 'count': 2}]",Шилоносов Артём
1604419475.459700,1604500003.473100,U0185Q2MK19,"<@U01AWENRANB>, при твоей организации функции apply не применим, т.к. apply работает с датафреймами.

Если у тебя логика внутри функции применяет все действия к Series, дак просто и передавай нужный столбец аргументом к этой функции :slightly_smiling_face:

```def table(series):
    mean = series.mean().round(1)
    var = np.var(series, ddof=1).round(1)
    sqrt_var = np.sqrt(var).round(1)
    if mean - 3*sqrt_var &gt; 0:
        bottom = mean - 3*sqrt_var
    else:
        bottom = 0
    top = mean + 3*sqrt_var
    return pd.DataFrame([mean, var, sqrt_var, bottom, top])
 
table(ultra['calls_duration'])```
",,Олег Булыгин
1604483003.471300,1604500038.473300,U01BB72RSH0,"<@U01BBD8EYR1>, попробуй сначала сделать <https://pastebin.com/XuLJ6HJF|такую> сводную таблицу. А затем уже объединяй ее со сводной таблицей датафрейма `users`, которая будет аналогично сгруппирована по столбцам с ID пользователя и месяцем.
В принципе половина от всей работы на третьем проекте - это извлечение сводных таблиц из исходных датафреймов (за исключением датафрейма с тарифами - в нем сводить нечего) и последующее объединение этих сводных таблиц в один большой датафрейм, по которому мы и будем считать среднее, дисперсию и стандартное отклонение для выборок, включающих пользователей разных тарифов и т.д.",,Шилоносов Артём
1604489000.472000,1604500381.473500,U0185Q2MK19,"<@U01C12GJCGY>, привет!

Нет, к нормальному распределению ничего приводить не надо. При проверки гипотез один из результатов точно будет близко к нулю (но не ноль). Если у тебя получается именно ноль, то надо смотреть на код, где-то ошибка.",,Олег Булыгин
1604483003.471300,1604500625.473700,U01BBD8EYR1,"<@U01BB72RSH0> у меня такая таблица как раз и есть, я по ней изначально и строила помесячный расчет. Она у меня calls_users называется. Выглядит вот так <http://joxi.ru/Dr8JWRoUMbGa42>
Там у меня лежат суммарные данные по каждому пользователю по месяцам и добавлен столбец с тарифом.
 И зачем эту таблицу объединять с пользователями?",,Евгения Батухтина
1604483003.471300,1604500801.474100,U01BB72RSH0,"<@U01BBD8EYR1> с общим датафреймом будет намного проще, когда потребуется считать выручку по каждому абоненту и проверять гипотезы на шаге 4.",,Шилоносов Артём
1604483003.471300,1604500890.474400,U01BBD8EYR1,"<@U01BB72RSH0> такая у меня тоже есть, гипотезы я по ней уже посчитала, мне их зачли, а вот третий шаг сказали переделать, и я не пойму, что сделала не так.",,Евгения Батухтина
1604483003.471300,1604501338.474600,U01BB72RSH0,"<@U01BBD8EYR1>, хм. Вот <http://joxi.ru/Q2KPDzjiv8YPdA|эти> дисперсия и стандартное отклонение - это единственные дисперсия и стандартное отклонение, которые считались по звонкам, или же ты считала дисперсию и стандартное отклонение в том числе по данным таблицы `calls_users`? Если по `calls_users` расчет был и ревьюер их не принял, то тут уже код и результат его выполнения смотреть надо, чтобы понять почему ревьюер их не принял.",,Шилоносов Артём
1604134182.385000,1604501488.474900,U0185Q2MK19,"<@U01BBD8EYR1>, я бы тоже округлял минуты вверх. Так и работает в реальности, если тариф поминутный, а не посекундный. Но если конкретный ревьюер так видит :man-shrugging:  Можно попробовать обосновать ему/ей свой подход и убедить)",,Олег Булыгин
1604483003.471300,1604501639.475100,U01BBD8EYR1,"smart_calls -  это у меня производная таблицы calls_users, где данные только по тарифу smart.
<http://joxi.ru/vAWPRzViO4vJ9r>
Кроме изначального суммирования, я больше ничего с этой таблицей не делала.
У меня сейчас единственное предположение, что нужно убрать в расчете разбивку по месяцам и сравнивать вот такие цифры.
<http://joxi.net/J2bPNgJiVaPZ7r>",,Евгения Батухтина
1604134182.385000,1604501841.475500,U01BB72RSH0,"<@U01BBD8EYR1>, <@U0185Q2MK19>, так про округление же говорится прямо под описанием тарифов в исходных данных: ""*Обратите внимание*: «Мегалайн» всегда округляет вверх значения минут и мегабайтов. Если пользователь проговорил всего 1 секунду, в тарифе засчитывается целая минута."" Речь здесь идет именно про округление в пределах разговора / сессии.
Быть может ревьюер пишет про округление суммы за месяц именно по гигабайтам?",,Шилоносов Артём
1604483003.471300,1604502143.475700,U01BB72RSH0,"<@U01BBD8EYR1>, теперь понятно: сводную таблицу от сводной строить не нужно. Среднее, дисперсию и стандартное отклонение (если говорить про длительность звонков), требуется определить по данным столбца `duration` датафрейма `calls_users` для двух срезов: сначала для абонентов тарифа ""Смарт"", а затем для среза по абонентам тарифа ""Ультра"".",,Шилоносов Артём
1604134182.385000,1604502358.476000,U01BBD8EYR1,"<@U01BB72RSH0> Я сделала округление только на этапе подсчета выручки, но ревьюер этого не заметил и написал, что нужно было сделать округление при подсчете суммы минут и гигабайт. Но я теперь подумала, что стоит каждый разговор/сессию округлять. Я напишу об этом ревьюеру, посмотрим, что будет.  Сейчас я данные уже округлила, но ревьюер сделал мне замечание после создания агрегированной таблицы по пользователям со звонками.

<http://joxi.ru/LmGPq97ilkQbg2>",,Евгения Батухтина
1604483003.471300,1604502696.476500,U01BBD8EYR1,<@U01BB72RSH0> то есть я убираю разбивку по месяцам и получаю нужные значения? но я их получаю опять же через сводную таблицу.,,Евгения Батухтина
1604134182.385000,1604502785.476700,U01BB72RSH0,"<@U01BBD8EYR1> Понял. Ревьюер здесь пишет про то, что на этапе предварительной обработки данных требуется:
1. в датафрейме `calls` округлить длительность каждого отдельного звонка до минут в большую сторону.
2. в датафрейме `internet` округлить длительность каждой отдельной интернет-сессии до мегабайта.
Уже после этого данные можно упаковывать в сводные таблицы. Думаю, что это решение должно ревьюера устроить.",,Шилоносов Артём
1604134182.385000,1604502897.476900,U01BBD8EYR1,"<@U01BB72RSH0> наверное так и есть. Спасибо большое, что помогаете разобраться. Сложно общаться по переписке, не всегда понятно, что ревьюер имеет ввиду.","[{'name': '+1', 'users': ['U01BB72RSH0'], 'count': 1}]",Евгения Батухтина
1604134182.385000,1604503210.477200,U0185Q2MK19,"Я подумал, что ты округляла все вверх, а ревьюер хочет округления только месячной выручки вверх)  Издержки переписки)",,Олег Булыгин
1604483003.471300,1604503269.477500,U01BB72RSH0,"<@U01BBD8EYR1>, не совсем. Здесь именно суть в том, что нам надо свести исходные данные в сводные таблицы, где будет сумма по фактическому месячному использованию каждого из параметров (минуты, сообщения, мегабайты) разными пользователями: среднее здесь не подойдет. Простой пример: я - пользователь тарифа ""Смарт"" и обычно укладываюсь в лимиты тарифа, но в феврале я превысил лимит по минутам, в июле - по сообщениям, в декабре - по гигабайтам, потому в эти месяцы платил больше абонентской платы за тариф. Задача и состоит в том, чтобы собрать в сводную таблицу вот такие вот помесячные данные по каждому из 500 пользователей и смотреть по этим данным среднее, дисперсию и стандартное отклонение.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1604134182.385000,1604503394.477900,U01BBD8EYR1,"<@U0185Q2MK19> а я подумала, что ревьюер хочет округления уже суммированных значений, так как написал свое замечание после создания такой таблицы :smiley:","[{'name': 'sweat_smile', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгения Батухтина
1604483003.471300,1604503769.478200,U01BBD8EYR1,"<@U01BB72RSH0> так у меня нет в таблице среднего! у меня как раз в таблице calls_users лежат данные по сумме минут и количество звонков для каждого пользователя за каждый месяц. И я сейчас хочу посчитать среднее, дисперсию и стандартное отклонение сразу по всей этой таблице без разбивки по месяцам. Изначально я сделала с разбивкой по месяцам. Удобней всего это сделать через сводную таблицу.",,Евгения Батухтина
1604483003.471300,1604503983.478400,U01BBD8EYR1,"<@U0185Q2MK19> помогите разобраться, пожалуйста!

Если я сделаю так, это будет правильно?
<http://joxi.ru/4AkK0gZTk4W6nA>",,Евгения Батухтина
1604483003.471300,1604505271.478800,U01BB72RSH0,"<@U01BBD8EYR1> думаю, что <http://joxi.ru/4AkK0gZTk4W6nA|это> - верный вариант.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Шилоносов Артём
1604419475.459700,1604505436.479600,U01AWENRANB,"Спасибо! Все получилось, ура! :tada:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Ксения Ушакова
1604483003.471300,1604506847.479800,U01BBD8EYR1,<@U01BB72RSH0> спасибо большое за ваши ответы!,"[{'name': '+1', 'users': ['U01BB72RSH0'], 'count': 1}]",Евгения Батухтина
1604489000.472000,1604507008.480100,U01C12GJCGY,"<@U0185Q2MK19> просто даже не знаю где ошибся, все делал через merge, но не получается <https://pastebin.com/z5NtxeiA> это код гипотезы, <https://pastebin.com/2CnCAuck> это я объединял тариф ultra, это график выручки по ultra <http://joxi.ru/J2bdzZxUVqwOnr>  и по smart <http://joxi.ru/vAWE8GWuO3VQ7m> , и такой же код для smart, мне кажется делаю что то нето, подскажи пожалуйста где нужно исправить?",,Миронов Владислав
1604489000.472000,1604507542.480400,U01C12GJCGY,может столбец id нужно было оставить?,,Миронов Владислав
1604509544.481100,1604509544.481100,U01B4EYRJ5U,Округление чисел в большую сторону,,Ольга Соколовская
1604509544.481100,1604509633.481200,U01B4EYRJ5U,"<@U0185Q2MK19> Привет! подскажи, пожалуйста, как правильно окгруглить значения по длительности звонка до целого числа в большую сторону? например, round() значение 5.18 округляет до 5, а ceil() не работает",,Ольга Соколовская
1604489000.472000,1604509670.481400,U01BB72RSH0,"<@U01C12GJCGY>, хм, а на этапе предобработки данных ты не извлекал из дат звонков/сообщений/интернет-сессий значения месяцев? Посмотрел код и вроде бы ты это совсем под конец задачи делаешь, ввиду чего сводные таблицы некорректно формируются.",,Шилоносов Артём
1604509544.481100,1604509719.482400,U01BB72MR6E,<@U01B4EYRJ5U> попробуй np.ceil( ),"[{'name': 'heavy_plus_sign', 'users': ['U01BB72RSH0', 'U01BPRKQP9P'], 'count': 2}]",Юлия Сова
1604509544.481100,1604509741.482600,U01BB72RSH0,"<@U01B4EYRJ5U>, `df['column_name'] = df['column_name'].apply(np.ceil)`","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12HASTA'], 'count': 2}]",Шилоносов Артём
1604509544.481100,1604509847.482900,U01B4EYRJ5U,"<@U01BB72MR6E> <@U01BB72RSH0> спасибо большое, получилось)","[{'name': '+1', 'users': ['U01BB72RSH0', 'U01BB72MR6E'], 'count': 2}]",Ольга Соколовская
1604489000.472000,1604511314.483300,U01C12GJCGY,"да извлекал чтобы посчитать все по месяцам все звонки/ сообщения/ интернет, а так все в предобработке",,Миронов Владислав
1604489000.472000,1604512606.484800,U01BB72RSH0,"<@U01C12GJCGY>,  датафрейм data какой длины получился?",,Шилоносов Артём
1604489000.472000,1604512999.485000,U01C12GJCGY,если просто data то 202000 грубо говоря,,Миронов Владислав
1604489000.472000,1604514073.488600,U01BB72RSH0,"<@U01C12GJCGY>, учитывая то, что абонентов у нас 500, а месяцев всего 12, то строк в общем датафрейме должно получиться не более 500 * 12 = 6000. Точно проблема в том, что месяцы не извлекал, а если и извлекал, то объединял таблицы, не используя столбец с месяцами.",,Шилоносов Артём
1604489000.472000,1604514503.488800,U01C12GJCGY,все равно че-то не соображу,,Миронов Владислав
1604518493.489400,1604518493.489400,U01BBD8JS75,Добавление к таблице столбца из другой таблицы,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1604518493.489400,1604519026.489500,U01BBD8JS75,"<@U0185Q2MK19> нужна помощь знатока)
Я слепил таблицу из user_id, month, calls_sum, calls_count, messages_count, mb_sum. Нужно добавить в эту таблицу сведения, каким тарифом пользуется юзер. Хотел это сделать <https://pastebin.com/de0gzhMz|так.>
Но появляется ошибка. Подскажи пожалуйста что не так с кодом или какой другой способ есть чтобы добавить тарифы в мою таблицу",,Алексей Глазов
1604518493.489400,1604520219.489900,U01BBD8JS75,"Как вариант можно пойти по длинному пути: к таблице user присоединить таблицу tariff, затем это все присоединить к моей таблице, и удалить лишние столбцы) но хотелось бы проще это сделать",,Алексей Глазов
1604527647.490600,1604527647.490600,U01C12HDRUG,Расчет дисперсии и стандартного отклонения.,,Елена Угдыжекова
1604527647.490600,1604527725.490700,U01C12HDRUG,"Помогите, пожалуйста, понять физический смысл этих величин. Рассчитать их рассчитала, но какой вывод можно сделать по их значениям?:exploding_head:",,Елена Угдыжекова
1604489000.472000,1604550440.491700,U0185Q2MK19,"<@U01C12GJCGY>, надо бы посмотреть, как ты формируешь итоговую таблицу детально.

Попробуй так:

```user_calls = calls.groupby(['user_id', 'месяц'])\
                  .agg({'duration':'sum', 'id':'count'})\
                  .reset_index()\
                  .rename(тут можно переименовать столбцы для удобства)

user_messages = messages.groupby(['user_id', 'месяц'])\
                        .agg({'id':'count'})\
                        .reset_index()\
                        .rename()
user_internet = internet.groupby(['user_id', 'месяц'])\
                        .agg({'mb_used':'sum'})\
                        .reset_index()\
                        .rename()```
И потом уже все это дело объединяем по месяцу и пользователю. Например, вот так:
`df = user_calls.merge(user_messages, on=['user_id', 'месяц'], how='outer')`

Потом к ней присоединяем users и tariffs. И да, конечно, перед этим нужно извлечь месяца из всех дат.",,Олег Булыгин
1604518493.489400,1604550952.492000,U0185Q2MK19,"<@U01BBD8JS75>, ошибка связана с тем, что  в одной из таблиц нету столбца user_id (возможно, он в индексе?).

Я бы порекомендовал следующий порядок объединения:

```user_calls = calls.groupby(['user_id', 'месяц'])\
                  .agg({'duration':'sum', 'id':'count'})\
                  .reset_index()\
                  .rename(тут можно переименовать столбцы для удобства)

user_messages = messages.groupby(['user_id', 'месяц'])\
                        .agg({'id':'count'})\
                        .reset_index()\
                        .rename()
user_internet = internet.groupby(['user_id', 'месяц'])\
                        .agg({'mb_used':'sum'})\
                        .reset_index()\
                        .rename()```
Потом это все объединяем по месяцу и пользователю:
`df = user_calls.merge(user_messages, on=['user_id', 'месяц'], how='outer')`

И далее присоединяем тарифы и самих пользователей:

```df = df.merge(users, on='user_id', how='left')
df = df.merge(tariffs, on='tariff', how='left')```",,Олег Булыгин
1604527647.490600,1604551106.492200,U0185Q2MK19,"Они показывают среднюю степень разброса значений величины вокруг среднего :slightly_smiling_face:
А чем они меньше, тем больше значения концентрируются вокруг среднего.
СКО измеряется в единицах самой величины, а дисперсия - в ее квадратах",,Олег Булыгин
1604585720.493500,1604585720.493500,U01BBD8JS75,Разница в значениях посчитанных в ручную и отображаемую на диаграмме.,,Алексей Глазов
1604585720.493500,1604585991.493600,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, почему у меня в таблице медианы, которые я считал сам отличаются от медиан, которые отображены в диаграмме размаха?
Считал и строил <https://pastebin.com/mbzWYfcG|так>. В итоге для длительности звонков у меня посчитаны медианы 440 и 546, а на диаграме показывает 423 и 529",,Алексей Глазов
1604489000.472000,1604590346.494300,U01C12GJCGY,"<@U0185Q2MK19> ревьюер  проверил,  у меня код получился, но все равно гипотезу показывается 0, я объединил таблицы в одну вот так <https://pastebin.com/f6hC2NjB>, у меня образовалось 70тыщ пропущенных значений, может не так таблицы объединил?",,Миронов Владислав
1604600657.494800,1604600657.494800,U01B84HU32R,Срез убирает строки с NaN,,Виктория Онучина
1604600657.494800,1604600702.494900,U01B84HU32R,"<@U0185Q2MK19> и остальные привет! Делаю тут срез, чтобы в датафрейме остались нужные мне значения. Выглядит он вот так:
`df = df.query('kitchen_area + living_area &lt; total_area').reset_index(drop=True)`
Однако он удаляет мне строки, где имеются NaN в kitchen_area или living_area. Как их можно сохранить? Я думала о том, чтобы сделать отдельно срез по ненужным значениям, а потом как-нибудь убрать из датафрейма все значения, которые равны этому срезу (или оставить все значения, которые не равны этому срезу). Но как это сделать...

NaN хочу сохранить, потому что в противном случае он удалит мне огромную часть студий и открытых планировок (200 значений именно их). Я NaN оставила лишь у них, где не могла заполнить по логике.",,Виктория Онучина
1604600657.494800,1604603755.495400,U01B84HU32R,"<@U0185Q2MK19> так, я сделала чуть по другому, написала кусок функции:
`def total_true(df):`
`if df['kitchen_area'] + df['living_area'] &gt;= df['total_area']:`
    `return 'False'`
`else:`
    `return 'True'`
Хотела от него плясать, но ничего не выходит... <http://joxi.ru/4AkWQkxCkoEobA>",,Виктория Онучина
1604489000.472000,1604604375.496000,U01C12GJCGY,<@U0185Q2MK19> вроде получилось,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19', 'U01C12GKE1E'], 'count': 2}]",Миронов Владислав
1604600657.494800,1604604541.496200,U01B84HU32R,"<@U0185Q2MK19> доперло)))
Я же писала False и True как object, а не булевые значения, следовательно нужно было брать их как слова в ' '.
Однако мне все еще интересно, как тут сделать все можно легче, чтобы не вот так обходами :wait:",,Виктория Онучина
1604600657.494800,1604605200.496400,U01BB74CMMG,"Можно столбец создать, заполнить его true (df['total_true'] = True). Затем применить df['total_true'].where(kitchen_area + living_area &lt; total_area, False,inplace = True). Если тебе это действительно нужно )))


Согласно нормативам минимальное соотношение жилой к общей (в среднем, в зависимости от типа квартир) должна составлять не менее 40%. Получается, что если жилая площадь составляет менее 40% от общей, то это уже подозрительно ))

Соответственно, можешь создать столбец с отношением df['ratio_area'] = df['living_area'] / df['total_area'].

А значения, которые выведутся при:
df[df['ratio_area'] &gt;= 0.8] - будут подозрительными. Можно отсеять (вместо 40% взял 20%, т.к. есть уникальные квартиры старого фонда, включая переделанные в коммуналки - которые не поддаются логике )))",,Антон Дмитриев
1604606200.497300,1604606200.497300,U01C12DM2BA,Анализ корреляций,,Фарид Бабаев
1604606200.497300,1604606385.497400,U01C12DM2BA,"Как мне провести анализ корреляций признаков `last_price` и `цена за квадрат` с различными признаками: площадь, числа комнат, категории этажа, удалённости от центра, дня недели, месяца и года?
 Ревьюер еще сказал что нужно при анализе корреляций строить scatterplot и выводить коэффициенты корреляции, а также  зависимость с категориальными признаками (например комнатность, этажность, временные признаки) лучше прослеживается путем формирования сводных таблиц. <@U0185Q2MK19> Помоги ежику в тумане :hedgehog:",,Фарид Бабаев
1604610316.498100,1604610316.498100,U019E3T5678,При объединении таблиц пропали данные,,Ольга
1604610316.498100,1604610374.498200,U019E3T5678,"<@U0185Q2MK19> Подскажи пожалуйста, что я делаю не так? при такой записи

pre_revenue = calls.merge(user_msg, on=['user_id', 'month'], how='outer')
pre_revenue = pre_revenue.merge(user_mb, on=['user_id', 'month'], how='outer')
revenue

в объединенной таблице отсутствуют месяцы",,Ольга
1604610316.498100,1604610418.498400,U019E3T5678,,,Ольга
1604239257.407000,1604610786.498700,U01BB74F8GJ,"<@U0185Q2MK19> привет! а подскажи, пожалуйста, где в логике ошибка: я сгруппировал таблицы по `user_id` и месяцам, создав отдельный столбец для месяца в датасетах по сообщениям, звонкам и интернету
`calls_piv = calls.groupby(['user_id', 'month'])['duration'].agg('sum')`
Потом объединяю эти датасеты с таблицей по юзерам и почему-то месяцы у меня пропадают при объединении
`df = users.merge(calls_piv,on='user_id').merge(internet_piv,on='user_id').merge(messages_piv, on='user_id')`",,Митя Журавлев
1604600657.494800,1604611165.499000,U01B84HU32R,"<@U01BB74CMMG> привет! Да, я остальное буду отдельно рассматривать, то есть вот процент жилой по отношению к общей и процент кухни по отношению к общей, но они уже есть же отдельными столбцами, там легче будет))
Я сейчас на 4 шаге и остальные столбцы у меня есть. Меня больше интересовало, где сумма жилой+кухни было равно общей, я разобралась как сделать (вот как  я сделала), но как можно сделать легче именно этот кусок - интересно).",,Виктория Онучина
1604585720.493500,1604636430.002300,U0185Q2MK19,"<@U01BBD8JS75>, почему расчет СКО и дисперсии будет отличаться понятно сходу - в numpy по-умолчанию число степеней свободы принимается за 0, а в том же pandas - 1. Для одинакового  результата надо делать `np.var(ddof=1)`, `np.std(ddof=1)` .
По медиане сходу сообразить не могу. Я бы для начала рассчитал статистики при помощи describe и построил boxplot не через plotly, а через pandas, чтобы посмотреть на каком этапе будет разница.",,Олег Булыгин
1604489000.472000,1604636578.002600,U0185Q2MK19,"Надо только указывать метод outer при объединении :slightly_smiling_face:
В остальном все ок, если месяца выделены корректно.",,Олег Булыгин
1604585720.493500,1604636926.004100,U01AWENRANB,"<@U01BBD8JS75>, подскажи пожалуйста, как ты сделал такой бомбический график?",,Ксения Ушакова
1604600657.494800,1604637315.004300,U0185Q2MK19,"<@U01B84HU32R>, ну, применить так арифметику к данным, в которым есть NaN не получится. Лучше тогда сразу добавить проверку только по условию: *если living_area и kitchen_area не NaN И их сумма меньше total_area, то*...",,Олег Булыгин
1604585720.493500,1604637481.004500,U01BBD8JS75,<@U01AWENRANB> <https://pastebin.com/mbzWYfcG> с 6 строчки. df_month это моя склеенная таблица,,Алексей Глазов
1604606200.497300,1604637901.004700,U0185Q2MK19,"<@U01C12DM2BA>, привет!

1. Можно применить функцию pairplot из библиотеки seaborn для построения scatterplot matrix, которая построит точечные графики по всем парам нужных признаков. По результату можно будет выявить основные закономерности по числовых значениями.
2. Для расчета коэффициентов корреляции можно применить метод corr()  к нужному срезу датафрейма. Тут сразу будет видно, если какие-то величины сильно зависят друг от друга.

3. Да, зависимость нужных значений от категорий можно продемонстрировать через сводные таблицы. Например построить таблицу, в которой будет средняя цена за кв. метр на последнем, первом и прочих этажах. Или средняя цена за кв. метр по дням недели. Здесь же очень подойдет построение boxplotов.",,Олег Булыгин
1604239257.407000,1604638537.005300,U0185Q2MK19,"<@U01BB74F8GJ>, привет!

Ты забыл сделать reset_index после группировки (надо чтобы id и месяцы были в столбцах, а не в индексах).

Посмотри на вариант, который я писал ранее: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604550440491700?thread_ts=1604489000.472000&amp;cid=G01B461LV0E>",,Олег Булыгин
1604610316.498100,1604638582.005600,U0185Q2MK19,"<@U019E3T5678>, привет!

Подозреваю, что у тебя абсолютно аналогичная проблема: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604638537005300?thread_ts=1604239257.407000&amp;cid=G01B461LV0E>",,Олег Булыгин
1604585720.493500,1604638859.005900,U0185Q2MK19,"<@U01BBD8JS75>, полностью воспроизвел кейс у себя - у меня такой проблемы нет :slightly_smiling_face:
Поясни, почему у тебя в fig аргументом является df_month, а сводную таблицу ты строишь по medians? По идее это должна быть одна и та же таблица",,Олег Булыгин
1604600657.494800,1604647543.006300,U01B84HU32R,<@U0185Q2MK19> спасибо)),,Виктория Онучина
1604610316.498100,1604648085.006500,U01C12EF41E,"<@U0185Q2MK19>, доброе утро!

У меня объединить таблицы получилось, но пропадают 10 клиентов!, у <@U019E3T5678> таже ситуация, на ее фото тоже видно, что user_id  всего 1489, а должно быть 1499!

Все перепробовал, не могу понять куда деваются десять клиентов. Где ошибка, подскажи пожалуйста",,Иван Гончаров
1604483003.471300,1604653109.006800,U01BBD8R6N7,"Всем спасибо за ответы, разобралась. Надо было построить гистограммы по услугам(интернет, сообщения, длительность звонков) по исходным(неагрегированным) таблицам по каждому из тарифов.  А среднее значение, дисперсию и стандартное отклонение я посчитала итого по тарифам и ревьюер принял такое решение.",,Даша Свечкина
1604600657.494800,1604653485.007100,U01B84HU32R,"<@U0185Q2MK19> да уж, потом узнала, что как я сделала, тоже не так, все же я арифметику приписывала. А скажи, если я NaN не использовала для замены пропусков, ну то есть, не писала fillna и там NaN, то лучше сначала сделать это? И в принципе, если пропуски оставляю, из лучше на NaN заменить?

А ещё вопрос такой, это если гору обходить. Если я возьму срез квартир, которые НЕ студии и НЕ открытые планировки, посмотрю по нему, то как я могу потом указать, что мне из моего датафрейма нужно убрать строки, которые я нашла в срезе? Так вообще можно?",,Виктория Онучина
1604483003.471300,1604655118.010900,U01BBD8EYR1,<@U01BBD8R6N7> а какой смысл строить гистограммы по неагрегированным данным? Задание же было про поведение пользователей в сумме за месяц. А по неагрегировагным данным только разброс по единичным звонкам/сообщениям/выходам в интернет. С поведением пользователя за месяц это трудно связать,,Евгения Батухтина
1604483003.471300,1604655282.011100,U01BBD8R6N7,"<@U01BBD8EYR1> Вот комментарий, который мне оставил ревьюер ""Ты посмотрела, как меняются значения по месяцам. Это важная и полезная информация, безусловно. Однако здесь также важно посмотреть на данные без группировки по месяцам. Т.е вывести распределения кол-ва смс, которые отсылают все пользователи, по тарифам конечно же. Описать распределения""",,Даша Свечкина
1604483003.471300,1604655398.012800,U01BBD8EYR1,"<@U01BBD8R6N7> в этом комментарии не сказано, что нужно именно неагрегированные данные смотреть. Тут сказано, что нужно только убрать разбивку по месяцам",,Евгения Батухтина
1604483003.471300,1604655479.013000,U01BBD8R6N7,"Я агрегировала только по месяцам, поэтому без агрегации по месяцам получаются исходные таблицы",,Даша Свечкина
1604483003.471300,1604655533.013200,U01BBD8R6N7,"В общем смысл в том, чтобы посмотреть распределение исходных данных без дополнительных преобразований",,Даша Свечкина
1604483003.471300,1604655794.016100,U01BBD8EYR1,"<@U01BBD8R6N7> тогда мне вообще не понятен смысл этого задания. И правда, у тебя ревьюер попросил убрать группировку по месяцам для гистограмм, я это понимаю так, что группировка по месяцам остаётся в таблице, но я смотрю не на каждый месяц отдельно, а сразу все суммы по всем месяцам. Потому что задание было именно про поведение пользователей за месяц. ",,Евгения Батухтина
1604483003.471300,1604656206.016400,U01BBD8R6N7,"<@U01BBD8EYR1> Возможно, они не совсем точно сформулировали задание. Исходя из моего опыта сдачи проекта, я бы разделила это задание на 3 части. *1 часть* - _Опишите поведение клиентов оператора, исходя из выборки. Сколько минут разговора, сколько сообщений и какой объём интернет-трафика требуется пользователям каждого тарифа в месяц?_ - здесь мы строим таблицы/диаграммы по месяцам и пишем пояснения. *2 часть* - _Посчитайте среднее количество, дисперсию и стандартное отклонение._ - здесь мы считаем итоговые значения по каждому тарифу. Я считала без разбивки по месяцам. *3 часть* - _Постройте гистограммы. Опишите распределения._ - здесь мы возвращаемся к исходным таблицам, джойним к ним названия тарифов и строим гистограммы по каждой из услуг, описываем распределения. У меня получилось как на картинке ниже (это по интернету, я такие же построила по звонкам и сообщениям).",,Даша Свечкина
1604483003.471300,1604659640.017000,U01BBD8EYR1,"<@U01BBD8R6N7> мой проект зачли с гистограммами по суммированным данным за месяц, поэтому все еще остается вопрос к формулировке третьего задания.",,Евгения Батухтина
1604483003.471300,1604659711.017200,U01BBD8R6N7,"Окей, значит, зависит от ревьюера",,Даша Свечкина
1604585720.493500,1604660157.017400,U01BBD8JS75,"<@U0185Q2MK19> В моем случае medians это сводник, в котором посчитано сколько в среднем каждому пользователю требуется минут, смс и трафика. Затем при помощи еще одной сводной таблицы я ищу среднее по тарифам.
Код для построения совместных диаграмм мне показывал ревьюер и я решил применить его в этом проекте. Я не знал как совместить две диаграммы разброса на одном графике кроме этого способа))",,Алексей Глазов
1604610316.498100,1604662011.017700,U0185Q2MK19,"<@U01C12EF41E>, почему ты думаешь, что что-то пропало? В нашей сводной таблице идет группировка по месяцам и по id (они не обязательно должны быть по порядку). Просто выведи максимальный id, он будет равен 1499. Если это не так - прикладывай код и результаты, разберем детальнее)",,Олег Булыгин
1604610316.498100,1604662726.022800,U019E3T5678,"<@U0185Q2MK19> Спасибо) я хочу убедиться, что я правильно понимаю, почему это поможет. 
Я сделаю сброс индексов в таблице с групбай, после этого id и month перестанут быть индексами (индексами станут числа по порядку).

Но я не понимаю, почему без reset_index месяц не показывается",,Ольга
1604585720.493500,1604662739.023000,U0185Q2MK19,"<@U01BBD8JS75>, ну просто твоя визуализация берет данные из df_month, а там что-то явное не связанное с medians, поэтому и цифры другие)
Несколько boxplotов можно построить вместе, например так:

```import seaborn as sns
sns.boxplot(x=""tariff"", y=""month_calls_duration"", 
            data=df) ```
, где df  - сводная таблица.

Либо так (более красивый вариант, как у тебя):

```fig = px.histogram(df, x = 'month_calls_duration', color = 'tariff', marginal = 'box',
                  title = 'Распределение длительности звонков для тарифов Smart и Ultra')
fig```
df формируем так: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604550440491700?thread_ts=1604489000.472000&amp;cid=G01B461LV0E>

Никаких промежуточных дополнительных агрегаций через pivot_table вообще не надо, просто работаем с итоговой таблицей. Все расчеты можно сделать через describe",,Олег Булыгин
1604610316.498100,1604662885.023500,U0185Q2MK19,"<@U019E3T5678>, просто так работает merge) Он объединяет именно по столбцам, на индексы при объединении не смотрит, если не задавать доп. параметры.",,Олег Булыгин
1604610316.498100,1604663204.024400,U019E3T5678,<@U0185Q2MK19> так я же прописала оба столбца при объединении :woman-shrugging:,,Ольга
1604600657.494800,1604663747.024600,U0185Q2MK19,"<@U01B84HU32R>, 1) всю импутацию пропусков надо делать до любых расчетов, на этапе подготовке данных.
Не совсем понимаю вопрос про замену пропуска на NaN, ведь NaN - это и есть пропуски. Если ты прочитаешь файл и сразу посмотришь их количество при помощи df.isna().sum(), то все сработает, ничего дополнительно на NaN заменять не надо.

2) Технически из датафрейма можно удалить хоть что по условию при помощи метода drop: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html?highlight=drop#pandas.DataFrame.drop>
Но я вообще не понимаю, зачем это может быть надо конкретно в текущей работе :slightly_smiling_face:",,Олег Булыгин
1604600657.494800,1604664000.024900,U01B84HU32R,"<@U0185Q2MK19> окей, я все это знаю, все это сделала. Вопрос по-другому задам: будет ли в if в условии учитываться NaN, если столбец не типа object, но в нем есть пропуски? 

А по поводу второго: я удаляю ненужные на 4 шаге. И, вроде, это уже обсуждалось, что удалять такие строки смысл имеется. Спасибо!",,Виктория Онучина
1604610316.498100,1604664200.025100,U0185Q2MK19,"<@U019E3T5678>, тогда надо четко посмотреть, что у тебя внутри таблиц, которые объединяешь)
Пришли скриншоты calls, user_msg и user_mb.",,Олег Булыгин
1604600657.494800,1604664875.025300,U0185Q2MK19,"<@U01B84HU32R>, вообще не важно object или нет столбец. Условие будет делать проверку по всем строкам, в т.ч. по тем, где есть NaN. Но любое арифметическое действие с NaN вернет NaN. А любое сравнение с NaN вернет False.

Ну и на всякий случай пришлю ссылку с примерами того, как можно удалять строки по условию / нескольким условиям: <https://thispointer.com/python-pandas-how-to-drop-rows-in-dataframe-by-conditions-on-column-values/>",,Олег Булыгин
1604600657.494800,1604665483.025500,U01B84HU32R,"<@U0185Q2MK19> спасибо большое за разъяснения и извини, что так много спрашиваю!","[{'name': 'heart_hands', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604239257.407000,1604751104.028000,U01BB74F8GJ,"<@U0185Q2MK19>,  спасибо.",,Митя Журавлев
1604761150.028400,1604761150.028400,U01B84HU32R,Зависимость цены от этажа,,Виктория Онучина
1604761150.028400,1604761290.028500,U01B84HU32R,"<@U0185Q2MK19> привет! Подскажи, написано, цитирую ""Изучите, зависит ли цена от квадратного метра, числа комнат, *этажа (первого или последнего)*, удалённости от центра."". И немного не понимаю про этажи. Нужно отдельно посмотреть зависимость от первого, а потом посмотреть зависимость от последнего? Как вообще это сделать корректно? Я перевела нашу категоризацию ""первый, последний, другой"" и цифры ""0,1,2"" соответственно, так как, если правильно понимаю, матрица корреляции не работает со словесным наполнением столбцы. Но когда я делаю срез, где только первый этаж, то у меня NaN в столбце с этажами.",,Виктория Онучина
1604767441.029000,1604767441.029000,U01C12GG1UG,Оптимизация построения графиков через цикл For,,Павел Катанов
1604767441.029000,1604767779.029100,U01C12GG1UG,"<@U0185Q2MK19> Привет! Нужна небольшая помощь :))

Ревьюер просит автоматизировать построение графиков через цикл For. А я совсем не могу понять: как именно и что именно автоматизировать.

Графики, которые строятся в несколько шагов - я строил через функцию. А графики в духе df['last_price'].hist() - и так строятся весьма просто и цикл, как мне кажется, немного лишь усложнит всё.

Подскажите, пожалуйста, как я могу воспользоваться циклом For в контексте автоматизации построения графиков?)",,Павел Катанов
1604761150.028400,1604772764.031600,U01BB72MR6E,<@U01B84HU32R> для категориальных переменных зависимость не получится посмотреть через коэф-т корреляции. Поможет группировка или сводная таблица,,Юлия Сова
1604761150.028400,1604772848.031800,U01C12G0QNL,"<@U01B84HU32R> привет. Можно построить график и посмотреть, как меняется цена для категорий этажей. Но перед этим данные нужно сгруппировать.",,Михаил Перцев
1604767441.029000,1604773191.032100,U01C12G0QNL,"<@U01C12GG1UG> привет. Как предположение - если у тебя уже есть функция для построения графиков, то ты можешь в цикле проходить список столбцов и на каждой итерации вызывать функцию построения графика для каждого столбца. Примерно так:
for col in list_of_columns:
    create_plot(y=col)",,Михаил Перцев
1604761150.028400,1604773342.032600,U01B84HU32R,"<@U01BB72MR6E> так, я категоризировала, но потом заменила их на численные значения, вроде с ними он работает..
Но вот скрины, первый как я заменила: <http://joxi.ru/MAj6JxXCkjQ74A>
Второй там убранные куски кода: <http://joxi.ru/Vrwkn60F47edXr>
Или так он тоже не будет работать?",,Виктория Онучина
1604761150.028400,1604773370.032900,U01B84HU32R,"<@U01C12G0QNL> я выше Юлии ответила, может Вы тоже подскажете)",,Виктория Онучина
1604761150.028400,1604773742.033100,U01C12G0QNL,"<@U01B84HU32R> не уверен, что в этом случае уместно считать корреляцию. Т.е. функция примет числовые значения этажей, но будет ли корректным значение коэффициента? Я всё же советую построить сводную таблицу с медианными  ценами и на основании этой таблицы - график. Должно получиться наглядно и сразу будет видна зависимость.",,Михаил Перцев
1604761150.028400,1604774443.033400,U01B84HU32R,"<@U01C12G0QNL> а извиняюсь за вопрос такой, под медианными ценами подразумевается медианными цена в зависимости от этажа? Или какая именно?...",,Виктория Онучина
1604761150.028400,1604774622.033600,U01C12G0QNL,"<@U01B84HU32R> да, по этажам. Т.е. при построении свободной таблицы нужна будет группировка по категории этажа (первый, последний, другой) и 'median' как агрегирующая функция.",,Михаил Перцев
1604761150.028400,1604774706.033800,U01B84HU32R,"<@U01C12G0QNL> спасибо, попробую поэкспериментировать!","[{'name': 'cat-high-five', 'users': ['U01C12G0QNL'], 'count': 1}]",Виктория Онучина
1604761150.028400,1604775470.034000,U01C12G0QNL,<@U01B84HU32R> пример графика соотношения цены и этажа:,"[{'name': 'green-thmbup', 'users': ['U01B84HU32R'], 'count': 1}]",Михаил Перцев
1604239257.407000,1604782416.034500,U01B84D31FF,"<@U0185Q2MK19> Привет! Посмотри пожалуйста объединяю данные вот так <https://pastebin.com/fdUBHgba> , но мне выдает ошибку (На скрине), что я не так делаю?",,Кирилл Солодков
1604767441.029000,1604786943.034800,U01C12GG1UG,"```for columns in ['last_price', 'total_area']:
    q3 = df[columns].quantile(q=0.75)
    df[columns].hist(bins=100, range=(0, q3*3))
    plt.title('2')
    plt.show()```
Вот такой цикл получился, но теперь новая проблема: не могу понять, как каждому графику дать отдельное название :(",,Павел Катанов
1604767441.029000,1604787589.035000,U01C12GG1UG,"<@U01C12G0QNL> Спасибо!
Так и сделал, теперь осталось разобраться, как каждому графику присваивать свое имя в рамках этой функции в цикле :)",,Павел Катанов
1604239257.407000,1604814051.035200,U0185Q2MK19,"<@U01B84D31FF>, привет!

Не совсем корректно применяешь merge. Этот метод применяется к таблице и в качестве аргумента указывается вторая таблица, вот так:

```df = user_calls.merge(user_messages, on=['user_id', 'месяц'], how='outer')```
Так мы объединим 2 таблицы. Потом аналогично присоединяем следующую к df.",,Олег Булыгин
1604761150.028400,1604814172.035400,U0185Q2MK19,"Я бы еще построил boxplotы для каждой категории, они более информативны, чем столбчатая диаграмма)
Конечно, строим их в дополнение к сводной таблице, в которой просто отражаем среднюю цену на квартиры на первом/последним/прочих этажах.
Корреляцию тут считать не надо, как и строить scatterplot",,Олег Булыгин
1604767441.029000,1604814283.035700,U0185Q2MK19,"<@U01C12GG1UG>, привет!

Посмотри, вот здесь обсуждали аналогичную ситуацию: <https://yandex-students.slack.com/archives/G01B461LV0E/p1603976744373600?thread_ts=1603368540.315600&amp;cid=G01B461LV0E>

То есть можно просто параметры визуализации поместить в словарь и в цикле из него подставлять значения в нужные параметры",,Олег Булыгин
1604761150.028400,1604824738.036200,U01B84HU32R,"<@U0185Q2MK19> а если вот дано по всем категориям посмотреть, ну вот в задании. То будет уместно этажи отдельно рассмотреть, а корреляцией взаимосвязь между остальными? И можно где-то побольше почитать о корреляции, когда ее использовать и что она в себя впитывает? А то мало ли я плохо понимаю ее...",,Виктория Онучина
1604761150.028400,1604827390.036500,U0185Q2MK19,"<@U01B84HU32R> Тут 2 мысли :slightly_smiling_face:
1. Правильный подход должен сводиться к тому, что мы _сначала_ выдвигаем гипотезы, а потом ее _проверяем_ расчетами. В данной задаче наш бытовой опыт вполне нам подсказывает, что цена на первом и последнем этаже по объективным причинам может отличаться от всех остальных. Остальные этажи между собой вряд ли значимо отличаются. 
При этом никогда не надо ""натягивать"" выводы на проведенные расчеты (нельзя подгонять интерпретацию под результат). Иначе можно дойти до такого: <https://tylervigen.com/spurious-correlations> (это реальные корреляции)
2. При желании, конечно, можно рассчитать все взаимосвязи, тут просто надо учесть, что мы изучаем взаимосвязь порядковой качественной переменной с непрерывной. И применять правильный метод расчета (мы в данном случае не можем применить стандартную корреляцию Пирсона). Вот тут статья про это: <https://machinelearningmastery.com/how-to-calculate-nonparametric-rank-correlation-in-python/>. Ну и всегда можно построить матрицу корреляций нужных признаков при помощи метода corr() и визуализировать ее при помощи heatmap.
Вообще про корреляцию можно почитать еще здесь: <https://www.machinelearningmastery.ru/the-intuition-behind-correlation-62ca11a3c4a/> (это не очень хороший перевод, лучше перейти на оригинал и прочитать на английском)","[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Олег Булыгин
1604761150.028400,1604828439.036900,U01B84HU32R,"<@U0185Q2MK19> спасибо! Я тут еще, с твоего позволения, переспрошу тогда про корреляцию. В тренажере мы рассчитывали вес\рост\возраст\пол с помощью матрицы корреляции. И вот пол, это же величина, которая может быть либо ж либо м.  И, вроде, это именно качественная переменная. Уместно ли использовать год\месяц\день в матрице корреляции? Я присылала скрин, но вот еще раз: <http://joxi.ru/MAj6JxXCkjQ74A>",,Виктория Онучина
1604761150.028400,1604829009.037200,U0185Q2MK19,"<@U01B84HU32R>, нет, корреляция для номинальных данных (для тех, у которых ранжирование незначимо, как дни недели, например) не имеет особого смысла (либо нужно использовать другие инструменты, типа регрессии). Я бы корреляцию для пола тоже бы не стал делать, это некорректно.

Тут уместнее просто рассчитать средние по группам и их сравнить. Дальше по программе обучения вы еще научитесь определять на сколько статистически значима разница вычисленных средних.",,Олег Булыгин
1604239257.407000,1604845472.038100,U01B84D31FF,"<@U0185Q2MK19> сделал как ты посоветовал, и уменя появились два новых не понятных мне  столбца( <https://pastebin.com/zKtePwTL>
id_x и id_y",,Кирилл Солодков
1604239257.407000,1604845719.038400,U01B84D31FF,,,Кирилл Солодков
1604239257.407000,1604848196.038700,U01B84D31FF,"<@U0185Q2MK19> , я разобрался, это количество совершенных звонков и отправленных смс. нужно только переименовать столбцы.",,Кирилл Солодков
1604239257.407000,1604896557.039300,U0185Q2MK19,"<@U01B84D31FF>, да, когда у объединяем датафреймов есть столбцы с одинаковыми названиями, то так и будет. Лучше просто заранее переименовывать, чтобы не путаться)",,Олег Булыгин
1604903844.039800,1604903844.039800,U01BHCRMNGL,Задание параметров функции,,Дарья Баранкова
1604903844.039800,1604903877.039900,U01BHCRMNGL,"<@U0185Q2MK19>  Привет!
Я пыталась создать функцию, которой можно было бы передать названия столбцов, названия тарифов и их условия, а функция посчитала бы превышения лимитов.
Но у меня возникает ошибка ""The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().""

Подскажи, пожалуйста, ошибка в логике или я неправильно задала функцию? Можно ли передавать такую кучу разных параметров?

<http://joxi.ru/eAOP0z5ikWEwJr>
<https://pastebin.com/ifieudwd>",,Дарья Баранкова
,1604903965.040500,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 1.* Изучите общую информацию
• Общие вопросы
Вопросы по датасету",,Маргарита Минеева
,1604904003.040900,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
Приведите к нижнему регистру названия столбцов",,Маргарита Минеева
1604904025.041200,1604904025.041200,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Преобразуйте данные в нужные типы. Опишите, в каких столбцах заменили тип данных и почему
",,Маргарита Минеева
1604904046.041500,1604904046.041500,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Обработайте пропуски при необходимости
",,Маргарита Минеева
,1604904077.041800,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Посчитайте суммарные продажи во всех регионах и запишите их в отдельный столбец
",,Маргарита Минеева
1604904100.042100,1604904100.042100,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
Посмотрите, сколько игр выпускалось в разные годы. Важны ли данные за все периоды?",,Маргарита Минеева
1604904117.042400,1604904117.042400,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Посмотрите, как менялись продажи по платформам. Выберите платформы с наибольшими суммарными продажами и постройте распределение по годам.
",,Маргарита Минеева
,1604904131.042700,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Возьмите данные за соответствующий *актуальный период.*
",,Маргарита Минеева
1604904144.043000,1604904144.043000,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Какие платформы лидируют по продажам, растут или падают? Выберите несколько потенциально прибыльных платформ.",,Маргарита Минеева
,1604904159.043300,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Постройте график «ящик с усами» по глобальным продажам игр в разбивке по платформам. Опишите результат.",,Маргарита Минеева
1604904173.043600,1604904173.043600,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Постройте диаграмму рассеяния и посчитайте корреляцию между отзывами и продажами. Сформулируйте выводы.
",,Маргарита Минеева
1604904192.043900,1604904192.043900,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Соотнесите выводы с продажами игр на других платформах.
",,Маргарита Минеева
1604904205.044200,1604904205.044200,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Посмотрите на общее распределение игр по жанрам. Что можно сказать о самых прибыльных жанрах? Выделяются ли жанры с высокими и низкими продажами?
",,Маргарита Минеева
1604904222.044500,1604904222.044500,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 4.* Составьте портрет пользователя каждого региона
• Определите для пользователя каждого региона (_NA, EU, JP_)
",,Маргарита Минеева
1604904233.044800,1604904233.044800,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 5.* Проверьте гипотезы
• Средние пользовательские рейтинги платформ _Xbox One_ и _PC_ одинаковые;
• Средние пользовательские рейтинги жанров _Action_ и _Sports_ разные.
",,Маргарита Минеева
,1604904243.045100,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 5.* Поясните гипотезы
• Как вы сформулировали нулевую и альтернативную гипотезы;
• Какой критерий применили для проверки гипотез и почему.
",,Маргарита Минеева
,1604904245.045300,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 6.* Напишите общий вывод",,Маргарита Минеева
1604903844.039800,1604922496.045900,U0185Q2MK19,"<@U01BHCRMNGL>, привет!

Это очень сильное переусложнение. Для этой операции достаточно просто арифметикой над столбцами, обрати внимание на этой мой коммент: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604241997418300?thread_ts=1604210798.404500&amp;cid=G01B461LV0E>
Мы просто вычитаем из расхода тариф (нам не нужно функции сообщать конкретный тариф, ведь в столбцах есть все нормативные значения для каждого).

А потом уже функцией можно посчитать доход.",,Олег Булыгин
1604903844.039800,1604923457.046200,U01BHCRMNGL,"<@U0185Q2MK19>, спасибо, я именно так эту задачу и решила)) Просто хочу разобраться в своих ошибках с функциями, на будущее.",,Дарья Баранкова
1604903844.039800,1604924319.046500,U0185Q2MK19,"<@U01BHCRMNGL>, я бы тогда сделал так на примере минут:

```def over(df, used, included):
    if df[included] &gt; df[used]:
        return 0
    else:
        return df[used] - df[included]

df['minutes_over'] = df.apply(over, args=('minutes_included', 'month_calls_duration'), axis=1)```
Обрати внимание, как передаются доп. аргументы функции при использовании apply",,Олег Булыгин
1604931836.048100,1604931836.048100,U01C12H8HJL,"Проект 3. Ошибки в данных. Не нашла, где подстава? :grin:",,Юлия Филоненко
1604931836.048100,1604944551.048200,U01B4EYRJ5U,"я посчитала за ошибку непонятный столбец ""Unnamed: 0"" в данных ""internet.csv"" :woman-shrugging:",,Ольга Соколовская
1604945052.050500,1604945052.050500,U01C12HG4QY,Вопрос про пропуски высоты потолков,,Маргарита К
1604945052.050500,1604945074.050700,U01C12HG4QY,"Я заменила пропуски средним значением, но ревьюер говорит что это искажает данные и что лучше обработать пропуски на основании другого параметра, что строительство, в основном, типовое, поэтому одинаковые дома обладают схожими характеристиками. Я подумала сделать на основании параметра этажности, но там ерунда получается",,Маргарита К
1604945052.050500,1604945778.051100,U01C12G0QNL,<@U01C12HG4QY> привет. Попробуй заменить на медианные значения в зависимости от количества комнат.,,Михаил Перцев
1604945052.050500,1604946031.051300,U01C12HG4QY,<@U01C12G0QNL> Привет! не понимаю зависимость между потолками и количеством комнат),,Маргарита К
1604945052.050500,1604946131.051500,U01C12G0QNL,"<@U01C12HG4QY> я рассуждал так: квартиры с большим количеством комнат расположены в ЖК более высокого класса. Соответственно и потолки там будут выше. Плюс, в задании речь идёт о Санкт-Петербурге, где есть квартиры старого фонда с очень высокими потолками - бывшие коммуналки.",,Михаил Перцев
1604945052.050500,1604947588.055400,U01BHCPLXHS,"<@U01C12HG4QY>, привет! Я заменяла медианными значениями в зависимости от этажности дома. Логика такая, что 5 и 9 этажки - скорее всего хрущёвки с высотой потолка 2.55, более высокие дома - новостройки, где стандартная высота потолка уже выше","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1604945052.050500,1604947711.055600,U01C12HG4QY,"<@U01BHCPLXHS> Спасибо, попробую!",,Маргарита К
1604947819.056100,1604947819.056100,U01C12HG4QY,Метод трансформ и пропуски жилого пространства,,Маргарита К
1604947819.056100,1604948030.056200,U01C12HG4QY,"Всем привет! Я посчитала долю жилого пространства в разрезе кол-ва комнат, теперь хочу заменить пропуски умножив общую площадь на %жилой площади в разрезе комнат, пытаюсь через трансформ но выдает ошибку`df['living_area'] = df['living_area'].fillna(df.groupby('rooms')['living'].transform(df['total_area']*df['living'].mean()))`",,Маргарита К
1604947819.056100,1604948156.056400,U01C12HG4QY,В общем нужно чтобы брались имеющиеся данные по общей площади и умножались на средний % жилой площади в разрезе кол-ва комнат,,Маргарита К
1604947819.056100,1604950010.056900,U01C12HG4QY,"Сделала в два этапа
1 Сначала заменила пропуски в столбце доли жилой площади на средний % доли в разрезе комнат
2 Создала переменную которая считает жилую площадь (общая площадь на среднюю долю жилой в разрезе комнат) и применила ее к пропускам в столбце с жилой площадью",,Маргарита К
1604954231.057900,1604954231.057900,U01C12DM2BA,Гайд для третьего проекта,,Фарид Бабаев
1604954231.057900,1604954545.058000,U01C12DM2BA,"<@U0185Q2MK19>
Подскажи пожалуйста, я тут свои мысли распишу, поправь  или добавь плиз если что.
 Как я понимаю, из предобработки данных только изменить типы данных и убрать если есть ошибки. Можно объединить датасет и добавить требуемые вычисления для каждого пользователя. Далее анализируем требуемые параметры (минуты разговора, смс и т.д.) с гистрограммами и выводами.",,Фарид Бабаев
1604931836.048100,1604954989.058400,U01C12H8HJL,"<@U01B4EYRJ5U>, фух) надеюсь, там действительно ничего такого!",,Юлия Филоненко
1604957352.059400,1604957352.059400,U01BB74F8GJ,проверка гипотез в проекте по стат.анализу,,Митя Журавлев
1604957352.059400,1604957524.059500,U01BB74F8GJ,"в тренажере приводился пример тестирования гипотез о равенстве средних с помощью t-теста, но вроде критерий Стьюдента применяется для небольших выборок, а у нас больше 900 пользователей в каждом тарифе. нужно пользоваться t-тестом или другим?","[{'name': 'white_check_mark', 'users': ['U01C12HF0AC'], 'count': 1}]",Митя Журавлев
1604931836.048100,1604983822.060200,U0185Q2MK19,"Да, тут речь про лишний столбец и про нулевые значения (нужно обоснование, что вы с такими записями будете делать)","[{'name': '+1', 'users': ['U01C12H8HJL'], 'count': 1}]",Олег Булыгин
1604954231.057900,1604984032.060400,U0185Q2MK19,"В целом все верно.

На первом этапе ""знакомимся"" с данными, приводим все столбцы к нужному типу, решаем, что делать с нулями.

Считаем основные метрики, строим распределения для интернета, звонков и сообщений.

Потом уже все таблицы можно объединить в одну для последующих расчетов",,Олег Булыгин
1604947819.056100,1604984294.060900,U0185Q2MK19,"В `transform` так сразу действия, к сожалению, передавать нельзя. Только конкретные агрегирующие функции. Поэтому твой второй вариант - оптимальный.",,Олег Булыгин
1604957352.059400,1604986545.061200,U0185Q2MK19,"Привет!

Вполне можно применять ttest в нашем случае.

Вот тут обсуждение для углубления: <https://www.researchgate.net/post/Is_it_rational_to_use_students_t-test_for_larger_sample>",,Олег Булыгин
1604988164.061700,1604988164.061700,U01BBD8JS75,поиск дубликатов,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1604988164.061700,1604988268.061800,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, если я хочу посмотреть, есть ли в датасете повторяющиеся названия игр и ее платформы, можно ли записать это так:
`games.duplicated(['name', 'platform']).sum())`",,Алексей Глазов
1604988164.061700,1604989028.062100,U0185Q2MK19,"Да, конечно :slightly_smiling_face:
Так ты найдешь количество записей у которых И игра И платформа одинаковые.

Можно их потом наглядно посмотреть вот так: `df[df.duplicated(['Name', 'Platform'], keep=False)]`",,Олег Булыгин
1604988164.061700,1604990157.062300,U01BBD8JS75,<@U0185Q2MK19> тогда почему при выводе этих строк у NFS разные платформы а для PS3 игры разные ?,,Алексей Глазов
1604988164.061700,1604990296.062600,U01BBD8JS75,"все, понял, у меня уже была эта ошибка в каком-то проекте))",,Алексей Глазов
1604988164.061700,1604990321.062800,U01BBD8JS75,"это не пары повторяющихся строк, а именно строки, которые имеют дубликаты","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Алексей Глазов
1604957352.059400,1604994658.063400,U01BB74F8GJ,"Олег, спасибо!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Митя Журавлев
1605000021.065600,1605000021.065600,U01C12DM2BA,Ошибка в переводе типа данных,,Фарид Бабаев
1605000021.065600,1605000118.065700,U01C12DM2BA,"<@U0185Q2MK19>
В таблице users выдает ошибку при попытке перевода даты в тип datetime.
`users['reg_date'] = <http://pd.to|pd.to>_datetime(['reg_date'], format='%Y-%m-%d')`
Выдает time data reg_date doesn't match format specified",,Фарид Бабаев
1604988164.061700,1605000581.066100,U01BPRN9VCH,"По этой же теме, у меня получилось, что есть две строчки, игра, у которой повторяется название, год, платформа, рейтинги, оценки, в общем все, кроме продаж. Надо ли мне складывать эти строки между собой и записывать в одну, а вторую удалять? и если да, то как, подскажите пожалуйста. Я уже всю голову сломала, слишком я придираюсь или норм:sweat_smile::see_no_evil:",,Анна Шлёнская
1604767441.029000,1605001901.066300,U01B84D31FF,"<@U0185Q2MK19> Привет! Не получается построить график через функцию. Сделал вот такую функцию вычисления медианы, дисперсии и отклонения
<https://pastebin.com/RU9jkMS9>
Получил таблицу (Во вложении), теперь хочу вот такой функцией (<https://pastebin.com/gTmcZk5q>) сделать графики, но выдает ошибку (второе вложение). Что я делаю не так?",,Кирилл Солодков
1605000021.065600,1605003461.066700,U01BPRKQP9P,"<@U01C12DM2BA> , ты забыл указать название датафрейма в функции `to_datetime()` . Вот так попробуй: `users['reg_date'] = <http://pd.to|pd.to>_datetime(users['reg_date'], format='%Y-%m-%d')`","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12DM2BA'], 'count': 2}]",Никита Коптелов
1605007193.067900,1605007193.067900,U01C12JD9TJ,"Вопрос по заполнению пропусков в столбце ""год релиза""",,Алиса Ручкина
1605007193.067900,1605007258.068000,U01C12JD9TJ,"<@U0185Q2MK19>, привет, помоги, пожалуйста, не кодом, а хотя бы идеей. Перепробовала цикл/функцию...не получается сам принцип. Хочу написать алгоритм замены пропуска в годе выпуска игры на значение известного выпуска с таким же названием. Если этого названия нет, то оставляем NaN.",,Алиса Ручкина
1605007193.067900,1605007749.068300,U01C12JD9TJ,"Например, для BioShock 2 заполнить пропуск на 2010.0, а для Yakuza 4 оставить NaN. И  избежать сбоя, который может быть в переборе, если в названии игры есть апостроф, как в McFarlane's Evil Prophecy",,Алиса Ручкина
1605007193.067900,1605007824.068800,U01C12JD9TJ,"Если будет совет удалить эти строки, т.к. их немного, тогда вопрос с прицелом на будущее: как поступить, если таких данных существенная часть? Вручную из Википедии 300 строк( и больше) перебивать не хочется, да и методом перебора тоже...Искала на всех ресурсах подобные кейсы, не нашла.  Или неправильно составила запрос",,Алиса Ручкина
1604988164.061700,1605009061.070000,U0185Q2MK19,"<@U01BPRN9VCH>, привет!
А не подскажешь, что за игра? Не помню, чтобы в датафрейме были такие.
Там, действительно, есть игры с одинаковым названием, но везде вроде разные годы релиза (это может быть ремейк или переиздание)",,Олег Булыгин
1604767441.029000,1605009257.071200,U0185Q2MK19,"<@U01B84D31FF>, привет!

Ты сообщаешь функции в аргумент `x` *столбец* `Тариф`.  У тебя в датарфейме такого столбца я не вижу (но есть такой индекс). К индексам по названию так технически нельзя обратиться :slightly_smiling_face:",,Олег Булыгин
1604988164.061700,1605009511.071900,U01BPRN9VCH,"<@U0185Q2MK19> это да, разные года могут быть перевыпуском игры, но тут прям идентично все

PS формат года я меняла позже, если что)",,Анна Шлёнская
1605007193.067900,1605009766.072200,U0185Q2MK19,"Привет! Лично я бы в этом кейсе не заполнял пропуски по такому принципу, т.к. игра может на разных платформах выходить с очень сильными задержками, не обязательно в этот же самый год.

Мне кажется, тут у нас нет возможности восстановить принцип, по которому пропуски можно заполнить адекватно. Можно заполнить их незначимой константой, про которую мы будем знать, что она отвечает за отсутствие данных.

Если в данных много пропусков, которые мы не можем адекватно восстановить - то надо идти к людям, которые поставили перед нами поставили аналитическую задачу и сказать: ""GIGO!"": <https://en.wikipedia.org/wiki/Garbage_in,_garbage_out>

Если данные восстановить нельзя, то их нужно собирать. Сбор данных - это не аналитическая задача.","[{'name': 'pray', 'users': ['U01C12JD9TJ'], 'count': 1}]",Олег Булыгин
1604988164.061700,1605009871.072500,U0185Q2MK19,"<@U01BPRN9VCH>, ага, вижу. Ну тут по факту нулевые значения в продажах (за исключением незначимого 0.1). Я бы оставил первую запись и все.",,Олег Булыгин
1604988164.061700,1605009992.072900,U01BPRN9VCH,"<@U0185Q2MK19> я хотела как то просуммировать, но у меня какая то несуразица получалась все время, спасибо, я поняла))","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Анна Шлёнская
1605010591.073900,1605010591.073900,U01C12H8HJL,Проект 3. Проблема с подсчетом сделанных звонков,,Юлия Филоненко
1605010591.073900,1605010645.074000,U01C12H8HJL,"<@U0185Q2MK19> подскажи, плз, я хочу посчитать количество звонков сделанных каждым юзером в месяц. Считаю так:
calls_sum = df.groupby(['user_id','month'])['id_calls'].agg(['count'])
Но, от чего то не считается ( Везде выдается по 1 звонку в месяц",,Юлия Филоненко
1605010901.074900,1605010901.074900,U01BBD8JS75,Характерный срок появления новых и исчезновения старых платформ,"[{'name': 'heavy_check_mark', 'users': ['U01BBD8JS75'], 'count': 1}]",Алексей Глазов
1605010901.074900,1605010932.075000,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, как можно оценить и вычислить данный параметр?","[{'name': 'heavy_plus_sign', 'users': ['U01B4EYRJ5U', 'U01BBD8R6N7'], 'count': 2}]",Алексей Глазов
1605007193.067900,1605011846.075200,U01C12JD9TJ,"<@U0185Q2MK19> , спасибо!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Алиса Ручкина
1605010901.074900,1605011883.075400,U01BBD8JS75,"у меня есть сводная таблица, в которой отражены продажи игр на все консоли по годам... В целом срок жизни это начало и конец продаж игр на консоль...но вот как это отразить в коде не понимаю... если построить все графики, врятли это будет очень наглядно",,Алексей Глазов
1605010901.074900,1605012221.075800,U01BBD8JS75,и подскажи пожалуйста как на одном поле вывести несколько линейных графиков (продажи по разным платформам)?,,Алексей Глазов
1605012360.076200,1605012360.076200,U019HNSQT9B,срезы,,Марьям Бисерова
1605012360.076200,1605012510.076300,U019HNSQT9B,"<@U0185Q2MK19> привет)
пытаюсь сделать таблицы с дисперсией и стандартным отклонением, но почему-то они дублируются",,Марьям Бисерова
1605010591.073900,1605016879.076700,U01C12H8HJL,"<@U0185Q2MK19> отбой :grin: Я вспомнила, что уже считала количество звонков при объединении всех таблиц","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Юлия Филоненко
1605012360.076200,1605023046.079100,U01BHCPLXHS,"<@U019HNSQT9B>, привет! Я сильно не вникала в код, но у тебя в первых двух строках переменные data_pv_tr_d и data_pv_tr_stv ссылаются на один и тот же датафрейф data_pv_tr_mean",,Вероника Гром
1605012360.076200,1605023097.079700,U01BHCPLXHS,Это так и нужно?,,Вероника Гром
1605012360.076200,1605023903.080000,U019HNSQT9B,"<@U01BHCPLXHS> привет! Да, я таким образом пытаюсь создать шаблоны для этих таблиц с нужными столбцами и строками, потом в цикле перезаписать значения в них.",,Марьям Бисерова
1605012360.076200,1605030860.083000,U01BHCPLXHS,"<@U019HNSQT9B>, ну я не очень понимаю, что там происходит в цикле) но я делала такие таблицы через pivot_table и туда уже передавала в аргумент aggfunc медиану, среднее, дисперсию и стандартное отклонение, в коде выглядит через pivot_table проще)",,Вероника Гром
1605012360.076200,1605032917.083200,U019HNSQT9B,"<@U01BHCPLXHS>я пыталась так сделать, но почему-то не получилось, и решила все усложнить :smile: Сейчас попробую еще раз, спасибо огромное!",,Марьям Бисерова
1605010901.074900,1605071101.084000,U0185Q2MK19,"<@U01BBD8JS75>, привет!

Вполне достаточно это оценить визуально - посмотреть на линейчатых графиках продаж, когда начинаются продажи и когда они сходят на нет. Также можно построить тепловые карты по годам и посмотреть когда продажи ""угасают"". Можно оценивать только по ""значимым"" платформам, а не вообще по всем, чтобы не захломлять  визуализацию.
Можно подойти к вопросу более формально и задать самому какие-то граничные значения, которые будут определять время жизни. Например если продается больше 25 млн. копии, то в эти года платформа ""живет"".

На счет построение нескольких линейчатых графиков на одной визуализации для этой задачи - можно использовать сводную таблицу:

```dynamics_by_platform = df.pivot_table(
                        index='Год', 
                        columns='Платформа', 
                        values='Продажи', 
                        aggfunc=sum).fillna(0)```
Применить метод plot :slightly_smiling_face:","[{'name': '+1', 'users': ['U01BBD8R6N7', 'U01C12G0QNL', 'U019HNSQT9B'], 'count': 3}]",Олег Булыгин
1605012360.076200,1605071631.084300,U0185Q2MK19,"Может я не совсем понял задачу автоматизации, но почему это просто не записать в одну строку? Зачем тут циклы?)

```df[['звонки', 'смс', 'гб']].apply(np.std, ddof=1)```
Ну и добавить срез по нужному тарифу. Будет для каждого своя одна строка кода.",,Олег Булыгин
1605082226.085000,1605082226.085000,U01B4EXCR7G,Как вставить рисунок в проект,,Сергей Саранцев
1605082226.085000,1605082290.085100,U01B4EXCR7G,"Подскажите пожалуйста как вставить рисунок в Jupiter Notebook  тот который в тренажере.
Вот такой синтаксис не помогает:
![](<https://wampi.ru/image/...>)",,Сергей Саранцев
1605082226.085000,1605082549.085700,U01B4EXCR7G,"Ответ нашел сам. Не работает короткая ссылка, которая без имени файла. Если вставлять полную ссылку, то все работает","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12H8HJL'], 'count': 2}]",Сергей Саранцев
1604489000.472000,1605090975.086700,U01B84D31FF,"<@U0185Q2MK19> Привет! Подскажи пожалуйста, делаю проверку гипотезы в задании 4.2 <https://pastebin.com/m3jQwTDK>
В результате получается вот такое( Не понимаю в какую сторону смотреть",,Кирилл Солодков
1605010901.074900,1605092735.087000,U01BBD8JS75,"<@U0185Q2MK19> а можно по такой таблице как-то построить один ящик с усами, который бы отражал разброс сколько лет длились продажи и медианой показывал средний возраст?",,Алексей Глазов
1605010901.074900,1605093261.087200,U01BBD8JS75,не получается построить график(,,Алексей Глазов
1604489000.472000,1605094066.087500,U0185Q2MK19,"<@U01B84D31FF>, привет!
Почти наверняка в этих столбцах остались пропуски, проблема из-за этого.",,Олег Булыгин
1605010901.074900,1605095352.087700,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, почему не сработал отбор платформ по заранее отобранному списку?",,Алексей Глазов
1605010901.074900,1605095373.088000,U0185Q2MK19,"<@U01BBD8JS75>, ошибка говорит о том, что у тебя в исходных данных нет столбца `year_of_release`. Надо смотреть на датафрейм

На счет распределения продаж, что ты предполагаешь брать за дату окончание продаж? Начало - выход первой игры на консоли. А конец?",,Олег Булыгин
1605010901.074900,1605095471.088200,U01BBD8JS75,"<@U0185Q2MK19> пивот построен по твоей схеме, может он год не видит, потому что они индексами стали? тогда как это исправить?",,Алексей Глазов
1605010901.074900,1605095529.088400,U0185Q2MK19,"<@U01BBD8JS75> ,
1. можно просто до формирование сводной таблицы исключить все ненужные платформы:
`df[df.platform.isin(top_platforms)]`
2. Если год в индексе, то можно его перевести в столбец при помощи reset_index","[{'name': '+1', 'users': ['U019HNSQT9B'], 'count': 1}]",Олег Булыгин
1604489000.472000,1605095794.089000,U01B84D31FF,<@U0185Q2MK19> Удалил все пропуски с помощью .dropna() в обоих датасетах и все равно такой результат,,Кирилл Солодков
1604489000.472000,1605095873.089300,U0185Q2MK19,"<@U01B84D31FF>, пришли тогда, пожалуйста, скриншоты действия с удалением пропусков и полным кодом при которым получаешь nan при ttest_ind",,Олег Булыгин
1604489000.472000,1605096171.089700,U01B84D31FF,<@U0185Q2MK19> <https://pastebin.com/ddypAcCL>,,Кирилл Солодков
1604489000.472000,1605096829.089900,U0185Q2MK19,"<@U01B84D31FF>, в grouped_data ты пропуски не удалил :slightly_smiling_face: Надо указать inplace=True.
Ты удаляешь в users, а все действия то потом все равно делаешь с grouped_data.

Возьми итоговый датафрейм, убедись, что в нем нет пропусков, разбей именно его на 2 части и примени ttest. Без каких-либо лишних действий.",,Олег Булыгин
1604489000.472000,1605097113.090100,U01B84D31FF,<@U0185Q2MK19> спасибо! Получилось,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Кирилл Солодков
1605012360.076200,1605097517.090500,U019HNSQT9B,"<@U0185Q2MK19> разобралась, спасибо!)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Марьям Бисерова
1603135390.244600,1605123530.090900,U01C12HG4QY,"Привет! Не могу никак справиться с этими выбросами
Эта штука меняет на nan всю строку, а мне нужно в ячейке `df.loc[(df.ceiling_height &gt; 40)] = np.nan`
После этой штуки никаких изменения `data['ceiling_height'].where(data['ceiling_height'] &gt; 40, np.nan)`
Что - то не так, не пойму",,Маргарита К
1605124714.092100,1605124714.092100,U01BB70GPPC,"пропуски в столбцах 'critic_score',  'user_score'",,Павел Овчинников
1605124714.092100,1605124758.092200,U01BB70GPPC,"что вы с ними делали? ничего в голову не приходит, как лучше с ними поступить",,Павел Овчинников
1605124714.092100,1605152045.092900,U01BB74BJ9G,Я с ними ничего не делал,,Владимир Саков
1603135390.244600,1605156769.094300,U01BHCPLXHS,"<@U01C12HG4QY>, привет, у тебя в loc пропущено название столбца, где производить изменения",,Вероника Гром
1603135390.244600,1605157219.094500,U0185Q2MK19,"<@U01C12HG4QY>, Вероника говорит абсолютно верно :slightly_smiling_face: Нужно через запятую сообщить, в каком столбце делаем изменения.",,Олег Булыгин
1605124714.092100,1605158753.094700,U0185Q2MK19,"Я бы тоже не стал ничего с ними делать :slightly_smiling_face:
Вряд ли мы на основании имеющихся данных можем уверенно прогнозировать оценки игры",,Олег Булыгин
1605124714.092100,1605165027.094900,U01BHCPLXHS,"<@U0185Q2MK19>, привет! Я тоже их решила не трогать, но при проверке гипотез из-за NaN не считалось pvalue, получается мне нужно их удалить на этапе создания массива, а в общем датафрейме не трогать, так?",,Вероника Гром
1605124714.092100,1605176600.095200,U01BBD8JS75,"Я заменил на - 1, вдруг там были реальные оценки 0.0. Чтобы их не путать, взял такое число",,Алексей Глазов
1605124714.092100,1605186505.095600,U0185Q2MK19,"<@U01BHCPLXHS>, да, именно для проверки их можно исключить
<@U01BBD8JS75>, такая замена сильно исказит все расчеты",,Олег Булыгин
,1605190722.100400,UTTGJQS6M,"Друзья, всем привет!

Для Сборного проекта созданы жесткие треды выше, <https://yandex-students.slack.com/archives/G01B461LV0E/p1604903965040500|начиная с этого треда> :bar_chart:

Когда вы задаёте вопросы здесь, это помогает в том числе и вашим одногруппникам.
Если у вас возникла трудность с заданием — прежде всего проверьте переписку в канале (пролистайте сообщения наверх), возможно, кто-то уже сталкивался с этой же проблемой, и в чате есть вопрос и полезные советы по его решению.
Удобно: не придётся ждать, когда придёт ответ и задавать повторяющийся вопрос — канал не будет сильно загружен :relieved:

Если вы хотите задать вопрос по проекту Статистический анализ данных и раньше, *коротко назовите свой тред:* название спринта и сфера вопроса и *тегните нашего преподавателя по проектам.*
А уже *внутри треда задайте свой вопрос,* опишите способы, которые уже использовали, приложите скриншоты, коды и другие подробности.
Также вы можете ставить реакцию-галочку, если ваш вопрос в треде решён_ _:heavy_check_mark:
<!channel>","[{'name': 'cat-high-five', 'users': ['U01C12G0QNL', 'U01C12EF41E', 'U01BPRN9VCH', 'U01AAM7LXJL'], 'count': 4}]",Маргарита Минеева
1605124714.092100,1605192350.101500,U01BHCPLXHS,"<@U0185Q2MK19>, спасибо!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1605194742.102300,1605194742.102300,U01B84JJ5L5,Постройте график «ящик с усами» ,,Ингвар Сильницкий
1605194742.102300,1605194842.104500,U01B84JJ5L5,"Постройте график ящик с усами по глобальным продажам игр в разбивке по платформам. Кто как делал? Перечитал тренажёр по этой теме, но все равно не очень понял. ",,Ингвар Сильницкий
1605208932.105200,1605208932.105200,U019E4BDJFQ,"Добрый! А что можно сделать, если при попытке merge появляется MemoryError?",,Nadyamane
1605208932.105200,1605209511.105300,U01BHCPLXHS,можно попробовать вместо merge использовать join,,Вероника Гром
1604134182.385000,1605210053.105500,U01C12DM2BA,"<@U0185Q2MK19>
А как реализовать логику вычисления выручки? Я понимаю что нужно вычесть количество израсходованных минут/смс/мб из тарифных лимитов, а как записать условие чтобы брать только тех кто зашел за лимит?",,Фарид Бабаев
1604134182.385000,1605213294.105700,U01C12HF0AC,"<@U01C12DM2BA> Привет! Может, тебе такой вариант поможет: я делала через функцию, которая бы сравнивала кол-во потраченных минут/сообщений/мб за месяц с лимитом по тарифу. Если лимит не превышен, то выводит 0, если превышен - разницу между потраченным и лимитом, умноженную на стоимость минуты/сообщения/мб сверх тарифа. А потом все эти столбцы суммировала и добавляла абонентскую плату. Видимо, можно это все в одну функцию запихнуть, но у меня не получилось(( Например, по превышению лимита по минутам у меня такая функция <http://joxi.ru/52awX74ukkBo7r>",,Светлана Белоглазова
1604134182.385000,1605240357.106100,U0185Q2MK19,"И вот здесь я приводил пример функции для выручки :slightly_smiling_face:
<https://yandex-students.slack.com/archives/G01B461LV0E/p1604241997418300?thread_ts=1604210798.404500&amp;cid=G01B461LV0E>",,Олег Булыгин
1605194742.102300,1605243629.106500,U0185Q2MK19,"Привет!

Можно использовать вот такой подход:

```df[df.platform.isin('тут можно отобрать только конкретные платформы')].boxplot('столбец с продажами', by='столбец с платформами')```","[{'name': '+1', 'users': ['U01C12H8HJL'], 'count': 1}]",Олег Булыгин
1605208932.105200,1605243839.106700,U0185Q2MK19,"Да, но вообще такое не должно происходить. Вполне может быть, что есть какая-то ошибка в действиях (например, не группируете данные  до объединения).",,Олег Булыгин
1605262875.107300,1605262875.107300,U01B84HU32R,Очередной вопрос про группировку таблиц,,Виктория Онучина
1605262875.107300,1605263174.107400,U01B84HU32R,"<@U0185Q2MK19> привет! Подскажи, вопрос по 3 проекту и объединению таблиц. Я решила отдельно добавить в начальные датафреймы месяца\сумму\количество, что требуют. Но потом хочу привести датафреймы в божий вид: удалить какие-то столбцы и, видимо, нужно будет удалить дубликаты (беру на примере звонков: когда посчитали сумму и количество, добавили месяц, то 3 столбцы не несут нагрузки, я их удалила, потом удалила дубликаты, чтобы на одного пользователя был один месяц, а не дубликатные строчки).

Вопрос такой: как можно это сделать легче? Я читала треды и в частности ответ Мирославу (вот этот: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604290095433800?thread_ts=1604239257.407000&cid=G01B461LV0E>), где ты поэтапно написал что делать. Но, видимо, я не до конца понимаю, а уйдут ли лишние значения (а вроде не уйдут).. Какую таблицу нужно получить в итоге..
Прикрепляю скриншот того, как я сделала.",,Виктория Онучина
1605262875.107300,1605263535.108600,U01C12H8HJL,"<@U01B84HU32R> Виктория, вот в этом треде <https://yandex-students.slack.com/archives/G01B461LV0E/p1604239257407000> максимум инфо по твоему вопросу (сама опиралась на план, который прописал Олег)",,Юлия Филоненко
1605262875.107300,1605263642.108900,U01B84HU32R,"<@U01C12H8HJL> я перечитала все треды и не до конца все равно понимаю)
У меня есть вот то, что сделала я, но чувствую, что можно сделать легче, до конца не понимаю. Буду экспериментировать, пока Олег отвечает",,Виктория Онучина
1605262875.107300,1605264712.109100,U01B84HU32R,"<@U0185Q2MK19>
Я воспользовалась твоей подсказкой касательно такого формирования ""<https://yandex-students.slack.com/archives/G01B461LV0E/p1604550440491700?thread_ts=1604489000.472000&amp;cid=G01B461LV0E>"". И мне интересно как удаляются там значения, потому что если группировать по отдельности, то reset_index не убирал у меня лишние строчки (я использовала reset_index(drop=True). Может я плохо понимаю разницу между reset_index() и reset_index(drop=True), но если верить записулькам своим, то в случае reset_index() старые индексы сохраняются (а у нас красиво все стало по новым индексам по порядку)... И почему магическим образом у нас по месяцам от большего меньшего и по юзерам от 1 к последнему...",,Виктория Онучина
1604904205.044200,1605267546.109600,U01BBD8JS75,"<@U0185Q2MK19> помоги пожалуйста. Построил графики продаж по платформам в актуальном периоде, но он оказался очень неудобным для анализа. Так как платформ и соответственно линий  много, не могу определить какая линия, какой платформе соответствует, подскажи как быть в таком случае, можно ли сделать так например, чтобы при наведении курсора на линию, появлялась бы подсказка что это за линия?",,Алексей Глазов
1604904144.043000,1605267742.109900,U01C12EF41E,"<@U0185Q2MK19> добрый день!, подскажите пожалуйста, я правильно понял задачу ""Какие платформы лидируют по продажам, растут или падают?"".
Сначала надо определить лидеров по общим продажам, потом понять, растут у них продажи, или падают?
И в конце определить потенциально прибыльные платформы(лидеры, которые растут по продажам в последнее время)",,Иван Гончаров
1604904205.044200,1605269163.110100,U01BBD8JS75,не понимаю как засунуть это в plotly.express,,Алексей Глазов
1605262875.107300,1605272603.110500,U0185Q2MK19,"<@U01B84HU32R>
1. Почему ты применяешь метод transofrm после группировки? Для таких задач есть агрегирующие методы и agg. Это будет намного проще.
2. Не совсем понимаю, зачем тебе делать reset_index(drop=True), ведь это просто удалит индексы, которые как раз у нас и являются группировочными признаками (месяц и id). По ним потом надо объединять таблицы, поэтому их можно перевести в столбцы, но не удалять (просто reset_index переводит индексы в столбцы, а drop=True их просто удаляет). 
3. Никаких полных дублей в строках в разрезе пользователей и месяцев при корректной группировке быть не может
4. Чтобы не путаться, рекомендую сначала все сгруппировать, объединить, а потом при необходимости удалять какие-то столбцы, если тебе покажется, что они не нужны. Столбцы с id пользователя и продолжительностью звонком точно удалять не надо, т.к. по id мы будем объединять, а звонки понадобятся еще много раз для дальнейших расчетов.
Итого рекомендую сначала корректно сгруппировать все исходные таблицы при помощи groupby и agg, а потом их объединить при помощи merge :slightly_smiling_face: Ничего пока не удалять.",,Олег Булыгин
1604904144.043000,1605272936.110700,U0185Q2MK19,"<@U01C12EF41E>, привет!

В целом - да, все верно.  Понятно, что общие лидеры, скорее находятся в закате, а потенциально прибыльные - это те, рост которых только начинается","[{'name': 'heavy_check_mark', 'users': ['U01C12EF41E'], 'count': 1}]",Олег Булыгин
1605262875.107300,1605273447.110900,U01B84HU32R,"<@U0185Q2MK19> спасибо за большой и развернутый ответ!
То есть я правильно понимаю, что при правильной группировки у нас группируются месяцы и за счёт этого становится меньше количество строк? Так как для одного пользователя остаются без дубликатов месяцы?",,Виктория Онучина
1604904205.044200,1605273538.111100,U0185Q2MK19,"<@U01BBD8JS75>, привет!

Не нужно делать сводную таблицу в таких ситуациях, нужна просто группировка.

Посмотри на такой пример:

```res = df.groupby(['year_of_release', 'platform']).sum().reset_index()

px.line(res, x='year_of_release', y='total_sales', color='platform')```
То есть категория должна быть одним отдельным столбцом, а не так, что каждая платформа в отдельном.","[{'name': '+1', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1605262875.107300,1605273911.111400,U0185Q2MK19,"<@U01B84HU32R>, да, все верно. При группировки по пользователям и по месяцам, у нас останутся строки каждого месяца для каждого пользователя (и все).

То есть мы будем считать суммарное количество звонок, смс, гб _пользователя 1_ за январь, за февраль и т.д. по всем месяцам.
И так же для всех оставшихся.",,Олег Булыгин
1605262875.107300,1605273982.111600,U01B84HU32R,"<@U0185Q2MK19> спасибо ещё раз, буду тогда побовать и находить почему моя группировка не работает, подключать agg вместо transform, а то слизывать коды с тредов просто так не хочется, все же хочется понять))","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604904192.043900,1605277604.114500,U01C12EF41E,"<@U0185Q2MK19> добрый вечер!
Подскажите пожалуйста, не могу сообразить.
Здесь имеется ввиду выводы прошлого пункта, корреляции оценок к продажам по выбранной платформе?
И их надо соотнести с такими же корреляциями других платформ?
Или просто, с продажами игр других  платформ?
Чет не могу сообразит  :grimacing::see_no_evil:",,Иван Гончаров
1604904205.044200,1605278485.115200,U01BBD8JS75,"<@U0185Q2MK19> для наглядности хотел построить столбчатый график для популярных платформ в 2013-2016 годах. График построил, а вот подписать оси не получается... они в данном случае подписываются как-то по особому, не так как с line? с линейными графиками я подписал оси так:       `labels=dict(total_sales=""Объем продаж (млн. копий)"", year_of_release=""Годы выпуска"", platform=""Платформа""), title = 'Анализ продаж компьютерных игр')`",,Алексей Глазов
1605194742.102300,1605281158.116000,U01B84JJ5L5,<@U0185Q2MK19> приветствую! Спасибо за помощь!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Ингвар Сильницкий
1605194742.102300,1605284239.117000,U01AWENRANB,"<@U01B84JJ5L5> привет, я делала вот так, результат мне понравился в целом

import seaborn as sns

plt.figure(figsize=(15, 10)) 
sns.boxplot(x=""platform"", y=""total_sales"", data=df_actual, palette='rainbow') ","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12H8HJL'], 'count': 2}]",Ксения Ушакова
1604239257.407000,1605295017.117400,U019E4BDJFQ,"<@U0185Q2MK19>, вопрос конечно  не очень умный, но до меня никак не доходит как в агрегированную таблицу добавить значения тарифов (((",,Nadyamane
1604489000.472000,1605303972.117700,U01C12H8HJL,"<@U0185Q2MK19> я прочитала вроде все треды, где ты говоришь об ошибках при создании единого df, но не вижу ошибку в своем (а мне выдается при проверке гипотез nan). Посмотри плз, все ли ок <https://pastebin.com/jLFetda9> Где косяк? У меня вышло всего 3216 строк в итоге, пропусков выше крыши, дело в их заполнении, да?)",,Юлия Филоненко
1605340832.118800,1605340832.118800,U01C12DM2BA,Проверка гипотез,,Фарид Бабаев
1605340832.118800,1605340911.118900,U01C12DM2BA,"<@U0185Q2MK19>
Застрял на 4 шаге в третьем проекте :wall:Направь в нужном направление плиз",,Фарид Бабаев
1605340832.118800,1605341915.120200,U01BPRN9VCH,Проверь по t критерию на равенство средних этих выборок),,Анна Шлёнская
1605340832.118800,1605355533.120700,U01C12H8HJL,"<@U01C12DM2BA> перечитай уроки 5 и 6 ""Проверка гипотез"", там как раз проверка гипотез о равенстве средних, код готовый по сути. Только подставить свое. Но я тебе сразу скажу, если по сводной таблице есть косяк (прям как у меня), p-value выдастся ноль)) Вот сижу выкаю, что я не так соединила :fire:",,Юлия Филоненко
1604904192.043900,1605359745.121000,U0185Q2MK19,"<@U01C12EF41E>, привет!

Да, все верно, это относится к предыдущему пункту (корреляция продаж с оценками). Можно изучить корреляции продаж с оценками на каких-то других конкретных платформах, либо просто взять срез ""все другие"".

И посмотреть, такая же там ситуация со взаимосвязью, или другая","[{'name': 'white_check_mark', 'users': ['U01C12EF41E', 'U019HNSQT9B'], 'count': 2}]",Олег Булыгин
1604904205.044200,1605360309.121300,U0185Q2MK19,"<@U01BBD8JS75>, надо вот так:
```            labels={
                     ""year_of_release"": ""Годы выпуска"",
                     ""total_sales"": ""Объем продаж (млн. копий)"",
                 },
            title = 'Анализ продаж компьютерных игр'```
В документации есть примеры: <https://plotly.com/python/figure-labels/>

На будущее - присылай, пожалуйста, и сам код, чтобы не было необходимости вручную аналогичные предварительные действия делать :slightly_smiling_face:",,Олег Булыгин
1604239257.407000,1605360632.121800,U0185Q2MK19,"<@U019E4BDJFQ>, привет!

Нужно теперь присоединить таблицу tariffs и users при помощи merge :slightly_smiling_face:

Посмотри, пожалуйста, вот в этом обсуждении я уже подробно прописывал алгоритм: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604550440491700?thread_ts=1604489000.472000&amp;cid=G01B461LV0E>

Потом просто делаем:

```df = df.merge(users, on='user_id', how='left')
df = df.merge(tariffs, on='tariff', how='left')```
",,Олег Булыгин
1604489000.472000,1605361308.122400,U0185Q2MK19,"<@U01C12H8HJL>,привет!

Все ок, за исключением того, что пользователей и тарифы лучше объединять при помощи left, а не outer, вот такой логикой:

```df = df.merge(users, on='user_id', how='left')
df = df.merge(tariffs, on='tariff', how='left') ```
То, что остались пропуски - это нормально :slightly_smiling_face:",,Олег Булыгин
1605340832.118800,1605361576.122700,U0185Q2MK19,"<@U01C12DM2BA>, все верно, то есть мы просто применяем функцию ttest_ind, передав в нее столбцы с доходностью по тарифам.

Алгоритм такой:
1. Формулируем нулевую и альтернативную гипотезы
2. Определяем пороговый уровень значимости
3. Применяем ttest
4. Интерпретируем результат",,Олег Булыгин
1604489000.472000,1605372655.123500,U01C12H8HJL,"<@U0185Q2MK19> сделала, все равно в p-value NaN Тогда вопрос по пропускам: я оставила их как есть, а надо, наверное, заполнить, да? :grin:

upd: чую, дело в пропусках в duration, mb_used и сообщениях...  думаю чем лучше заполнять, средним или нулями. Если duration и mb_used мало пропусков, то в сообщениях аж 499 штук, там точно на ответ повлияет. Пока писала придумала попробовать и так и так (как Глеб в вебинаре говорил). :grin:",,Юлия Филоненко
1605340832.118800,1605374737.123800,U01C12DM2BA,"Правильно ли я делаю? <https://pastebin.com/6mTDj6b0>
У меня во втором случае получается
```p-значение: 6.129437607155033e-191
Отвергаем нулевую гипотезу```
, что явно неправильно :face_with_rolling_eyes:
В первом похоже на правду:
```p-значение: 0.4712668200760739
Не получилось отвергнуть нулевую гипотезу```
",,Фарид Бабаев
1604904025.041200,1605380131.124100,U01BB74F8GJ,"пытался кто-нибудь год привести к datetime?
такой метод `<http://pd.to|pd.to>_datetime(df['year_of_release'].astype(str), format='%Y').dt.year`  привел к ошибке `unconverted data remains: .0`
<@U0185Q2MK19> подскажи, пожалуйста. Понятно, что можно в принципе и не трогать, но интересно, если такое встретится в реальной жизни",,Митя Журавлев
1605340832.118800,1605420432.124400,U0185Q2MK19,"<@U01C12DM2BA>, почему считаешь, что неправильно?)
Это просто число близкое к нулю, такое вполне может быть)",,Олег Булыгин
1605340832.118800,1605421840.124600,U01C12DM2BA,То есть это значит что различие не случайное?,,Фарид Бабаев
1604489000.472000,1605422029.124800,U0185Q2MK19,"<@U01C12H8HJL>, ты точно правильно делаешь проверку гипотез? Нам нужно проверять гипотезы по выручке (в ней не может быть пропусков после объединения и расчета, каждый пользователь приносит хотя бы абонентскую плату). Пропуски в интернете и продолжительностм звонков тут вообще не причем.

Посмотри вот это сообщение, где прописан алгоритм подсчета дохода: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604241997418300?thread_ts=1604210798.404500&amp;cid=G01B461LV0E>",,Олег Булыгин
1604904025.041200,1605422794.125400,U0185Q2MK19,"<@U01BB74F8GJ>, тут .astype(str) не нужен :slightly_smiling_face:
Ну и вообще перевод только года к datetime бессмысленен. Вся суть datetime в том, что там хранится полноценная временная метка (день, месяц, год, часы, минуты и пр. - то есть несколько показателей, каждый из которых мы можем вытащить по отдельности). Когда у нас просто год - это тот же самый integer",,Олег Булыгин
1605340832.118800,1605424713.125600,U0185Q2MK19,"<@U01C12DM2BA>, если быть максимально корректным, то это значит, что вероятность получить такие же, либо еще больше различия при том, что нулевая гипотеза верна - очень малы. И мы ее отвергаем при том пороговом значении, который мы приняли.",,Олег Булыгин
1605340832.118800,1605435756.125800,U01B84HU32R,"<@U0185Q2MK19> чтобы не засорять, напишу здесь. Подскажи, я сделала гипотезы, но мне ревьюер сказал брать не среднее по пользователям (то есть у меня была таблица с названием тарифа, ид юзера и рядом с каждым юзером средня выручка за 12 месяцев), а брать именно полную выборку, то есть, как понимаю, по всем пользователям по каждому месяцу. А почему так? Ведь наша гипотеза звучит как ""средняя выручка пользователей cмарт и ультра не различается"". Я немного не понимаю, как это работает",,Виктория Онучина
1604489000.472000,1605437492.126000,U01C12H8HJL,"<@U0185Q2MK19> точно, я проверяю гипотезы по выручке,  считала ровно по твоему примерному поэтапному алгоритму. Но у меня были в таблице незаполненные пропуски в duration, sms и mb = в выручке из-за этого тоже получаются пропуски",,Юлия Филоненко
1604489000.472000,1605443930.128300,U0185Q2MK19,"<@U01C12H8HJL>, давай тогда еще раз поэтапно все проверим.

1. Все объединяем:
```user_calls = calls.groupby(['user_id', 'month'])\
                  .agg({'duration':'sum', 'id':'count'})\
                  .reset_index()\
                  .rename(columns={'duration':'month_calls_duration','id':'calls_total_in_month'})

user_messages = messages.groupby(['user_id', 'month'])\
                        .agg({'id':'count'})\
                        .reset_index()\
                        .rename(columns={'id':'sms_total_in_month'})
user_internet = internet.groupby(['user_id', 'month'])\
                        .agg({'mb_used':'sum'})\
                        .reset_index()\
                        .rename(columns={'mb_used':'mb_total_in_month'})

df = user_calls.merge(user_messages, on=['user_id','month'], how='outer')
df = df.merge(user_internet, on=['user_id','month'], how = 'outer')

df = df.merge(users, on='user_id', how='left')

df = df.merge(tariffs, on='tariff', how='left')```
2) Считаем перерасход:
```df['minutes_overrun']  = df['month_calls_duration'] - df['minutes_included']
df['messages_overrun'] = df['sms_total_in_month'] - df['messages_included']
df['mb_overrun']  = df['mb_total_in_month'] - df['mb_per_month_included'] ```
3) Считаем выручку:

```def get_revenue(row):
    revenue_by_min = 0
    revenue_by_messages = 0
    revenue_mb = 0

    if row['minutes_overrun'] &gt; 0:
        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']

    if row['messages_overrun'] &gt; 0:
        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']

    if row['mb_overrun'] &gt; 0:
        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']

    return revenue_by_min + revenue_by_messages + revenue_mb

df['revenue'] = df.apply(get_revenue, axis=1)```
4) Проверяем пропуски: `df.revenue.isna().sum()`  - их нет. При расчеты выручки мы все это учитываем",,Олег Булыгин
1604904205.044200,1605449668.128700,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, откуда правильнее брать информацию для анализа игр по жанрам? я построил гистограмму, по ней четко видно, что больше всего игр Action. А затем построил диаграмму разброса, и на ней если смотреть по медиане, больше всего игр жанра Schooter",,Алексей Глазов
1604767441.029000,1605455121.130000,U01BBD8JS75,"<@U0185Q2MK19> схожая проблема, чтобы не строить графики в сборном проекте для продаж в регионах, хочу сделать это через цикл. но не получается поменять подпись оси Y и не знаю как трем гистограммам сделать подписи разные по типу ""Продажи в Северной Америке"", ""Продажи в Европе"" ... словарь я создал, а как им воспользоваться не знаю...need your help!)",,Алексей Глазов
1604767441.029000,1605456977.130300,U01BBD8JS75,"и можно ли сделать так, чтобы они все три находились рядом?",,Алексей Глазов
1604904222.044500,1605457503.130500,U01BBD8JS75,"<@U0185Q2MK19> на этапе предобработки данных, я заменил 40,5% пропусков в столбце Rating на ""Нет информации"", теперь же когда дошло дело до определения топ-5 рейтингов, у меня для Японии вышла такая картина...  что в таких ситуациях делать?",,Алексей Глазов
1604904205.044200,1605462110.130800,U019M1YCHKM,"<@U01BBD8JS75> Подскажи пожалуйста, как ты отображаешь диаграммы размаха на одном графике для данных, сгруппированных по признаку (в данном случае, по жанру)? Хочу понять принцип:sweat_smile:",,Олеся Дмитриева
1604904205.044200,1605463393.131000,U01BBD8JS75,"<@U019M1YCHKM>
`fig = px.box(df,`
             `x='genre',`
             `y='total_sales',`
             `range_y=[0, 3],`
             `labels=dict(total_sales=""Объем продаж (млн. копий)"", genre=""Жанр""),`
             `title = 'Диаграмы размаха продаж компьютерных игр по жанрам')`
            
`fig.show()`
Ничего сложного как видишь))",,Алексей Глазов
1604904205.044200,1605463681.131200,U019M1YCHKM,"<@U01BBD8JS75> Спасибо! Да, да, действительно все понятно на самом деле)",,Олеся Дмитриева
1604904205.044200,1605463801.131400,U01BBD8JS75,<@U019M1YCHKM> ну и px это import plotly.express as px,"[{'name': 'ok_hand', 'users': ['U019M1YCHKM'], 'count': 1}]",Алексей Глазов
1604904144.043000,1605472784.132200,U01B4EYRJ5U,"<@U0185Q2MK19> подскажите, пожалуйста, по комментарию ревьюера
я построила график распределения продаж по платформам по годам, в качестве актуального периода выбрала 2005-2015 гг, потому что это период, когда существовали все платформы из топ-5 по продажам. В качестве потенциально прибыльной, по которой в дальнейшем смотрю корреляцию по оценкам, выбрала PS3.
Но ревьюер мне написал `Обрати внимание, что нам стоит в том числе проверить динамику продаж по актуальному периоду.Потому что, я думаю сразу изменить картина по тем платформам, которые мы выбрали сейчас.` 
Не совсем понимаю, в чем ошибка, если по сути динамика есть на графике",,Ольга Соколовская
1604954231.057900,1605475434.132500,U019E3T5678,"<@U0185Q2MK19> подскажи пожалуйста, а что не так с пропусками данных? я увидела пропуски только в *churn_date,* но совершенно логично, что там у большинства пропуски и не вижу смысла заполнять. Что касается 0 смс или длительность звонка 0 - вроде тоже все логично.
Вопрос: где там нули, к которым стоит присмотреться? Чего я не вижу?",,Ольга
1605340832.118800,1605476224.132700,U01C12DM2BA,"<@U0185Q2MK19>
`Прежде чем произвести проверку гипотезы через T-критерий Стьюдента произведи проверку дисперсии выборок, чтобы понять с каким параметром использовать метод проверки.`
Можешь расшифровать?) И я до конца не понимаю как правильно сформулировать гипотезы",,Фарид Бабаев
1605340832.118800,1605481482.133000,U01B84HU32R,"<@U01C12DM2BA> привет)
По поводу гипотез: если больше читать и углубляться в нулевую гипотезу и ее формулировку, то она обычно формируется как равенство двух чего-либо или утверждение какого-то события, пример ""дети спят 8 часов в день"". В нашем случае будет ""средняя выручка между тарифами равна"".  У нас прям тема называется ""гипотеза РАВЕНСТВА средних двух генеральных совокупностей"". 

По поводу дисперсии. Мы делаем двусторонний тест, в котором кроме массивов вводится ещё один показатель equal_var. По умолчанию он принимает значение True, что дисперсия равна. Поэтому и нужно ее посмотреть, чтобы правильно вставить этот параметр.",,Виктория Онучина
1605491889.133700,1605491889.133700,U01BBD50335,обработка пропусков NaN,,Гогу Зинаида
1605491889.133700,1605493018.134000,U01BBD50335,"<@U0185Q2MK19> В первом проекте, нужно обработать пропуски NaN в столбцах: ""days_employed"" и ""total_income"". Хочу преобразовать их хотя бы на медиану как было показано в треде и всё равно не получается. Вопрос: как я могу убрать минус в столбце  ""days_employed"", а в столбце с доходом округлить данные после точки?  Код я начинаю писать так-<https://pastebin.com/f1DDwG0P>. Не могу понять что мне дальше нужно делать чтобы обработать пропуски в этих двух столбцах?",,Гогу Зинаида
1605340832.118800,1605500623.134600,U0185Q2MK19,"<@U01B84HU32R>,
Привет!

Когда мы проверяем гипотезу, нам важно не просто сравнить средние (мы ведь тогда просто могли их высчитать и посмотреть, какая больше/меньше), но нам важно понять статистически ли значимо это различие (или оно может быть случайным). А это можно понять только на основе всех значений, учитывая их отклонения, разброс и пр. (это все считается по специальным формулам функций проверки гипотез).

Поэтому и надо передавать не просто 2 средних, а все изначальные значения :slightly_smiling_face:",,Олег Булыгин
1605340832.118800,1605500721.134800,U0185Q2MK19,"<@U01C12DM2BA>, виктория все говорит верно, все верно. От этого зависит нужно ли применять критерий Уэлча (*equal_var=False*).

Но я придерживаюсь точки зрения, что его можно применять вообще всегда, даже без проверки, вот тут можно почитать обоснование: <https://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html>",,Олег Булыгин
1604904205.044200,1605503041.135100,U0185Q2MK19,"<@U01BBD8JS75>, привет!
Это диаграммы показывают совершенно разные вещи. По столбчатой диаграмме ты можешь сравнить количество
проданных копий в разрезе жанров.

А боксплоты показывают распределение. Медиана не показывает, что стрелялок больше, она показывает именно, что медианное значение количество проданных копий больше.

По аналогии:
у нас 2 страны, одна с населением 1000 человек, другая 100 000.
В первой медианная зарплата 1000 у.е., а во второй 500 у.е.
Не смотря на то, что в первой медианная зарплата больше, зарплатный фонд больше во второй просто из-за большего количества людей.",,Олег Булыгин
1604767441.029000,1605504003.135300,U0185Q2MK19,"<@U01BBD8JS75>, просьба всегда присылать и сам код, чтобы я сразу мог внести в него какие-то правки :slightly_smiling_face: Только по скриншотам разбирать код очень некомфортно.

Это можно сделать аналогично при помощи аргументов labels и title функции bar. Только лучше вынеси title_dict за пределы цикла, он в цикле не нужен.
И просто добавляем аргументы в bar:
```                 labels={
                     ""platform"": ""Платформы"",
                     column: ""Объем продаж""
                 },
                 title=title_dict[column])```","[{'name': 'raised_hands', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1604767441.029000,1605504189.135800,U0185Q2MK19,"<@U01BBD8JS75>, а чтобы сделать визуализации рядом можно использовать функции subplots: <https://plotly.com/python/subplots/>",,Олег Булыгин
1604904222.044500,1605505032.136100,U0185Q2MK19,"<@U01C12GKE1E>, просто построить визуализацию на основе столбца, где пропуски не заполнены)
Я вообще в данном случае не вижу особого смысла чем-то их заполнять",,Олег Булыгин
1604904144.043000,1605505135.136300,U0185Q2MK19,"<@U01B4EYRJ5U>, привет!
По визуализации явно видно, что продажи на PS3 находятся в нисходящем тренде (падают). То есть ее нельзя отнести к _потенциально_ прибыльным. Тут надо смотреть на те платформы, продажи которых только начинаются расти :slightly_smiling_face:",,Олег Булыгин
1604954231.057900,1605506564.136500,U0185Q2MK19,"<@U019E3T5678>, на эти нули просто надо будет обратить внимание при расчете средней продолжительности звонка и других подобных метрик. Скорее всего, не очень логично, если сразу сброшенные звонки будут влиять на среднюю продолжительность. А в целом я бы тоже не стал их трогать.",,Олег Булыгин
1605491889.133700,1605506842.136800,U0185Q2MK19,"<@U01BBD50335>, привет!

Для того, чтобы убрать минус есть метод abs, который можно применить к нужному столбцу: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.abs.html>
А для округления метод round: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round>

Пропуски заполняешь верно, с кодом все ок. Если результат отличается от ожидаемого, напиши подробней и пришли скриншоты.",,Олег Булыгин
1604904144.043000,1605507549.137000,U01B4EYRJ5U,"<@U0185Q2MK19> в предыдущих заданиях указано, что необходимо выбрать платформы с наибольшими суммарными продажами, потом взять актуальный период и посмотреть, какие растут по продажам, а какие падают. я так и взяла и получается, что у меня все падают. значит ли это, что тут необходимо смотреть больше платформ?",,Ольга Соколовская
1604904144.043000,1605507657.137200,U0185Q2MK19,"<@U01B4EYRJ5U>, да. Кроме того, у тебя почему-то в актуальный период не входят последние года данных (все заканчивается 2011). Актуальный период надо считать от последней даты назад на n лет",,Олег Булыгин
1604904144.043000,1605508333.137400,U01B4EYRJ5U,"<@U0185Q2MK19> спасибо за пояснение. в графике случайно не поправила заголовок, на 2015. на оси х видно, что там весь период c 2005 по 2015 г","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Ольга Соколовская
1605340832.118800,1605516069.137700,U01B84HU32R,"<@U0185Q2MK19> проект приняли, поэтому могу скрины присобачить))
Смотри, 1 скрин - моя изначальная группировка и таблица, по которой я потом делала срезы по тарифам (смарт\ультра), но такой вариант ревьюеру не понравился. Я сделала то, что на 2 скрине + еще вариант, где в самом массиве обращалась к нужному столбцу из общего датафрема:
`array1_1 = df[df['tariff_name'] == 'smart']`
`array2_1 = df[df['tariff_name'] == 'ultra']`
Такой вариант ревьюеру тоже понравился. Но я не понимаю, почему нельзя использовать первый столбец и что тогда я там группирую, что это не показатель средних выручек по пользователям тарифа.",,Виктория Онучина
1605340832.118800,1605517728.138200,U01B4EXCR7G,"<@U0185Q2MK19> Олег, подскажи пожалуйста как в итоге сравнить две дисперсии и как определить разницу между ними?  У меня от ревьювера вот такой запрос: Убедись в том, что дисперсии обоих выборок отличаются не более чем на 5%, прежде чем использовать `equal_var=True` при вызове `ttest_ind()`",,Сергей Саранцев
1604904046.041500,1605522947.138900,U01BHCPLXHS,"<@U0185Q2MK19>, привет! У меня вопрос немного отвлеченный от проекта. Я понимаю, что для нашего анализа заполнять пропуски в столбцах с рейтингами, годом не корректно в данном случае. Но что если мы по этим же данным начнем строить алгоритмы машинного обучения. Там же пропуски оставлять не вариант. В связи с этим вопрос такой - как на практике это происходит? сначала строится анализ, проверка гипотез и тд. А потом уже на этих же данных заполняются пропуски и строятся модели для прогнозирования?",,Вероника Гром
1604767441.029000,1605524263.139100,U01BBD8JS75,"<@U0185Q2MK19> в subplots в коде графики необходимо указать row=1, col=__ , а что в col указать чтобы они по порядку шли? Попробовал еще один цикл <https://pastebin.com/1dNCctGt|з><https://pastebin.com/DmxJZ1pM|апустить>, но выходит ошибка.",,Алексей Глазов
1604904046.041500,1605528585.139500,U01BHCPLXHS,или это всё же должна быть какая-то общая тактика?,,Вероника Гром
1604489000.472000,1605529511.139700,U01C12H8HJL,"<@U0185Q2MK19> разжевал, так разжевал :grin: спасибо огромное! Я нашла 2 косяка. Один при группировке таблицы с интернет-трафика и второй... Стыдно признаться... При расчете перерасхода. Я вычитала из положенных минут по тарифу использованные, а получается, надо было наоборот. Сдала на проверку. Чую, правда, сейчас посыпятся вопросики по разнице дисперсий, судя по тому, что пишут ребята в комментариях","[{'name': 'cool-doge', 'users': ['U0185Q2MK19'], 'count': 1}, {'name': 'grin', 'users': ['U01C12GKE1E'], 'count': 1}]",Юлия Филоненко
1605340832.118800,1605529981.139900,U0185Q2MK19,"<@U01B84HU32R>, в результате группировки у тебя получается средний доход по каждому пользователю (за какой-то период). Когда ты пытаешься проверить гипотезу на этих данных, как ты ее формулируешь? То есть ты как бы пытаешься найти значимую разницу средних среднего дохода пользователя между тарифами. Это странновато :slightly_smiling_face:

Но когда ты берешь все данные по помесячному доходу, ты явно сравниваешь средний доход между тарифами. При проверке гипотез надо брать исходные данные нашей исследуемой характеристики, ее никак группировать перед этим не надо. Рекомендую немного углубиться в статистику и посмотреть формулы расчета того же критерия Стьюдента, чтобы понять, какая логика расчетов там внутри заложена (например, вот здесь: <https://medstatistic.ru/methods/methods.html>). В формуле расчета t-значения уже все учитывается, ничего дополнительно делать не надо)",,Олег Булыгин
1605340832.118800,1605530097.140300,U01B84HU32R,<@U0185Q2MK19> спасибо большое! Теперь поняла почему такая группировка не нужна. Углублюсь в познания)),"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1605340832.118800,1605530146.140500,U0185Q2MK19,"<@U01B4EXCR7G>, дисперсию можно рассчитать при помощи метода var: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.var.html?highlight=var#pandas.Series.var>

Считаем дисперсию дохода по одному и второму тарифу, сравниваем их, если они примерно равны, то оставляем `equal_var=True`, иначе - ставим `equal_var=False`.

Лично я придерживаюсь точки зрения, что критерий Уэлча (`equal_var=False`) можно применять вообще всегда, даже без проверки, вот тут можно почитать обоснование: <https://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html>","[{'name': 'raised_hands', 'users': ['U01B4EXCR7G'], 'count': 1}]",Олег Булыгин
1604904046.041500,1605530465.141000,U0185Q2MK19,"<@U01BHCPLXHS>, привет!

Если мы строим модель по алгоритмам, которые чувствительны к пропускам, то да, пропуски оставлять нельзя.

И тут все сводится к тому, уверены ли мы в том, что мы их можем восстановить, не исказив при этом данные. Чаще всего так не бывает (для этого пропуски должны быть распределены случайно и мы должны иметь возможность явно их восстановить на основании других имеющихся данных, а так бывает редко). В этом проекте аналогично, нет никаких адекватных способов восстановления.

Поэтому пропуски в таких ситуациях просто удаляются. Если данных после этого перестают хватать для нормального обучения модели - garbage in garbage out. Ищем еще данные :slightly_smiling_face:",,Олег Булыгин
1604767441.029000,1605531237.141700,U0185Q2MK19,"<@U01BBD8JS75>, оу, тут беда, да. Оказывается именно plotly express не поддерживает такой вид отображения. subplots доступен только в полноценном plotly. Прямо в первой строке по ссылке про это написано: `Plotly Express does not support arbitrary subplot capabilities`
Я почему-то был уверен, что в нем можно тоже можно :disappointed:",,Олег Булыгин
1604767441.029000,1605533004.142200,U01BBD8JS75,"<@U0185Q2MK19> помоги реализовать эту затею в plotly пожалуйста, я запутался в коде, не выходит...",,Алексей Глазов
1604767441.029000,1605534630.142800,U01BBD8JS75,<@U0185Q2MK19> <https://pastebin.com/4EPisy66> получилось построить три одинаковых последних графика.... и без подписей(,,Алексей Глазов
1604904046.041500,1605536196.144000,U01BHCPLXHS,"<@U0185Q2MK19>, всё поняла - спасибо! :)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1605340832.118800,1605536275.144200,U019E3T5678,"<@U0185Q2MK19> Спасибо за комментарии.
Я сначала в качестве альтернативной гипотезы взяла то, что средняя выручка не равна. У меня получилось, что не равна. Потом взяла следующую гипотезу и проверила, что средняя выручка на тарифе Ультра больше. Мне ревьюер посоветовал не проверять односторонние гипотезы. Так как тогда увеличивается вероятность ошибки. Но я не понимаю почему, так как в конуе концов нам же важно знать, у кто больше денег приносит. Или я не так поняла что-то?",,Ольга
1604767441.029000,1605538048.144400,U01BBD8JS75,"Еще один способ построить три графика, но тоже не получается сделать их три в ряд <https://pastebin.com/zbtbE4Cs>",,Алексей Глазов
1604904046.041500,1605554687.144600,U01B84HU32R,"<@U0185Q2MK19> привет! Что-то я встряла. Хочу в rating заменить пропуски. Заменить в духе ""если находится игра с таким же названием, то заменяем пропуск rating на такой же rating"". Аргументация: ESRB выставляет рейтинг для самой игры, независимо от платформы, а следовательно на разных платформах у одной и той же игры один и тот же рейтинг должен быть (по логике). Но я плохо представляю как такое реализовать. Через if else? Или через цикл? Как правильнее. Подскажи, пожалуйста. А если заменять не надо, то может есть где почитать о подобных случаях или ты объяснишь, почему нет. Остальные рейтинги я не трогаю, там аргументацию привела.",,Виктория Онучина
1604904100.042100,1605555529.144800,U01B84HU32R,"<@U0185Q2MK19> привет! Подскажи, что считается за весь период и как понять вот это формулировку ""важны ли данные за все периоды?"", Важны для чего? Просто оценить важность количества игр в разные года и оценить так ли это вообще важно для оценки?",,Виктория Онучина
1604239257.407000,1605558552.145000,U019E4BDJFQ,"@ Олег, большое спасибо.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Nadyamane
1604904025.041200,1605559150.145200,U01BB74F8GJ,"<@U0185Q2MK19> без .astype(str), например, вот так
`df['year_of_release'] = <http://pd.to|pd.to>_datetime(df['year_of_release'], format='%Y-%m-%d').dt.year`
он превращает год в 1970",,Митя Журавлев
1604904025.041200,1605559212.145500,U01BB74F8GJ,,,Митя Журавлев
1605491889.133700,1605560103.145800,U01BBD50335,"<@U0185Q2MK19>, спасибо, не сложно, конечно, после чего уже получается)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Гогу Зинаида
1605562182.146800,1605562182.146800,U01B4EZSWHL,Подсчет для каждого пользователя в проекте про Мегалайн,,Лиза Толмачева
1605562182.146800,1605562367.146900,U01B4EZSWHL,"<@U0185Q2MK19> Добрый вечер, подскажи пожалуйста как добавить столбцы к общей таблице, а то что я туплю. Я рассчитала( прилагаю скриншот) и не могу добавить в общую таблицу. Извиняюсь за глупый вопрос",,Лиза Толмачева
1605562182.146800,1605562458.147300,U01B4EZSWHL,<http://joxi.ru/1A5E860ibGednA>,,Лиза Толмачева
1605340832.118800,1605584703.147900,U0185Q2MK19,"<@U019E3T5678>, даже при проверке двухсторонней гипотезы мы можем понять, какая из средних больше по знаку t-статистики, это не проблема)
Вопрос именно в формулировке нулевой гипотезы. Если у нас изначально нету убежденности в знаке разницы (мы допускаем отклонения в обе стороны), то надо использовать двухстороннюю гипотезу. Если же нам важно знать только про отклонение в одну сторону, то можно использовать одностороннюю, но это не наш случай.",,Олег Булыгин
1604767441.029000,1605585330.148200,U0185Q2MK19,"<@U01BBD8JS75>, подправил твой первый вариант, посмотри, это то, что предполагалось?

```plt.figure(figsize=(15, 5))
i = 1
for column in ['NA_sales', 'EU_sales', 'JP_sales']:
        top_region_platform = (df.groupby('Platform')[column].sum()
                                            .sort_values(ascending=False).reset_index().head(5))
        plt.subplot(1, 3, i)
        sns.barplot(data = top_region_platform,
                             x = 'Platform', 
                             y = column)
        plt.title(f'Продажи в {column[:2]}')
        plt.ylabel('Объем продаж')
        plt.xlabel('Платформы')
        i += 1```","[{'name': 'cat-high-five', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1604904046.041500,1605585429.148500,U0185Q2MK19,"<@U01B84HU32R>, тут можно сделать такую логику:

1. пишем функцию для ее дальнейшего использования в apply
2. в этой функции делаем проверку, если в строке стоит NaN у рейтинга
3. Если там NaN, то берем срез у датафрейма с таким же названием игры
4. И в этом срезе берем значение по столбцу рейтинга, который не NaN (если такой есть)
5. Заменяем у текущей строки NaN на это значение
6. Применяем функцию через apply к датафрейму
",,Олег Булыгин
1604904100.042100,1605586080.148700,U0185Q2MK19,"<@U01B84HU32R>, весь период - это все данные, которые есть в датафрейме. Но, очевидно, давние периоды могут быть уже неактуальны. Понятно, что 1995 динамика не показателя, т.к. тогда просто не было массово ПК и консолей. Потом рынок растет и достигает пика в 2008 году. Уже ПК и консоли есть у всех, кому надо. Скорее всего, для дальнейших выводов показательнее будут данные именно примерно с этого года.",,Олег Булыгин
1604904025.041200,1605586216.149000,U0185Q2MK19,"<@U01BB74F8GJ>, в format надо указывать только `'%Y'` , т.к. в исходных данных у нас нет ни месяца, ни дня. Из-за этого перевод будет происходит неправильно",,Олег Булыгин
1605562182.146800,1605586336.149300,U0185Q2MK19,"<@U01B4EZSWHL>, привет!

Вот здесь подробно обсуждали, как считать выручку: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604241997418300?thread_ts=1604210798.404500&amp;cid=G01B461LV0E>

Просто делаем `df['revenue'] = df.apply(get_revenue, axis=1)`",,Олег Булыгин
1604904046.041500,1605613040.150000,U019E3T5678,"<@U0185Q2MK19> Олег, подскажи пожалуйста, а как можно проверить, что пропуски случайны (кроме здравого смысла)?",,Ольга
1604904046.041500,1605616129.150200,U01C12DM2BA,А у кого какие есть соображения о причинах пропусков? Мне в голову ничего не лезет пока.,,Фарид Бабаев
1604904046.041500,1605616164.150400,U0185Q2MK19,"<@U019E3T5678>, это довольно непростая тема для начала. Рекомендую почитать вот эти материалы:

<https://towardsdatascience.com/statistical-test-for-mcar-in-python-9fb617a76eac>
<http://www.stat.cmu.edu/~hseltman/726/Missing%20Data%20726.pdf>

Иногда может помочь простая визуализация",,Олег Булыгин
1604904046.041500,1605616259.150700,U0185Q2MK19,"<@U01C12DM2BA>, в этом наборе данных мы только с натяжкой в некоторых случаях можем восстановить рейтинг (как писали выше). Никакие другие пропуски адекватно восстановить не получится на основе имеющихся данных.",,Олег Булыгин
1604904046.041500,1605616318.150900,U01C12DM2BA,"Это понятно, я о причинах возникновения пропусков, тут тоже только гадать можем?",,Фарид Бабаев
1604904046.041500,1605616359.151100,U0185Q2MK19,"<@U01C12DM2BA>, в целом да. Как и в большинстве случаев, если у нас нет под рукой человека, который эти данные собирал)",,Олег Булыгин
1604904046.041500,1605616518.151300,U01C12DM2BA,"В задании еще говорится про аббревиатуру 'tbd' в столбце рейтинга, я вывожу `df['rating'].unique()` и у у меня там нет ничего подобного.",,Фарид Бабаев
1604767441.029000,1605620627.151600,U01BBD8JS75,"<@U0185Q2MK19> попробовал применить твой <https://pastebin.com/tRFmCziQ|код> к классификации по жанрам, и вышло что-то странное",,Алексей Глазов
1605562182.146800,1605631642.152200,U01B4EZSWHL,<@U0185Q2MK19> спасибо большое ),"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Лиза Толмачева
1604904046.041500,1605673387.152400,U0185Q2MK19,"<@U01C12DM2BA>, могут быть разные версия датафрейма, его периодически обновляют. Ничего страшного :slightly_smiling_face:",,Олег Булыгин
1604767441.029000,1605673961.152600,U0185Q2MK19,"<@U01BBD8JS75>, проблему воспроизвести не могу, у меня аналогичная группировка и визуализация работает полностью, как надо. Попробуй запустить этот код изолированно, без предыдущих действий. И тогда надо изучать таблицу top_region_genre, какая она у тебя в  итоге получается с учетом всех предыдущих действий над данными. В другом проблемы не вижу.
<https://i.paste.pics/AQ04A.png>",,Олег Булыгин
1604904025.041200,1605680722.153000,U01BHCRMNGL,"<@U0185Q2MK19> , помоги пожалуйста: ревьюер попросил преобразовать год релиза и оценку критиков в тип данных int, но варианты, которые я пробовала не работают. Как это правильно сделать?
 <http://joxi.ru/gmvy6pjF1P3E0r>",,Дарья Баранкова
1604904117.042400,1605694252.153500,U01B84HU32R,"<@U0185Q2MK19> привет! Подскажи, а зачем мы вообще этот этап делаем? Почему нам нужно анализировать данные эти, если потом все равно будет делать срез актуального периода и анализировать по нему? Немного не понимаю, что в этом этапе должно быть итогом.",,Виктория Онучина
1604904025.041200,1605699466.153700,U0185Q2MK19,"<@U01BHCRMNGL>, вот так все получится :slightly_smiling_face:

`df['critic_Score'] = df['critic_Score'].astype('Int64')`",,Олег Булыгин
1604904117.042400,1605699629.154000,U0185Q2MK19,"<@U01B84HU32R>, привет!

Это нам поможет определить стандартный жизненный цикл средней платформы. Понять, когда после роста в среднем начинается спад и платформа начинает ""умирать"".",,Олег Булыгин
1604904117.042400,1605699782.154200,U01B84HU32R,"<@U0185Q2MK19> а как он нам потом поможет? При анализе актуального периода и, к примеру, где ПС4 и Хone мы могли сделать выводы, что ""платформы новые, а так как мы знаем, когда платформа вымирает, им ещё жить и жить""?",,Виктория Онучина
1604904025.041200,1605700202.154400,U01BHCRMNGL,"<@U0185Q2MK19>, :joy:, заучилась походу. Спасибо, все получилось",,Дарья Баранкова
1604904117.042400,1605700657.154600,U0185Q2MK19,"<@U01B84HU32R>, да, понимая жизненный цикл, мы можем сделать предположения о том, по каким платформам будет вскоре рост продаж (и когда он сойдет на нет). Ну и по сути ""актуальный период"" анализа из следующего вопроса и определяется на основе понимания жизненного цикла. Он явно не может быть больше него, при этом если у новых платформ, какие то первые этапы прошли, то мы должны делать предположения исходя из этого усредненного цикла предыдущих поколений консолей.",,Олег Булыгин
1604904117.042400,1605700714.154800,U01B84HU32R,<@U0185Q2MK19> спасибо большое за ответ! А то именно в логической цепочке что куда потерялась немного. Теперь стало яснее,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604904117.042400,1605706789.155100,U01C12DM2BA,"<@U0185Q2MK19>
Я выявил лидеров по продажам так `platform = df.groupby('platform')['total_sales'].count().sort_values(ascending=False)`,
после вывожу их распределение через цикл
`platforms = ['DS', 'PS3', 'Wii', 'X360', 'PSP']`
for plat in platforms:
    fig = px.histogram(df.query('platform == @plat'), x = 'year_of_release', marginal = 'box', title = plat)
    fig.show()
но я хочу чтобы все было на одном графике, как мне это сделать подскажи плиз",,Фарид Бабаев
1605706856.155800,1605706856.155800,U01C12H8HJL,значения tbd в столбцах с рейтингом,,Юлия Филоненко
1605706856.155800,1605706941.155900,U01C12H8HJL,"• Во втором шаге есть задание ""разберемся с аббревиатурой 'tbd' в столбцах с рейтингом. Опишем его и подумаем как обработать."" Я не вижу эти значения. Есть RP - который означает, что рейтинг ожидается ... а вот tbd не вижу... кто нашел?
",,Юлия Филоненко
1605706856.155800,1605706975.156100,U01BB74CMMG,users_....,,Антон Дмитриев
1605706856.155800,1605707026.156300,U01BB74CMMG,"Выведи информацию о таблице  и увидишь, что столбец с рейтингом пользователей имеет строковый тип. Вот там и есть эти значения",,Антон Дмитриев
1605706856.155800,1605707214.156900,U01BB74CMMG,,,Антон Дмитриев
1605706856.155800,1605708592.157200,U01B84HU32R,"Олег писал, что датафреймы обновляют и тебе мог попастся новый/старый. Если не нашла, то не страшно. Я через unique смотрела по столбцу, они были.","[{'name': 'heart', 'users': ['U01C12H8HJL'], 'count': 1}]",Виктория Онучина
1605706856.155800,1605708651.157400,U01B84HU32R,Вот :),,Виктория Онучина
1605706856.155800,1605708691.157900,U01C12H8HJL,<@U01B84HU32R> спасибо!,"[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Юлия Филоненко
1605706856.155800,1605708777.158300,U01C12H8HJL,<@U01BB74CMMG> я и так uniqe и value_counts смотрела. Ничего нет),,Юлия Филоненко
1605706856.155800,1605709202.158600,U01BB74CMMG,Тебе повезло!!! Уже предобработанные df попались :smiley:,"[{'name': 'grin', 'users': ['U01C12H8HJL'], 'count': 1}]",Антон Дмитриев
1605706856.155800,1605709267.158800,U01C12H8HJL,"<@U01B84HU32R> а ты расшифровывала значения в `rating`? Я вот думаю, заморачиваться или оставить обозначения как есть)",,Юлия Филоненко
1605706856.155800,1605709583.159000,U01B84HU32R,"<@U01C12H8HJL> я не смогла сделать, как написал Олег, что-то не допираю, сделала иначе (правда криво), там 170 значений заполняется, я плюнула на это дело))
Нет, значит нет. Там вообще способов полно это все распределить вплоть до того, что у всех игр Марио рейтинг Е ахах. Но лучше оставить, искать и заполнять информацию со сторонних ресурсов не наша работа))",,Виктория Онучина
1605706856.155800,1605709735.159200,U01C12H8HJL,<@U01B84HU32R> спасибо еще раз!,"[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Юлия Филоненко
1604904117.042400,1605715300.159600,U01C12DM2BA,"<@U0185Q2MK19>
я пробую делать так <https://pastebin.com/fbEBTisg> , но выходит KeyError: 'year_of_release'",,Фарид Бабаев
1605706856.155800,1605715308.159800,U01BBD8JS75,"Tbd вроде в user_score спрятаны, а не в рейтинге, где его Фарид искал...",,Алексей Глазов
1605706856.155800,1605715366.160000,U01C12H8HJL,"<@U01BBD8JS75> я его и там, и там, и в оценках критиков смотрела. Нет нигде)",,Юлия Филоненко
1605706856.155800,1605715510.160200,U01BBD8JS75,"<@U01C12H8HJL> ну одной заботой меньше, если у числовых столбцов в info стоят типы float или int, значит все норм)",,Алексей Глазов
1604904173.043600,1605730308.167200,U01BHCRRVNG,"<@U0185Q2MK19> и ребята привет! У меня изначально коэффициент корреляции между оценкой пользователей и продажами был очень мал, сделала вывод, что зависимости нет. Код-ревьюер сказал, что заполнять пропуски в столбце user-score медианой не корректно, и связь с продажами на самом деле есть. Я оставила пропуски на местах, но коэффициент корреляции все равно оооооочень низкий. У всех нет связи между этими столбцами или я что-то делаю не так?  `df_actual_platform.query('platform == ""XOne""')['sales'].corr(df_actual_platform.query('platform == ""XOne""')['user_score'])`",,Валерия Круглова
1604904173.043600,1605736392.167600,U01B84HU32R,"<@U0185Q2MK19> тоже вопрос по этой теме. В самом здании на практикуме написано, что нужно взять одну популярную платформу (я выбрала ps3, поскольку она самая прибыльная, охватывает почти весь актуальный период, думаю, что подходит). И по ней сделаю диаграмму и посчитаю корреляцию. Корреляцию считать по каждой игре? Рассмотреть название игры, отзывы и внутри корреляцию рассмотреть для каждого? Или как правильно ее посмотреть?

А потом нужно сравнить выводы. А как их сравнивать? Мне потом корреляции такие по всем делать? Или там как-то кучнее все можно вообразить?

Подскажи, а то я очень путаюсь. Здесь одно написано (не указано про одну популярную платформу), на сайте практикума другое. Я читала ниже ответ твой, но не очень понимаю: если групп позвать все другие, то там же не на каждой платформе игры одинаковые... Короче, запуталась снова))",,Виктория Онучина
1604904173.043600,1605764654.167900,U01BHCRMNGL,"<@U01BHCRRVNG>, у меня тоже получилось, что корреляции с оценкой пользователей нет. У ревьюера вопросов не возникло.","[{'name': '+1', 'users': ['U01BHCRRVNG'], 'count': 1}]",Дарья Баранкова
1604904222.044500,1605772886.168100,U01C12DM2BA,<@U0185Q2MK19> а как можно проверить влияет ли рейтинг ESRB на продажи в отдельном регионе?,,Фарид Бабаев
1604904117.042400,1605776074.168400,U0185Q2MK19,"<@U01C12DM2BA>, если надо прямо вот все на одном, то можно так:

```platform = df.groupby('platform')['total_sales'].count().sort_values(ascending=False)
platforms = ['DS', 'PS3', 'Wii', 'X360', 'PSP']
fig = px.histogram(df[df.platform.isin(platforms)], x = 'year_of_release', marginal = 'box', color='Platform')
fig.show()```
Но я не уверен, что это очень читаемо будет, сразу много гистограмм друг на друге",,Олег Булыгин
1604904173.043600,1605776160.168600,U0185Q2MK19,"<@U01BHCRRVNG>, подтверждаю, там маленькая величина должна очень получаться. Но заполнять пропуски не надо :slightly_smiling_face:",,Олег Булыгин
1604904173.043600,1605776197.169500,U01BHCRRVNG,Спасибо!)) ,,Валерия Круглова
1605776220.170000,1605776220.170000,U01BBD8JS75,Открытие блокнотов из я.практикума в юпитере на компьютере,,Алексей Глазов
1605776220.170000,1605776583.170100,U01BBD8JS75,"<@U0185Q2MK19> столкнулся с такой проблемой, скачал проекты на компьютер и так как не загружались графики решил перезапустить код, но локальный юпитер не смог прогнать код, который в я.практикуме быстро запускается. В первом случае появилась ошибка, после того как запустил скаченное окружение, ошибка пропала, но теперь уже минут 10 думает над лемматизацией....",,Алексей Глазов
1604904173.043600,1605776883.170700,U0185Q2MK19,"<@U01B84HU32R>, корреляцию по каждой игре посчитать невозможно, т.к. корреляция оценивает взаимное изменение двух факторов (а оценка конкретной игры - это одно число). Нужно именно определить, как вообще продажи связаны с оценками (то есть мы смотрим все данные). Для этого можно использовать метод `corr()` .

Ну и scatter plot надо построить.

Т.е. считаешь корреляцию между продажами и оценками пользователей по одной платформе, визуализируешь.
Считаешь корреляцию между продажами и оценками критиков, визуализируешь.

Там скорее всего будет явная разница, что и нужно написать в выводах.

Потом делаешь тоже самое, но берешь срез ""все платформы, кроме этой"" (ту которую ты уже посмотрела). И изучаешь, результат - такой же он или нет.","[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Олег Булыгин
1604904173.043600,1605776967.170900,U01B84HU32R,"<@U0185Q2MK19> спасибо большое за ответ, визуально поняла теперь яснее, что нужно!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1605776220.170000,1605776987.171200,U01BBD8JS75,html также как-то криво открывается,,Алексей Глазов
1604904222.044500,1605777033.171500,U0185Q2MK19,"<@U01C12DM2BA>, можно сгруппировать данные по рейтингу и посмотреть какую долю продаж от общих продаж занимает каждый возрастной рейтинг. И так по каждому региону.
Если структура будет отличаться - то зависимость от региона есть.",,Олег Булыгин
1605776220.170000,1605777354.171700,U0185Q2MK19,"<@U01BBD8JS75> - если окружение точно такое же, то таких ситуаций возникать не должно (код должен работать одинаково). Но с лемматизацией - разговор отдельный, это частая проблема при исполнении на локальном ПК, вот здесь я писал, что помогает операция кеширования: <https://yandex-students.slack.com/archives/G01B461LV0E/p1602158715161500?thread_ts=1602157427.160400&amp;cid=G01B461LV0E>

На счет html - не совсем понимаю вопроса. Криво открывается тот, который сохранен в практикуме? Просто Jupyter то тут вообще не причем, html открывается браузером напрямую.",,Олег Булыгин
1605776220.170000,1605777611.172200,U01BBD8JS75,"<@U0185Q2MK19> Из практикума нажал сохранить проект в html, раз не получается сохранить сам блокнот (чтобы потом можно было посмотреть какие-то моменты и части кода). Но когда открываю его в браузере, то текст сначала идет нормально сверху вниз, а потом как-будто размазывается вправо по одной ячейке кода, как на скриншоте.",,Алексей Глазов
1605706856.155800,1605777819.172400,U0185Q2MK19,"Я сейчас у себя в среде проверил, у меня tbd в user score есть :slightly_smiling_face:

На всякий случай чекните именно этот столбец, чтобы не пропустить. Если нет - то и нет)","[{'name': 'cat-high-five', 'users': ['U01C12H8HJL'], 'count': 1}]",Олег Булыгин
1605776220.170000,1605777961.172700,U0185Q2MK19,"<@U01BBD8JS75>, а почему ты говоришь, что блокнот нельзя сохранить из Практикума? Конечно, можно. `File - download as... ipynb`
Или я не правильно понимаю?)

html сейчас у себя протестил - все ок сохраняет.
Можешь скинуть мне проблемный блокнот в личку, тоже попробую его в html перевести и понять из-за чего так",,Олег Булыгин
1605776220.170000,1605778005.173000,U01BBD8JS75,"<@U0185Q2MK19> скачать можно, запустить и прогнать на компьютере - проблематично)",,Алексей Глазов
1605776220.170000,1605778091.173200,U0185Q2MK19,"<@U01BBD8JS75>, это все упирается только в версии библиотек. Если они совпадают со средой практикума - запускаться должно все ок (опять же, кроме лемматизации у многих).

Я также страдаю, т.к. у меня все библиотеки всегда актуальных версии,  а в практикуме многие немного устаревшие)",,Олег Булыгин
1605706856.155800,1605778100.173400,U01C12H8HJL,"@Олег я уже начинаю думать, что со мной что-то не так. Ни unique, ни sort_values, ни value_counts, ни query, ни loc не нашли мне этот мифический tbd :cattyping:",,Юлия Филоненко
1605706856.155800,1605778185.173600,U0185Q2MK19,"<@U01C12H8HJL> - если нет, то и нет, ничего страшного)",,Олег Булыгин
1605776220.170000,1605778463.173800,U0185Q2MK19,"<@U01BBD8JS75>, проблему нашел.

<https://pastenow.ru/AQGOY>

Посмотри на этот комментарий. Тег div не закрыт, что ломает всю разметку.

Нужно в конце добавить &lt;/div&gt;","[{'name': 'happy-cat', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1605776220.170000,1605780180.174200,U01BBD8JS75,"<@U0185Q2MK19> а не подскажешь более быстрые библиотеки лемматизации? в интернете было написано про pymorphy2, но я не могу ее в анаконду засунуть",,Алексей Глазов
1605776220.170000,1605786174.174400,U0185Q2MK19,"<@U01BBD8JS75>, я не могу сказать, что есть какие-то библиотеки, которые более оптимизированы в этом плане. Может не знаю, но обычно это вообще не критично.

Если использовать функцию кеширования в nltk, то операция в нашем случае должна выполнятся почти мгновенно.

nltk при этом одна из самых распространенных библиотек для работы с текстами.",,Олег Булыгин
1604904233.044800,1605788289.174600,U01C12DM2BA,<@U0185Q2MK19> а почему у меня p-значение вышло nan?,,Фарид Бабаев
1604904173.043600,1605807879.175500,U01B84HU32R,"<@U0185Q2MK19> привет! Подскажи, пишу вот такой код, чтобы сделать корреляцию, пробовала еще другой, ни в какую не хочет. Уже всю голову сломала, что не так. Делала такой же, но с user_score (в котором делала срез без tbd и меняла тип данных на float64), а тут уже проблемы...

Сам код:
`pop_ps3_corr = df[df['platform'] == 'PS3']`
`np.correlate(pop_ps3_corr['critic_score'], pop_ps3_corr['all_sales'])`
`pop_ps3_corr['critic_score'].corr(pop_ps3_corr['all_sales'])`",,Виктория Онучина
1604239257.407000,1605814248.175900,U01C12HG4QY,"<http://joxi.ru/l2ZPn43i7qGGwr>
Привет! делаю объединение таблицы users с объединенными, сгруппированными таблицами и у меня пропал столбец ""Месяц"" после группировки",,Маргарита К
1604904233.044800,1605815410.176200,U01B84HU32R,"Подпишусь, послушаю, тоже интересно почему (у самой так).",,Виктория Онучина
1604239257.407000,1605815809.176400,U01C12HG4QY,Починилось,,Маргарита К
1604904233.044800,1605816521.176600,U01B84HU32R,<@U01C12DM2BA> я попробовала удалить пропуски в user_score перед всем этим. Рассчитала в итоге p-value. Но интересно послушать отзыв Олега)),,Виктория Онучина
1604904222.044500,1605827606.176800,U019E3T5678,"<@U0185Q2MK19> Добрый день!
Я хочу написать функцию для анализа региона
def region_special(region):
    return data_good_platforms.groupby('genre')[region].sum().sort_values(by=region).head(5)
Но на при добавлении сортировки пишет ошибку. Не могу разобраться, что не так.",,Ольга
1604904222.044500,1605834495.177000,U019E3T5678,"если делать через agg, то все хорошо",,Ольга
1604904173.043600,1605849280.177200,U0185Q2MK19,"<@U01B84HU32R>, нужно применять метод corr. Но убедись, что нужные столбцы у тебя имеют числовой тип (а не object). Скорее всего, проблема именно в этом.",,Олег Булыгин
1604904222.044500,1605849478.177400,U0185Q2MK19,"<@U019E3T5678>, привет!

Надо так:

```def region_special(region):
    return df.groupby('genre')[[region]].sum().sort_values(by=region).head(5)```
Иначе у тебя получается не датафрейм, а Series, а его так отсортировать не получится.",,Олег Булыгин
1604904233.044800,1605849546.177700,U0185Q2MK19,"<@U01C12DM2BA>, да, дело именно в пропусках. Функция ttest_ind по-умолчанию  с ними не работаем, надо их предварительно убрать.",,Олег Булыгин
1604904173.043600,1605856104.177900,U01B84HU32R,"<@U0185Q2MK19> corr тоже применяла, везде числовые типы. Но я плюнула, сделала по итогу общую таблицу на все нужны значения, так она делается, а по отдельности - нет.",,Виктория Онучина
1604904173.043600,1605856334.178100,U01B84HU32R,"<@U0185Q2MK19> в user_score tbd я убирала, все работало, а вот с critic_score выдавало ошибку, что я выше в скрине скинула. critic_score я переводила в Int64, может из-за этого ругался..",,Виктория Онучина
1604210798.404500,1605867237.178300,U01B4EZSWHL,Добрый день <@U0185Q2MK19> подскажи пожалуйста почему так может получатся? я уже голову сломала и не понимаю а хочется разобраться <http://joxi.ru/52aWwd9HkkXN4r>,,Лиза Толмачева
1604904233.044800,1605867377.178600,U019E3T5678,"<@U0185Q2MK19> а что значит, что функция с ними не работает? Что конкретно она делает?",,Ольга
1604210798.404500,1605867838.178800,U01BHCPPL2Y,"Так надо из включённых в тариф услуг вычитать сколько абонент наговорил, а не наоборот.
Далее все положительные числа заменяешь на 0 (у абонента остался неизрасходованный трафик), а у всех отрицательных убираешь знак минус - это и будет перерасход",,Me_
1604210798.404500,1605867871.179200,U01B4EZSWHL,"Поняла , спасибо ",,Лиза Толмачева
1604904173.043600,1605873034.179400,U0185Q2MK19,"<@U01B84HU32R>, можно попробовать просто применить метод corr датафрейма: `df['critic_score', 'all_sales'].corr()` ",,Олег Булыгин
1604210798.404500,1605874292.179600,U0185Q2MK19,"<@U01B4EZSWHL>, твой вариант тоже вполне приемлемый, если получается отрицательное число, то просто нету перерасхода. А потом это можно учесть при расчете дохода, вот здесь обсуждали как: <https://yandex-students.slack.com/archives/G01B461LV0E/p1604241997418300?thread_ts=1604210798.404500&amp;cid=G01B461LV0E>",,Олег Булыгин
1604904233.044800,1605874387.179900,U0185Q2MK19,"<@U019E3T5678>, если мы делаем какое-то действие между числом и NaN мы всегда будем получать NaN. Функция для проверки  гипотезы так себя и ведет - по формуле расчета значения t-статистики при наличии пропусков мы всегда будем получать в результате NaN.

Чтобы так не было нужно указывать специальный аргумент na_policy у функции: <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html>",,Олег Булыгин
1604904173.043600,1605876823.180100,U01B84HU32R,"<@U0185Q2MK19> спасибо, в будущем попробую, проект уже приняли))","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1605706856.155800,1605878710.180400,U01C12DM2BA,"Я нашел таки его в user_score)
просто после перевода типа данных ""tbd"" исчезло, так как указал errors='coerce'","[{'name': '+1', 'users': ['U01C12H8HJL'], 'count': 1}]",Фарид Бабаев
1605706856.155800,1605881159.180900,U01C12DM2BA,"<@U0185Q2MK19> Я решил заменить все tbd на средний рейтинг этой же игры. У меня есть отдельный датафрейм со средним пользовательским рейтингом и общая база, где есть tbd. Как ме построить условие для replace?или использовать что то другое?",,Фарид Бабаев
1605706856.155800,1605883212.181200,U01C12H8HJL,<@U01C12DM2BA> тайна раскрыта),,Юлия Филоненко
1605706856.155800,1605887752.181600,U0185Q2MK19,"<@U01C12DM2BA>, мне кажется, более правильным решением будет их все заменить на NaN. Это будет очень смелым предположением, что рейтинг игр на разных консолях всегда примерно одинаковый для замены на средние. Мы так сильно исказим данные.","[{'name': '+1', 'users': ['U01C12DM2BA'], 'count': 1}]",Олег Булыгин
1604904144.043000,1605895661.181900,U01C12DM2BA,"<@U0185Q2MK19> когда я строю график,(на фото) , видно что PS4 лидирует по количеству продаж, а когда делаю так `df.query('platform in @active_platforms and year_of_release >= 2006').groupby('platform')['total_sales'].sum().sort_values(ascending=False)`  , то выходит это
```platform
X360    952.99
PS3     931.34
Wii     891.18
PS4     314.14
3DS     257.81
PC      163.42
XOne    159.32
WiiU     82.19
PSV      53.81```
что я делаю не так?",,Фарид Бабаев
1604904233.044800,1605898649.182200,U01C12DM2BA,"<@U0185Q2MK19> Я удалил все пропуски, первый тест удачно проходит, а у второго почему то опять p-значение: nan. Они подряд выполняются :eyes:",,Фарид Бабаев
1604904144.043000,1605937253.182400,U0185Q2MK19,"<@U01C12DM2BA>, все так :slightly_smiling_face:

График показывает динамику, а сводная таблица суммарные продажи за все периоды. То, что PS4 лидирует в последние года, не значит, что за все время у нее суммарные продажи больше (т.к. более старые платформы продаются намного больше времени).",,Олег Булыгин
1604904233.044800,1605937363.182600,U0185Q2MK19,"<@U01C12DM2BA>, без когда сказать сложно, в чем может быть причина. Но я рекомендую использовать именно аргумент na_policy в функции тестирования гипотез, так будет надежнее (выше об этом писал).",,Олег Булыгин
1604904144.043000,1605942366.183300,U01C12DM2BA,"Да я понял, там pivot table mean же берет по умолчанию)",,Фарид Бабаев
1604904233.044800,1605943738.183500,U01C12DM2BA,"<@U0185Q2MK19> Что еще интересно, при первом выполнении кода выдается такое предупреждение",,Фарид Бабаев
1604904233.044800,1605943843.183800,U01C12DM2BA,"<@U0185Q2MK19> Добавив nan_policy='omit', получаю тот же результат",,Фарид Бабаев
1604904233.044800,1605955601.184200,U0185Q2MK19,"<@U01C12DM2BA>, функция у тебя применена верно, но явно что-то не так с содержимым variance_action и variance_sport. Ты считаешь средние оценки по этим двум жанрам и у тебя получаются значения 1 и 2 (при том, что оценка идет по 100-балльной шкале у критиков и по 10-балльной у пользователей). Явно средние значения оценок не могут быть 1 и 2.
Видимо, ты сделал какие-то преобразования со столбцами, которые как-то попортили данные. Покажи именно их содержимое",,Олег Булыгин
1604904046.041500,1606034923.184400,U01C12DM2BA,<@U0185Q2MK19> Подскажи как можно проверить есть ли закономерности в появлении пропусков?,,Фарид Бабаев
1604904144.043000,1606036222.184600,U01C12DM2BA,"<@U0185Q2MK19> Мне надо уточнить, я хочу выявить наиболее успешные платформы. Я определил что средний срок платформы (по медианному значению) составляет 6 лет. Соответственно я построил график по таким данным:
(df
     .query('platform in @active_platforms and year_of_release &gt;= 2010')
     .pivot_table(index='year_of_release', columns = 'platform', values='total_sales', aggfunc='sum')
     .plot(grid=True, figsize=(15,10), fontsize= 10, style = 'o-', linewidth=4.0, xticks=(range(2010, 2017)))
     .legend(loc=5, prop={'size': 15})
)
я использовал aggfunc = sum, правильно да?
спрашиваю, потому что если использовать mean, то потом когда получаю срез на 2016 год `df.query('platform in @active_platforms and year_of_release == 2016').groupby('platform')['total_sales'].mean().sort_values(ascending=False)` , то почему то данные  с данными на графике не совпадают.",,Фарид Бабаев
1604904046.041500,1606039192.185200,U0185Q2MK19,"<@U01C12DM2BA>, вот здесь уже давал материалы про это:
<https://yandex-students.slack.com/archives/G01B461LV0E/p1605616164150400?thread_ts=1604904046.041500&amp;cid=G01B461LV0E>

Это достаточно непростым вопросом может быть)",,Олег Булыгин
1604904144.043000,1606039430.185500,U0185Q2MK19,"<@U01C12DM2BA>, если определяем популярность, то да, корректнее брать суммарные продажи за периоды :slightly_smiling_face:",,Олег Булыгин
1604904173.043600,1606039849.185700,U01C12DM2BA,"<@U0185Q2MK19> Про коэффициент корреляции понятно, но вот ревьюер попросил построить диаграмму рассеяния и сделать вывод по ней, а  у меня другого вывода который я уже сделал по коэффициентам нет",,Фарид Бабаев
1604904173.043600,1606049674.186200,U01B84HU32R,"<@U01C12DM2BA> на диаграмме можешь заметить, где больше разбросов, где меньше, где увеличение в бОльшую сторону, а где в принципе равномерно распределено все +/-. Тут, мне кажется, проверяют умение читать такую диаграмму.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1604904222.044500,1606051212.186400,U01C12DM2BA,"<@U0185Q2MK19> Мне нужна помощь с подсчетом доли продаж по каждому региону. Цитата ревьюера:
""Сейчас *ты считаешь долю продаж игр определенного рейтинга от общих продаж игр с данным рейтингом (то есть в знаменателе ты суммируешь все продажи по указанному рейтингу)*. Это вполне нормальные расчёты. Но в нашей ситуации мы хотим сравнить регионы между собой. Нам важно, какой рейтинг преобладает внутри региона. Поэтому *стоит найти долю проданных игр по каждому рейтингу от общего количества игр, проданных в регионе (то есть в знаменателе мы фиксируем регион и суммируем продажи по региону)*.""
Как мне это более простым способом посчитать? То как я это делаю выходит очень криво и неинформативно",,Фарид Бабаев
1604904222.044500,1606092150.186700,U01B84HU32R,"<@U01C12DM2BA> привет! Я делала через сводную таблицу. То есть сделала сводную таблицу, добавила aggfunc, топ5 - это наш head(5), если сортируем по убыванию.  У тебя просто должна получиться таблица с жанром и суммой продаж.  Но если хочешь найти долю продаж от всего, то в сводной будут столбцы жанры, общие продажи, продажи региона, доля продаж. Ну, доля находится просто делением всего на регионное)",,Виктория Онучина
1604904173.043600,1606105804.186900,U0185Q2MK19,"<@U01C12DM2BA>, согласен с Викторией, также здесь можно прокомментировать выбросы.

Советую почитать вот эти материалы: <https://datavizcatalogue.com/RU/metody/diagramma_rassejanija.html>
<https://studopedia.ru/2_109437_diagrammi-rasseivaniya.html>",,Олег Булыгин
1604904222.044500,1606108473.187500,U0185Q2MK19,"<@U01C12DM2BA>, код может выглядеть примерно так:

```region_ratings = (df
                   .groupby('rating')
                   .agg({'na_sales': 'sum', 
                         'eu_sales': 'sum', 
                         'jp_sales': 'sum'
                        }
                       )
              )

na = region_ratings.sort_values(by='na_sales', ascending=False)[['na_sales']].div(na.na_sales.sum()).round(2)```
Последняя строка - подсчет для одного региона, аналогично можно для двух других",,Олег Булыгин
1604904117.042400,1606313381.193900,U01C12HG4QY,"Всем привет! Помогите плиз. <@U0185Q2MK19> Как мне эту штуку построить в цикле, чтобы через query не фильтровать каждую платформу в запросе`platform.query('platform ==""PS3""').groupby(['year_of_release'])['sale'].agg(['count']).plot()`",,Маргарита К
1606315310.195100,1606315310.195100,U01B4EXCR7G,“Борьба” с кодировкой,,Сергей Саранцев
1606315310.195100,1606315422.195200,U01B4EXCR7G,"Загружаю файл csv и пытаюсь преобразовать числовые значения в числа. Но спецсимвол “\xa0”, который по сути означает разделение тысяч не дает это сделать. Как применить правильную кодировку при открытии csv? <https://pastebin.com/RDGUH9Bf>",,Сергей Саранцев
1604904117.042400,1606332293.198600,U01B84HU32R,"<@U01C12HG4QY> а что Вы пытаетесь сделать? Посмотреть, как продажи менялись? Тут удобнее взять и общий плот построить, где были бы все платформы на одном графике. Перед этим я смотрела, какой отрезок взять, чтобы не слишком криво было. Плюс ещё тепловая карта очень хорошо показывает касательно количество продаж. Но ее было мало для меня и уже после тепловых карт я строила plot по всем платформам выбранного периода (чтобы там всякие платформы за 1990 не учитывались, там явно информация неактуальна).",,Виктория Онучина
1604904117.042400,1606333396.198800,U01C12HG4QY,"Спасибо, попробую тогда на общем вывести",,Маргарита К
1604904117.042400,1606375275.199000,U0185Q2MK19,"<@U01C12HG4QY>, предлагаю еще посмотреть, как это можно сделать при помощи plotly express, вот здесь обсуждали: <https://yandex-students.slack.com/archives/G01B461LV0E/p1605273538111100?thread_ts=1604904205.044200&amp;cid=G01B461LV0E>

Все будет на одном графике, еще и фильтровать можно будет.",,Олег Булыгин
1606315310.195100,1606376631.199300,U0185Q2MK19,"Привет!

Подскажи, к какому спринту и к какому шагу относится вопрос?

Вообще кодировку можно указать прямо при чтении файла: параметр encoding у функции read_csv: <https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html>",,Олег Булыгин
1606315310.195100,1606388375.199900,U01B4EXCR7G,"<@U0185Q2MK19> Это вопрос не и спринта, а из личной практики использования Python.  Пробывал использовать encoding - не удалось исправить ошибку. Слышал мнение, что нужно откатиться на 2 версию python,  но хочется узнать есть ли решение поэлегантнее",,Сергей Саранцев
1606315310.195100,1606389869.200100,U0185Q2MK19,"Можно попробовать использовать модуль для автоматического распознавания кодировки: <https://chardet.readthedocs.io/en/latest/_modules/chardet/universaldetector.html>

На вторую версия откатываться точно не стоит. Но тут надо сам файлик иметь и в нем поразбираться, чтобы найти решение и причину ошибку.

Вопросы, не связанные с проектами, лучше задавать в teamwork :slightly_smiling_face:",,Олег Булыгин
1606315310.195100,1606395023.200300,U01B4EXCR7G,Спасибо за помощь!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Саранцев
1606499900.212400,1606499900.212400,U01BB72P2HG,Вопрос по таблицам для проекта,,Мария Пименова
1606499900.212400,1606499906.212500,U01BB72P2HG,"Где можно скачать таблички из проекта?):slightly_smiling_face: Я бы хотела проект полностью оформить в Jupyter, чтобы в проекте был и парсер и SQL-запросы :blob_0w0: И заодно потренироваться работать с SQL импортированным в тетрадку:smile::dizzy: Уже получилось импортировать и работает:black_heart: Только табличек не хватает))) :raised_hands::skin-tone-2:",,Мария Пименова
1606499900.212400,1606732305.213100,U0185Q2MK19,"<@U01BB72P2HG>, не забывай, пожалуйста, тегать меня при вопросах, а то я их могу не увидеть)

Таблицы к проектам практикум не выкладывает, т.к. это все немного out of the scope проекта. Это ведь не просто табличные структуры, а база данных. Если выкладывать ее дамп, вам будет необходимо развернуть у себя локально сервер с ней, что может быть весьма непросто для неподготовленных и не входит в изучаемые темы.

Аналитики данных обычно получают к ним доступ через дата-инженеров или администраторов БД.","[{'name': 'heavy_check_mark', 'users': ['U01BB72P2HG'], 'count': 1}]",Олег Булыгин
1606499900.212400,1606732571.213300,U01BB72P2HG,<@U0185Q2MK19> благодарю за познавательный ответ:slightly_smiling_face::pray:,,Мария Пименова
1608290243.301100,1608290243.301100,U01BPRKQP9P,Визуализация когортного анализа.,,Никита Коптелов
1608290243.301100,1608290687.301200,U01BPRKQP9P,"<@U0185Q2MK19>, <@U013KK77R2S> Добрый день! Столкнулся с проблемой визуализации heatmap. Даты на оси y отображаются некорректно. Делал всё согласно алгоритму из тренажёра. Приложу скриншоты, чтобы отобразить ход выполнения работы и её конечный результат. Подскажите, пожалуйста, что не так и как это можно исправить? (извиняюсь, если этот вопрос уже был)",,Никита Коптелов
1608290243.301100,1608291898.301700,U013KK77R2S,"<@U01BPRKQP9P>, привет! Попробуй вот такие шаги:
1. Сохрани `sns.heatmap` в какую-то переменную (допустим, `retention_heatmap`)
2. Потом к этой переменной примени вот это: `retention_heatmap.set_yticklabels(retention_heatmap.get_yticklabels(), rotation = 0)`
Также порекомендую использовать в `sns.heatmap` аргумент `vmax = 0.1` — это позволит визуализировать разницу в небольших процентах возвращаемости","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01BPRKQP9P'], 'count': 2}]",Владимир Лученко
1608290243.301100,1608298506.307300,U01BPRKQP9P,"<@U013KK77R2S>,  Спасибо большое за ответ! `vmax = 0.1` пригодился. Что касается остального.. Когда начал пытаться реализовать, предложенный тобой способ решения, понял, что не совсем понимаю, как это правильно сделать. В итоге получилось на stackoverflow найти, как мне кажется, более доступное решение. Строки кода, которые необходимо прописать выделил на скриншоте. Ссылку на пост со stackoverflow оставлю на всякий случай для тех, кто столкнётся с такими же трудностями. <https://stackoverflow.com/questions/27037241/changing-the-rotation-of-tick-labels-in-seaborn-heatmap|Ссылка на статью stackoverflow>.","[{'name': '+1', 'users': ['U013KK77R2S'], 'count': 1}, {'name': 'raised_hands', 'users': ['U01C12JD9TJ'], 'count': 1}]",Никита Коптелов
1608378619.314700,1608378619.314700,U01BBD8JS75,"Анализ бизнес-показателей. Проект.
*Шаг 2. Постройте отчёты и посчитайте метрики*
• Маркетинг",,Алексей Глазов
1608378619.314700,1608379046.314900,U01BBD8JS75,"<@U0185Q2MK19> помоги пожалуйста, хочу посчитать сколько нам стоило привлечь покупателей из каждого источника:
1. я сделал группировку в таблице visits по пользователям и из какого источника они пришли:
`first_source = visits.groupby('user_id').agg({'source_id': 'first'})`
`first_source.reset_index()`
2. теперь я хочу из получившейся группировки вытащить сколько уников принес каждый источник:
`uniq_user_per_source = first_source.groupby('source_id').agg({'user_id': 'nunique'})`
И тут сразу две ошибки появляется:
ругается на метод `agg({'user_id': 'nunique'})`, хотя когда он был применен строчку назад все прошло нормально, и ошибка, что судя по всему не видит столбец 'user_id'",,Алексей Глазов
1608378619.314700,1608380819.316100,U01BBD8JS75,<@U013KK77R2S> не подскажешь в чем проблема здесь :point_up_2:?,,Алексей Глазов
1608378619.314700,1608381571.316800,U013KK77R2S,"<@U01BBD8JS75>, скорее всего, ты не присвоил `.reset_index()` в `first_source`  — добавь его сразу после `.agg({'source_id': 'first'})` . Можно даже сразу в одну строку:
```uniq_user_per_source = visits.groupby('uid').agg({'source_id': 'first'}).reset_index().groupby('source_id').agg({'uid': 'nunique'}).reset_index()```
Также обращу внимание на сортировку — насколько мне известно, `first` просто выдает первое значение в строке, а если нет возрастающей сортировки по дате, то оно может не быть хронологически первым. Поэтому стоит перед `groupby` сделать `sort_values(by='start_ts')` :
```uniq_user_per_source = (visits.sort_values(by='start_ts')
                        .groupby('uid').agg({'source_id': 'first'}).reset_index()
                        .groupby('source_id').agg({'uid': 'nunique'}).reset_index())```",,Владимир Лученко
1608378619.314700,1608383773.318400,U01BBD8JS75,"<@U013KK77R2S> ух, какой код)) спасибо, такой способ сработал)",,Алексей Глазов
1608378619.314700,1608385941.318600,U0185Q2MK19,"<@U01BBD8JS75>, ну и на счет первого скриншота - это не ошибка, это предупреждение, которое говорит о том, переименование столбцов через словарь в следующих версиях pandas будет невозможно. Нужно будет переименовывать через кортежи, как показано в тексте самого предупреждения.",,Олег Булыгин
1608378619.314700,1608386089.318800,U01BBD8JS75,"<@U0185Q2MK19> просто: 1) почему в первый раз этого предупреждения не было? 2) а при чем тут переименование столбцов, я же хотел посчитать кол-во?",,Алексей Глазов
1608378619.314700,1608387018.319000,U0185Q2MK19,"<@U01BBD8JS75>,в функции agg ты указываешь словарь, в которым значением является агрегирующая функция (в твоем случае nunique), а ключом - как будет называться столбец с этим подсчетом (это по-сути и есть переименование, потому что по умолчанию его название будет совпадать с функцией агрегации). Такой синтаксис скоро будет недоступен.
Вот здесь можно найти подробное обсуждение: <https://stackoverflow.com/questions/44635626/rename-result-columns-from-pandas-aggregation-futurewarning-using-a-dict-with>

Если в прошлый раз абсолютно на аналогичном коде не было этого предупреждения, это странно)","[{'name': '+1', 'users': ['U01BBD8JS75'], 'count': 1}]",Олег Булыгин
1608378619.314700,1608401804.320900,U01BBD8JS75,"<@U013KK77R2S> скажи пожалуйста, а когда CAC по когортам считаем, то же нужно cumsum применять?",,Алексей Глазов
1608378619.314700,1608402189.321300,U013KK77R2S,"<@U01BBD8JS75>, нет, у нас же относительно каждого пользователя не копятся затраты на него — считается, что мы один раз привлекли пользователя, а для повторных покупок он приходит сам.

Если смотреть за пределы этого проекта, то есть продукты или ситуации, для которых имеет смысл отслеживать повторное привлечение — решение об этом принимает продуктовая команда, я не знаю о каких-либо универсальных принципах по поводу этого вопроса :slightly_smiling_face:","[{'name': 'raised_hands', 'users': ['U01BBD8JS75'], 'count': 1}]",Владимир Лученко
1608472259.338700,1608472259.338700,U01BB74CMMG,"Анализ бизнес-показателей. Проект.
*Шаг 2. Постройте отчёты и посчитайте метрики*
• Продажи",,Антон Дмитриев
1608472259.338700,1608472474.338800,U01BB74CMMG,"<@U0185Q2MK19> *Средний чек.*
В тренажере нас учили, что средний чек считается так: сумма покупок, делённая на число покупателей.

Число покупателей определяется по итогам группировки с использованием метода nunique (код также из тренажера) `orders_grouped_by_cohorts = orders.groupby(['first_order_month','order_month']).agg({'revenue':'sum','customer_id':'nunique'})`

НО, исходя из практики средний чек считается обычно не по уникальным пользователям, а как выручка, деленная на количество чеков (или количество неукникальных покупателей)

Если брать уникальных покупателей, то покупатель, сделавший покупки несколько раз за период, увеличивает объективный показатель стоимости среднего чека. Что может дезинформировать заказчика анализа

*Например, задача:*
• Объем выручки = 100 руб.
• Число чеков = 3
• Число уникальный покупателей = 2
*Решаем*:
• По варианту из тренажера мы имеем средний чек 100 / 2 = 50.
• По варианту, который я написал, средний чек 100 / 3 = 33
Последний вариант считаю более объективным для текущего проекта, т.к. цель - отследить его изменение с целью благоприятно повлиять на операционную прибыль, увеличив стоимость чека, а не стоимость всех товаров, купленных пользователем за период. Это разные цели. Повышая стоимость чека мы уменьшаем накладные расходы на каждого пользователя. А повышая стоимость всех покупок за период - мы только повышаем их сумму, не зная о количестве накладных расходов (т.к. эта сумма может быть достигнута и 100 заказами одним пользователем за период), - а это уже совсем по-другому считается...

Так вот вопрос, какая форма расчета более справедлива для проекта ?",,Антон Дмитриев
1608472259.338700,1608475002.340500,U0185Q2MK19,"<@U01BB74CMMG>, привет!
В целом твои размышления полностью верные. Оба способа подсчета в зависимости от целей исследования имеют место быть. И да, конкретно в этом проекте я бы ожидал средний чек на одну транзакцию (то есть не nunique, а просто count).",,Олег Булыгин
1608472259.338700,1608475108.340700,U01BB74CMMG,"Спасибо! А то у меня начинался когнитивный диссонанс, и нужен бы чей-то апруф моих умозаключений...",,Антон Дмитриев
1608490921.341700,1608490921.341700,U01963FA11V,"Анализ бизнес-показателей. Проект.
*Шаг 2. Постройте отчёты и посчитайте метрики*
• Продукт",,Елена Беспалова
1608490921.341700,1608491149.341800,U01963FA11V,"<@U0185Q2MK19> Олег посмотри пжл где в коде ошибка. В итоговой появляются Nane, не могу найти  <https://pastebin.com/JkKvpWKt>",,Елена Беспалова
1608378619.314700,1608499775.342000,U01BB74CMMG,"<@U0185Q2MK19> Опять вопрос из теории тренажера.
Там мы считали возврат инвестиций с использованием .cumsum()

То есть ROMI с каждым периодом увеличивался нарастающим итогом, а когда достигал 1 или больше - мы говорили об окупаемости в данный период.

Исходя из моей практики этот подход применим, в случае, если мы в начале первого периода инвестировали 1 раз, а затем отслеживали окупаемость данной инвестиции и считали нарастающим итогом - здесь теория тренажера работает.

НО в теории и в проекте - у нас инвестиции (затраты на маркетинг) ежемесячные, поэтому считать их окупаемость нарастающим итогом, как в тренажере - неверно. А нужно считать ROMI за каждый месяц и говорить об окупаемости затрат именно помесячно, а не с нарастающим итогом.

И как на экзамене ))) *Верно ли мое утверждение?* Нужен апрув умозаключению для движения дальше )))",,Антон Дмитриев
1608490921.341700,1608527325.342500,U0185Q2MK19,"<@U01963FA11V>, привет!
А почему ты работаешь с visits?. Когорты ведь определяются по месяцу первой покупки.
Тут надо все с orders делать.
Попробуй, пожалуйста, вот такой алгоритм, отпишись о результатах)

```# выделим месяц из даты 
orders['order_month'] = orders['Buy Ts'].astype('datetime64[M]')

# получим месяц первой покупки для каждого клиента
first_orders = orders.groupby('Uid').agg({'order_month': 'min'}).reset_index()
first_orders.columns = ['Uid', 'first_order_month']

# найдем количество новых покупателей ежемесячно
cohort_sizes = first_orders.groupby('first_order_month').agg({'Uid': 'nunique'}).reset_index()
first_order_month = pd.merge(orders, first_orders, on='Uid')
cohorts = first_order_month.groupby(['first_order_month', 'order_month']).agg({'Revenue': 'sum'}).reset_index()

report = pd.merge(cohort_sizes, cohorts, on='first_order_month')

report['age'] = (report['order_month'] - report['first_order_month']) / np.timedelta64(1, 'M')
report['age'] = report['age'].round().astype('int')
report['ltv'] = report['Revenue'] / report['Uid']

result = report.pivot_table(
        index='first_order_month', 
        columns='age', 
        values='ltv', 
        aggfunc='mean')
result.cumsum(axis=1).round(2)```
",,Олег Булыгин
1608378619.314700,1608527625.342700,U0185Q2MK19,"<@U01BB74CMMG>, скорее не соглашусь.
Мы исходим из посылки, что мы единожды затрачиваемся на привлечение конкретного пользователя. Пользователь совершает покупки в сервисе на протяжении его lifetime. Пользователь окупится (или не окупится) через несколько периодов исходя из его накопленной суммы затрат. Всех пользователей объединяем в когорты  и смотрим агрегированные показатели LTV, ROMI и пр.

Затраты на маркетинг у нас ежемесячные, но привлекаем то мы новых пользователей. Они могут вообще сразу ничего не заплатить, а заплатить потом. Ты предлагаешь учитывать затраты на маркетинг новых пользователей и доход от старых, это некорректно.",,Олег Булыгин
1608378619.314700,1608528816.343000,U01BB74CMMG,"<@U0185Q2MK19> Опять же из теста тренажера. Пользователь сервиса тот, кто совершил заказ, поэтому, все кто учтен в расчете уже заплатили. Если считать по посетитнлям, - тогда конечно с нарастающим итогом",,Антон Дмитриев
1608378619.314700,1608529275.343300,U0185Q2MK19,"<@U01BB74CMMG>, считаем по тем, кто совершил первый заказ, все верно. Но это не значит, что пользователь не совершит заказы в следующих периодах, что увеличит его  LTV и ROMI и это можно учесть только нарастающим итогом (привлекли то конкретно его один раз).",,Олег Булыгин
1608490921.341700,1608529881.346000,U01963FA11V,<@U0185Q2MK19> спасибо) попробую по этому варианту. Ревью сказал делать по visit и не джойнить :face_with_rolling_eyes:,,Елена Беспалова
1608378619.314700,1608530939.346200,U01BB74CMMG,"<@U0185Q2MK19>
У меня другая стратегия была в голове - Я считал, что мы привлекаем не Пользователя, а заказ )))
Если пользователя - тогда понятно, все встало на свои места.
Выходит, что если вопрос только о дате выхода на окупаемость, а мы вышли на окупаемость в первый же месяц, то остальные можно не учитывать ...

Если считать возврат инвестиций, затраченных не для привлечения пользователей, а для повышения количества заказов (без учета уникальности), тогда без нарастающего итога...

Вроде как разобрался, спасибо!",,Антон Дмитриев
1608490921.341700,1608531308.346400,U0185Q2MK19,"<@U01963FA11V>, если ревьюер настаивает на таком варианте, то сделай по посещениям) Можно посчитать и по первым визитам и по заказам, на самом деле конкретный подход сильно зависит от рекламного подхода к привлечению

Тогда тебе нужно исправить ошибку в твоем коде вот в этой строке:
```visit['lifetime'] = visit['lifetime'].astype('int') ```
на
```visit['lifetime'] = visit['lifetime'].round().astype('int') ```",,Олег Булыгин
1608378619.314700,1608531447.346600,U0185Q2MK19,"<@U01BB74CMMG>, ну да, согласен, что в целом это может варьироваться от способов монетизации конкретного сервиса)
:+1:",,Олег Булыгин
1608490921.341700,1608532047.347600,U01963FA11V,<@U0185Q2MK19> Спасибо :slightly_smiling_face: получилось),"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Елена Беспалова
1608472259.338700,1608569074.354800,U01B84D31FF,"<@U0185Q2MK19> Привет! Делаю ответ на задачу: Продажи - Какой средний чек
<https://pastebin.com/6Fw1WL3g>
При выполнении кода выдает вот такое окно (Во вложении) что я делаю не так?)",,Кирилл Солодков
1608378619.314700,1608577484.355100,U01BBD8JS75,"<@U0185Q2MK19> подскажи пожалуйста, ревьюер сказал, что лучше для анализа брать когорты, которые уже какое-то время живут, например не менее 6 месяцев. Как можно отсечь когорты, которые не дотягивают до нужной продолжительности?",,Алексей Глазов
1608472259.338700,1608611997.355300,U0185Q2MK19,"<@U01B84D31FF>, привет!
А зачем ты оперируешь когортами в вопросе среднего чека?
Средний чек считается по всем данным (его еще важно посмотреть в динамике).
Примерно так:

```orders['Buy Ts'] = orders['Buy Ts'].dt.strftime('%Y-%m')
average_revenue = orders.groupby('Buy Ts').agg({'Uid':'count','Revenue':'sum'})
average_revenue.columns = ['n_orders','total_revenue']
average_revenue['average_revenue'] = average_revenue['total_revenue'] / average_revenue['n_orders']
print(average_revenue['average_revenue'].mean())
average_revenue['average_revenue'].plot(kind='line')```
",,Олег Булыгин
1608378619.314700,1608612865.355500,U0185Q2MK19,"<@U01BBD8JS75>, тут можно вернутся к этапу в начале, когда ты строишь retention по когортам. Там ты высчитываешь сами когорты, на основе которых строишь сводную таблицу с когортами и их возрастом на осях.
И именно на этом этапе у тебя есть все данные о каждой когорте и ее возрасте. Можно просто отсечь те, которые порекомендовал ревьюер (у которых есть возраст &gt;= 6)",,Олег Булыгин
1608378619.314700,1608615292.355700,U01BBD8JS75,"<@U0185Q2MK19> а на практике в реальных задачах приходится отсекать маленькие когорты? Ведь так же можно не увидеть динамику в зарождении когорт: что когорты стали малочисленнее, что уже с самых первых месяцев они мало покупают. И вообще, много ли когорт берут для анализа)",,Алексей Глазов
1608378619.314700,1608621633.355900,U01BHCPLXHS,"<@U0185Q2MK19>, <@U013KK77R2S>, добрейшего вам утра! Помогите разобраться с ltv, cac, romi. Понимаю, что уже наверняка не раз отвечали, но супер трудно искать :face_with_rolling_eyes: Я не понимаю сам алгоритм подсчета. Поправьте, где я думаю не так. 1. Считаем ltv, получаем сводную с накопительной суммой ltv по когортам и lifetime. Далее нам нужно как-то его по источникам посчитать, как? 2. САС посчитать по источникам получилось.  3. ROMI считаем просто поделив одно на другое по источникам и сформировав сводную с накопленным итогом?",,Вероника Гром
1608378619.314700,1608625589.356700,U01BBD8JS75,"<@U0185Q2MK19> <@U013KK77R2S> добавил для себя отдельно среднее значение по когорте и по лайфтайм, а можно как-то отсоединить их от основного массива когорты, чтобы при визуализации они стояли рядом?",,Алексей Глазов
1608378619.314700,1608626339.357000,U01BBD8JS75,"<@U0185Q2MK19> отсечь когорты предложили только в двух конкретных таблицах: LTV и ROMI. Я в целом мало понимаю, что от меня хотят:
&gt; Лучше выбрать условное ""время жизни"" когорты, и считать результативность исходя из него - например, 6 месяцев - чтобы не слишком много когорт отсечь, потому что они прожили меньше этого времени. И главное смотреть, чтобы когорты прожили это время)
То есть нужно выбрать только те когорты, которые уже существуют 6 месяцев... и смотреть сколько они принесли ровно за 6 месяцев каждая?Но мы же тогда теряем часть данных, а вдруг на 7 месяце жизни произошел скачек и когорта потратила несколько сотен тысяч денежных единиц?..",,Алексей Глазов
1608378619.314700,1608626708.357300,U013KK77R2S,"<@U01BHCPLXHS>, привет!

Да, LTV считаем так. Процесс подсчета у нас делится как бы на 2 части:
• формировании таблицы с когортами, где мы используем `groupby`, 
• сводная таблица с `cumsum`, от которой потом можно взять среднее по `lifetime`. 
Чтобы сделать дополнительный срез по источникам, нужно при формировании таблицы с когортами — не сводная, а когда еще используются `groupby` — добавлять группировку по нужному столбцу, в данном случае `source_id`.

А для второго этапа я проходился циклом по числу источников, каждый раз делая этап со сводной таблицей отдельно для каждого источника и брал среднее по lifetime — результаты собирал в отдельный датафрейм. В итоге у меня получалась таблица, где строки — lifetime, столбцы — источники, а значения — средний накопленный LTV. Возможно, есть более оптимальный вариант, не знаю :slightly_smiling_face:

Для ROMI да, делим LTV на CAC, но по источникам тоже лучше брать средний накопленный ROMI и визуализировать на линейном графике.

Напиши, если нужна будет помощь с кодом.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Лученко
1608378619.314700,1608627040.357500,U013KK77R2S,"<@U01BBD8JS75>, для разделения на тепловой карте: если видишь, heatmap повторяет структуру таблицы, из которой он построен; пустые ячейки — это NaN. Поэтому можно в саму таблицу добавить строку и столбец с NaN, чтобы они стали пустыми ячейками на карте. Дополнительно можно убрать сетку вокруг ячеек, для этого можно прописать `linewidths=0`  или вообще не добавлять этот аргумент",,Владимир Лученко
1608378619.314700,1608627242.357700,U01BBD8JS75,"<@U013KK77R2S> хитро) подскажи пожалуйста, как сделать так, чтобы когда считалось среднее по когорте в расчет не брался первый столбец?",,Алексей Глазов
1608378619.314700,1608627556.358100,U013KK77R2S,"<@U01BBD8JS75>, не знаю, как это сделать «автоматически». Если это тоже нужно для визуализации, можно вручную заменить эту ячейку на NaN, добраться до нее можно через `.iloc[-1, -1]`  или `.loc['Average', 0]`",,Владимир Лученко
1608378619.314700,1608627834.358500,U013KK77R2S,"<@U01BBD8JS75>, для отсечения когорт с временем жизни меньше 6 месяцев попробуй вот такой срез: `ltv_pivot[ltv_pivot[6].notna()]`","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Лученко
1608378619.314700,1608628245.358700,U01BBD8JS75,"<@U013KK77R2S> спасибо, помогло. Но я все равно не понимаю для чего это делается... Следуя логике ревьюера сравнивать 1ю и 6ю когорты тоже не верно, так как 1я живет уже 12 месяцев, а 6 - 6 месяцев...",,Алексей Глазов
1608378619.314700,1608628499.359200,U01BBD8JS75,"а вдруг наши маркетологи совершили какую-то революцию, и отсеченная когорта уже за первые 2 месяца принесла больше, чем 4я) а мы этого теперь не увидим",,Алексей Глазов
1608378619.314700,1608631109.359700,U0185Q2MK19,"<@U01BBD8JS75>, все зависит от того, какие мы вопросы задаем. Если мы хотим проанализировать весь жизненный цикл когорты, то можно смотреть те, которые уже живут долго (и, например, пересекли черту окупаемости).
На счет твоего тезиса приведу простой пример:
1. мы запустили на сервисе какую-то акцию по привлечению, которая будет резко бустит продажи в краткосрочной перспективе. Получим клиентов, быстро окупимся по рекламе и пр. 
2. Казалось бы хорошо, но это приведет к тому, что  спрос уменьшится в отложенной перспективе. Все, кто хотел что-то купить/заплатить сделают это просто раньше. Будет стандартный эффект - после резкого роста числа продаж потом будет яма (по сравнению с базовым уровнем) - люди отдали все деньги, активировались и им надо ""отдохнуть"".
3. Что для нас это значит? Да, какая-то когорта может показать сразу хороший результат, как в твоем примере. Но не учитывая дальнейшие периоды этот анализ будет плохим, т.к. мы не рассматриваем возможный дальнейший спад показателей. Объективно можно оценить только когда жизненные циклы примерно равны и уже прошло какое-то время
Но при этом я ранее не встречал, чтобы в этом проекте просили так сделать :)",,Олег Булыгин
1608378619.314700,1608631319.360300,U01BBD8JS75,"<@U0185Q2MK19> тогда нужно не только отсеять когорты, которые не прожили условный срок, но и отбросить значения, которые превышают этот срок?",,Алексей Глазов
1608378619.314700,1608633837.360500,U0185Q2MK19,"<@U01BBD8JS75>, превышают какой именно срок? Мы знаем lifetime клиентов?) Это вообще очень растяжимое понятие, т.к. мы можем только догадываться, когда пользователи в среднем прекратят пользоваться услугой/продуктом. Это всегда на уровне догадок и очень индивидуально в конкретных ситуациях. Поэтому делаем так, как поставлена задача)",,Олег Булыгин
1608378619.314700,1608634018.360700,U01BBD8JS75,"<@U0185Q2MK19> я не знаю) ревьюер не стал вдоваться в подробности... Я понимаю если бы мы были какой-то компанией, которая обещает клиентам окупить их вложения в течении 6 месяцев, тогда да наверное, делали бы срез по 6 месяцам жизни каждой когорты и оценивали бы ровно эти 6 месяцев...",,Алексей Глазов
1608378619.314700,1608634145.361000,U0185Q2MK19,"<@U01BBD8JS75>, в реальности бизнес может ждать окупаемости клиента месяц, а может год. Все зависит от продукта и бизнес-модели (и желаний конкретного бизнеса).
В мобильных играх вообще очень короткие периоды анализируют (часто - максимум месяц).
У нас учебный проект, нет требований бизнеса, поэтому делаем исходя из максимально общих предположений и требований ревьюера)",,Олег Булыгин
1608378619.314700,1608641482.361300,U01AALXG4SU,"<@U0185Q2MK19> <@U013KK77R2S> привет! Вчера в ночи доделав раздел маркетинга и вздохнув с облегчением, поняла, что рано вздохнула и весь проект придется повторить еще раз?? Я все верно поняла? я тут задам свои вопросы
1.DAU MAU WAU Строю афики по устройствам
2. дительность сессй по устройствам
3.средний чек по устройствам (когорты и тепловые карты)
4. LTV, CAC,(пересекающиеся линейные графики, средние по источникам), ROMI по источникам (тепловая карт или хватит значений).
p.s. этот проект меня вымотал уже, кошмар какой-то!!!:face_with_thermometer:",,Наталья Рожанкова
1608378619.314700,1608644301.361600,U0185Q2MK19,"<@U01AALXG4SU>, привет!
Давай опишу, что точно должно быть в рамках проекта:
&gt; Сколько людей пользуются в день, неделю, месяц?
DAU, WAU, MAU с разбивкой по источникам и устройствам.
&gt; Сколько сессий в день?
Среднее количество сессий в день на одного пользователя с разбивкой по месяцам. Разбивать по источникам и устройствам не обязательно (если не запросит ревьюер).
&gt; Сколько длится одна сессия?
Разбивать во времени и по другим параметрам не нужно. Просто распределение продолжительности
&gt; Как часто люди возвращаются?
Нужно посчитать удержание (треугольная таблица) без дополнительных разбивок.
&gt; Когда люди начинают покупать?
Нужно посчитать количество времени от начала первой сессии до первой покупки.
&gt; Сколько раз покупают за период?
Нужно посчитать количество покупок в месяц. Можно с разбивкой по устройствам и источникам (но ревьюер может и не запросить).
&gt; Какой средний чек?
Нужно посчитать средний чек с разбивкой во времени (динамику).
&gt; Сколько денег приносят? (LTV)
Собственно, LTV. С разбивкой по источникам будет достаточно.
То же самое для САС и ROI.

Ревьюер может попросить что-то сделать за этими рамками, но вроде все обязательные вещи я написал.

На мой взгляд, это действительно самый сложный проект из всех :slightly_smiling_face: Поэтому сделали, выдохнули, погордились вперед и изучаем все дальше)",,Олег Булыгин
1608378619.314700,1608644689.361900,U01AALXG4SU,<@U0185Q2MK19> Спасибо! Вроде немножко осталось:) но боюсь загадывать,"[{'name': 'cat-high-five', 'users': ['U0185Q2MK19'], 'count': 1}]",Наталья Рожанкова
1608378619.314700,1608646219.364600,U01BHCPLXHS,"<@U013KK77R2S>, Спасибо, теоретически поняла, но помоги, пожалуйста, с кодом, я уже всю голову сломала :exploding_head: в первую очередь с ltv, а там может включусь ",,Вероника Гром
1608378619.314700,1608649038.364800,U013KK77R2S,"<@U01BHCPLXHS>, вот что-то такое у меня было: <https://pastebin.com/cSwf7SAe>. Если будут ошибки, приложи скриншот, разберемся :slightly_smiling_face:",,Владимир Лученко
1608378619.314700,1608663119.365800,U01BHCPLXHS,"<@U013KK77R2S>, у нас в таблице orders нет столбца с Source Id, мы его до этого смёрджили с visits по пользователю?",,Вероника Гром
1608663140.366500,1608663140.366500,U01AWENRANB,Проект по кагортному анализу. Расчет окупаемости рекламного источника. ,,Ксения Ушакова
1608663140.366500,1608663395.370800,U01AWENRANB,"Привет, <@U0185Q2MK19>, объясни пожалуйста, как посчитать момент окупаемости рекламного источника. Построила таблицу источник - лайфтайм с суммой прибыли, но теперь понимаю, что затраты мне сюда никак не прикрутить. Не могу сам алгоритм понять",,Ксения Ушакова
1608378619.314700,1608664174.371600,U013KK77R2S,"<@U01BHCPLXHS> , да, только оттуда его можно получить",,Владимир Лученко
1608378619.314700,1608664319.371800,U01BHCPLXHS,"<@U013KK77R2S>, спасибо тебе, добрый человек, уже разобралась :pray::blush: какой-то ступор случился с этим ltv :woman-shrugging:","[{'name': 'cat-high-five', 'users': ['U013KK77R2S'], 'count': 1}]",Вероника Гром
1608663140.366500,1608698552.372100,U0185Q2MK19,"<@U01AWENRANB>, привет!

Окупаемость надо смотреть по ROMI, как только он превысит 1, значит это и есть искомая точка)

Вот здесь я приводил достаточно подробный пример расчета как раз по рекламным источникам: <https://yandex-students.slack.com/archives/G01B461LV0E/p1608466757337200?thread_ts=1607324407.225000&amp;cid=G01B461LV0E>
Это как раз то, что тебе нужно :)",,Олег Булыгин
1608663140.366500,1608738878.373100,U01AWENRANB,Спасибо! Все удалось )),"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Ксения Ушакова
1608663140.366500,1608744643.373300,U01B84D31FF,"<@U0185Q2MK19> Привет! У меня такая же проблема, ревьюер попросил сделать расчет окупаемость расходов по источникам, пытаюсь воспользоваться твоим примером Но вылетает ошибка вот на этом шаге <https://pastebin.com/RKZ1HtUd> (во вложении)
Что я делаю не так?",,Кирилл Солодков
1608663140.366500,1608745314.373700,U0185Q2MK19,"<@U01B84D31FF>, у тебя столбцы buy_ts и first_buy судя по всему не являются datetime объектами (а являются просто текстом). Выведи отдельно их содержимое и убедись, что там корректные временные метки.",,Олег Булыгин
1608781086.374500,1608781086.374500,U01BBD8EYR1,"Анализ бизнес-показателей. Проект.
*Шаг 2. Постройте отчёты и посчитайте метрики*
• Продукт - Возвращаемость (Retention)",,Евгения Батухтина
1608781086.374500,1608781325.374700,U01BBD8EYR1,"<@U0185Q2MK19> Ревьюер написал такой комментарий к моим расчетам. Я не очень поняла, что означает сделать _""средний расчет по одному из когорт `lifetime`"":_
```В целом логика расчета верна.
    
В том числе рекомендую делать средний расчет по одному из когорт `lifetime`, например по 2–му месяцу. Почему по 2–му? 
    
Это одна из важнейших метрик, потому что с помощью неё мы можем далее прогнозировать наши потоки доходов и в целом понимать, насколько пользователи у нас могут задерживаться, ведь действующим клиентам продать проще, чем новым.  ```
Олег, можешь пояснить, пожалуйста.",,Евгения Батухтина
1608781086.374500,1608784752.374900,U0185Q2MK19,"<@U01BBD8EYR1>, привет!
Я правильно понимаю, что этот комментарий относится к расчету retention?
Логика состоит в том, что многие пользователи могут пользоваться сервисом только 1 раз и сразу отвалиться.
Если пользователи возвращаются в наш сервис, вероятно, они с нами останутся надолго. Т.е. можно сравнить средний retention первого месяца жизни когорты со вторым. Второй может быть более показателен, особенно если он далее падает заметно меньше, чем с первого на второй.",,Олег Булыгин
1608781086.374500,1608786825.375100,U01BBD8EYR1,"<@U0185Q2MK19> да, комментарий был про возвращаемость, я почему-то попутала с LTV.
Поняла про сравнение месяцев. Спасибо.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгения Батухтина
1608928207.384200,1608928207.384200,U01B84HU32R,"Анализ бизнес-показателей. Проект.
*Шаг 2. Постройте отчёты и посчитайте метрики*
Вопрос касательно графиков",,Виктория Онучина
1608928207.384200,1608928618.384300,U01B84HU32R,"<@U0185Q2MK19> или <@U013KK77R2S> подскажите. Я делаю график <http://joxi.ru/L21klZYF0axVWr> по ежедневным пользователям. код графика:
`dv = daily_visits.plot(figsize=(13,8), color = 'darkgreen', linewidth = 2, grid=True);`
`dv.set_title('Visits per day', fontsize=13);`
`dv.set_xlabel('Days', fontsize=13);`
`dv.set_ylabel('Visits', fontsize=13);`
Потом делаю другой график по количеству сессий в день <http://joxi.ru/BA0xOKDHpZXw8A>, код графика:
`ss = sum_sessions.plot(figsize=(13,8), color = 'darkgreen', linewidth = 2, grid=True);`
`ss.set_title('Visits in day', fontsize=13);`
`ss.set_xlabel('Days', fontsize=13);`
`ss.set_ylabel('Visits', fontsize=13);`

Мне бы хотелось объединить этот график и сделать вывод по количества сессий и количеству ежедневных пользователей (пусть это и не просят, но мне интересно). Я пыталась добавлять во второй график код `dv=dv` , но он пишет, что dv не видит. Но если я переименую график количества сессий в день в ax и буду использовать `ax=a`  в plot по количеству пользователей в день, то он видит <http://joxi.ru/n2YwBq4ueyBVxr>

И как бы ладно, Вика, назови просто ax, но мне интересно как сделать можно без переименования в ax. Ибо в этих ax потом можно запутаться, если таких графиков нужно много.

Я была бы рада советам или ссылкам (ссылкам больше буду рада).",,Виктория Онучина
1608928207.384200,1608936209.384600,U01B84HU32R,"<@U0185Q2MK19> и <@U013KK77R2S> еще вопрос такой, в pandas с помощью plotly можно же делать графики, где при наведении на, к примеру, точки, высвечивалось бы значение? Я знаю, что в будущем будет plotly express, он выполняет эти действия? Или лучше просто изучать глубже matplotlib?",,Виктория Онучина
1608928207.384200,1608941313.384800,U0185Q2MK19,"<@U01B84HU32R>, привет!
Ссылка по первому вопросу про обсуждение этого параметра: <https://stackoverflow.com/questions/64545066/make-sense-of-parameter-ax-in-pandas-series-plot|https://stackoverflow.com/questions/64545066/make-sense-of-parameter-ax-in-pandas-series-plot>
На самом деле переменную можно назвать хоть как, только параметр функции все равно будет ax :)

На счёт динамический визуализации - да, это умеет plotly и ряд других библиотек. В matplotlib такого функционала нет.",,Олег Булыгин
1608928207.384200,1608944460.385100,U01B84HU32R,"<@U0185Q2MK19> спасибо! Я почему-то думала всегда, что ax - это не функция, а просто пишем, что нам нужен этот графичек и нужен именно он в таком названии :porg:
Визуализацию буду учить, хочется уметь делать ее более функциональной и описательной, спасибо!",,Виктория Онучина
1608928207.384200,1609003775.387200,U01B84HU32R,"<@U0185Q2MK19> подскажи! Есть ли смысл перед тем, как анализировать продукт (это вот где сессии рассматриваем), сначала обрезать наш датафрейм визитов по логике ""если начало сессии позже конца сессии, то мы это не учитываем"", то есть end &gt; start. Или когда среднюю продолжительность смотреть буду, то это никак не отразится, ведь берем мы значение, встречающееся чаще всего? Вот когда число сессий в день рассматривала, то я делала логический срез end &gt; start, но вот встал такой вопрос ""а может лучше сделать сразу"".",,Виктория Онучина
1608928207.384200,1609013153.394400,U01B84HU32R,"<@U0185Q2MK19> еще вопрос с точки зрения логики проекта. Стоит ли рассматривать пункт ""продукт"" относительно рекламного источника? Я посчитала нужным рассмотреть относительно девайсов, но также думаю, что и относительно рекламного источника тоже будет полезно. Нам же нужно сделать выводы по девайсам и источникам.
Следовательно в пункте ""продажи"" я хотела бы также рассмотреть более подробно, а не только общую.

Если так углубляться не надо, мало ли, то я не понимаю, как мне сделать вывод какой рекламный источник лучше или какой девайс (платформу) рекомендовать.",,Виктория Онучина
1608928207.384200,1609020808.394600,U01B84HU32R,"<@U0185Q2MK19> и ещё вопрос, извини! Графики, которые я присылала выше, - это же matplotlib, а не plotly? Плохо разбираюсь пока что в них и в разнице, решила уточнить у тебя, чтобы не зависнуть в сети на несколько часов...",,Виктория Онучина
1608928207.384200,1609025857.394800,U01B84HU32R,"<@U0185Q2MK19> еще мега странный вопрос, но он меня озадачил. Сумма средних по платформам (desktop touch) не обязательно будет равна среднему по общей таблице? А то вышло, что сумма 645 в день, в общая 625 в день.",,Виктория Онучина
1608928207.384200,1609053662.395200,U0185Q2MK19,"<@U01B84HU32R>,
1. очень верное наблюдение. В целом такие записи вряд ли нам как-то значимо повлияют на анализ и не плохо было бы знать причины того, почему так произошло. Если мы понимаем, что это какая-то техническая проблема сбора, то ее можно попробовать исправить (например, даты местами для таких записей поменять). В нашем случае я бы их сразу удалил. Но если оставить, тоже ничего страшного не произойдет)
2. Вот здесь уже писал, что точно должно быть рассчитано: <https://yandex-students.slack.com/archives/G01B461LV0E/p1608644301361600?thread_ts=1608378619.314700&amp;cid=G01B461LV0E>
Разрез девайса тут нужен для DAU, WAU, MAU
3. Да, все предыдущие визуализации - matplotlib
4. Тут не совсем понял вопрос) Каких средних по платформам? Ты про DAU, MAU, WAU? Если да, то это норм, там ведь смотрятся уникальные пользователи. Какие-то пользователи могут пользоваться несколькими девайсами, а какие-то одним.",,Олег Булыгин
1608928207.384200,1609066184.395500,U01B84HU32R,"<@U0185Q2MK19> а подскажи тогда. DAU/WAU/MAU - это среднее, как было дано в теории. Я делала так: сначала нруппировала таблицу по датам (365 строк) и добавляла уникальные пользователи. То есть вид дата - пользователи. По ней делала график, смотрела просадки, пики. Потом рассчитывала DAU, сколько в среднем в день. Так сделала и для WAU MAU. Причем я так сделала и для девацсов и для рекламных источников (рекламные источники смотрела как ущик с усами, просто посмотрела какие источники приносят пользователей больше, сделала  пометки в выводе). Все верно? Или я перемудрила?",,Виктория Онучина
1608928207.384200,1609069878.395800,U0185Q2MK19,"<@U01B84HU32R>, динамику достаточно посмотреть без срезов по источникам/девайсам. А от средние MAU/DAU/WAU рассчитать надо в обоих разрезах (просто числами). Можно дополнить боксплотами, но я бы не сказал, что это обязательно. Все ок :slightly_smiling_face:",,Олег Булыгин
1608928207.384200,1609069954.396000,U01B84HU32R,"<@U0185Q2MK19> поняла, немного перемудрила, но ничего, стирать уже жалко ахах
А подскажи, почему мы смотрим количество сессий только в разбивке по месяцам?",,Виктория Онучина
1608928207.384200,1609070137.396200,U01B84HU32R,"<@U0185Q2MK19> и заодно еще вопрос... Я вот в боксплотах использовала plotly, потому что там ящики видно лучше. Но все графики после у меня теперь строятся в plotly, а не matplotlib, хотя до боксплотов я делала в matplotlib. Из-за чего такое происходит? Я код после боксплотов не меняли никак.",,Виктория Онучина
1608928207.384200,1609070274.396400,U0185Q2MK19,"<@U01B84HU32R>, можно без проблем посмотреть и в разрезе источников/девайсов. Отличия, конечно, будут, но по хорошему тогда еще надо доказать, являются ли они статистически значимыми. Можно вообще любой показатель смотреть в любом количестве срезов и работа будет бесконечной.

Нужно просто находить баланс между лаконичностью и достаточностью расчетов для конкретных выводов.",,Олег Булыгин
1608928207.384200,1609070362.396600,U0185Q2MK19,"<@U01B84HU32R> на счет второго вопроса - такого не может быть, т.к. у plotly принципиально другой синтаксис и для построения визуализаций нужен совсем другой код. Это две библиотеки, которые никак друг с другом не связаны, у них совершенно разный функционал.

Нельзя кодом для matplotlib построить интерактивную визуализацию, как в plotly",,Олег Булыгин
1608928207.384200,1609070667.396800,U01B84HU32R,"<@U0185Q2MK19> вот скриншоты. 1: <http://joxi.ru/YmEwY67uMqkLlA> это первые графики, как ты сказал, matplotlib. 2: <http://joxi.ru/E2paLN8fGxqjQA> график пониже, логика построения та же, но уже выглядит иначе..

Про лаконичность и достаточность - спасибо, буду думать в эту сторону!",,Виктория Онучина
1608928207.384200,1609070796.397100,U0185Q2MK19,"<@U01B84HU32R>, я думаю, ты путаешь plotly и seaborn.
Если ты использовала seaborn (который основан на matplotlib), то он меняет дефолтное отображение всех графиков на немного другой стиль (более аккуратный).",,Олег Булыгин
1608928207.384200,1609071113.397700,U01B84HU32R,"<@U0185Q2MK19> скорее всего.. Все, погуглила, поняла в чем прикол. Спасибо

Тогда последний вопрос (надеюсь до вечера, а то я тут назадавала уже). Уместно ли в проектах (рабочих, учебных, без разницы, интересна именно уместность) использовать выводы без графических и прочих подтверждений? К примеру я посмотрела длительность сессий в разбивке по платформам, увидела, что разницы нет (те же n секунд), написала в выводе, что так и так, в разбивке по платформам разницы нет, но при этом удалила свой код и вывод по нему. С точки зрения того, кто смотрит впервые, это голые факты, ведь я просто пишу текстом. Вот и встал вопрос: лучше уж ничего не писать или если писать, то подтверждать слова?",,Виктория Онучина
1608928207.384200,1609071312.397900,U0185Q2MK19,"<@U01B84HU32R>, в реальных проектах, конечно, обязательно нужно подтверждать выводы расчетами и визуализациями.

Просто писать факты без обоснования - это не очень серьезно и вряд ли уместно в профессиональных кейсах. Поэтому точно второй вариант","[{'name': 'cat-high-five', 'users': ['U01B84HU32R'], 'count': 1}]",Олег Булыгин
1608928207.384200,1610319475.412500,U01B84HU32R,"*Виктория Онучина*  [1:25 AM]
<@U0185Q2MK19> добро пожаловать на рабочую неделю,  я тут сразу с вопросами и их ого-го))
1. В нашей RR тепловой карте после 0-го месяца резко спады со 100% до 4-9 где-то. Ревьюер сказал, что либо vmin vmax настраивать, либо удалять 0-ю когорту, чтобы ""виднелось почетче"", а то там просто однотонное все (так как малые значения). И возник вопрос: когда важно оценить эти значения досконально, а когда - нет. Ведь если спад со 100% до 7-9 везде, то это уже маячок о чем-то, зачем его смотреть глубже, чтобы цвета 7 и 9 процентов отличались?
2. Видимо на этой стадии мозг у меня расплавился от проекта и не хочет собираться. Как рассмотреть относительные покупки? Ревьюер объяснил, но я не поняла. Цитирую его: *Тут можно было бы взять показатели по количеству покупок и разделить из на данные из таблиц dau_source, wau_source, wau_source. Таким образом ты получить количество покупок на один визит.*  Что делать плохо понимаю. 
3. Еще у меня возник момент, что в сводной таблице в первом столбце после fillna остаются нули. Скриншот: <http://joxi.ru/bmold87CyjZzJ2>. Ревьюер говорит, что нули ушли там, где были пропуски, а как убрать вообще эти нули отовсюду? Как-то тип данных поменять? 
4. Я очень запуталась как искать.. средний чек. Можешь как-то помочь. Я сделала средние чеки графиком, графики делала по сводным таблицам с индексом и начинкой, ну и аггрегацией. Вышли вот такие для графиков: <https://pastebin.com/pA82Kk3N>, а как потом найти ОДНО среднее число для месяца, дня, недели? Я сделала потом вот так: <https://pastebin.com/d0rQt7M4>, оно будет считаться как среднее? Или достаточно к сводной таблице применить mean? Ревьюер так и не ответил как, он лишь сказал ""стандартный способ и твой метод"", а я даже не знаю, что такое мой метод, потому что старалась действовать по теории. 
5. Самый уже замученный вопрос, я все каникулы читала треды и делала, но так и не поняла. Как смотреть LTV по источникам? Как смотрела я: <https://pastebin.com/KcAJFq1r>, там каша видимо. Цитирую ревьюера: *А можешь объяснить, как так получается, что LTV по источникам в первом месяце около 0.4-0.5, а если смотреть по когортам, то он там везде 4-5? Если подозрение, что тут ошибка.*
6. LTV по девайсам потом смотреть таким же способом, как по источникам? Зачем его вообще смотреть по девайсам? 
7. Дальше у нас идет CAC. Ревьюер ругает меня за среднее от среднего (<http://joxi.ru/1A581O6CbZdMn2>, без кода, там визуально просто оценить можно). Почему так нельзя? Я все еще не понимаю, почему нельзя смотреть среднее от среднего, ревьюер как-то не смогу объяснить. Может ты сможешь?
8. Здесь вот тоже по CAC и я тоже не поняла, что от меня требуют. Может ты как аналитик аналитика поймешь и объяснишь на просточеловечном.. <http://joxi.ru/l2ZwMgDu7aJoVA> и код <https://pastebin.com/duCemQK3> (вроде там весь, если не сработает, скажи). 
9. По ROMI я тоже не поняла, особенно. Вот мой код и я уверенна, что ROMI там НЕправильный: <https://pastebin.com/vRBtn5BU>, а вот замечание: *Давай еще раз упростим нашу задачу. У тебя есть таблица — monthly_costs_source, она точно правильная, можешь сделать такую же таблицу, только не по расходам, а по прибыли на источник? А потом разделить одно на другое. Нам же нужно считать их не месяцам, а также, как LTV. Источники окупаются постепенно.* 
*Спасибо большое за все ответы!* :pikapika:",,Виктория Онучина
1608928207.384200,1610344377.412700,U0185Q2MK19,"<@U01B84HU32R>, привет! С прошедшими праздниками!
Давай разбираться :slightly_smiling_face:

1. На самом деле это вполне нормальная ситуация. Спад в первом периоде обозначает, что большинство пользователей пользуются продуктом 1 раз, а потом не возвращаются к нему. Оставшаяся малая часть остается и пользуется продуктом постоянно, такой сценарий вполне может быть допустим бизнесом. А вот когда потом отваливаются лояльные пользователи - это отдельный и интересный вопрос. 
Если там данные отображены в процентах, то по идее можно просто задать `vmax=0.1` (а `vmin` здесь не обязателен). Но надо смотреть код. Проще правда просто откинуть первый столбец.
2. Не совсем понимаю о каком пункте проекта идет речь и к ответу на какой вопрос эти действия привязаны. Что такое ""относительные покупки""? Зачем это смотреть?
3. я правильно понимаю, что это сводная таблица по количеству покупок? просто по условию она не требуется, поэтому уточняю. Попробуй вот так: `purchase.apply(<http://pd.to|pd.to>_numeric, downcast='integer')`
Если не получится, то надо видеть весь код построения таблицы.
4. средние чеки по периодам у тебя рассчитаны верно. Чтобы посчитать итоговое средние можно просто применять `mean` к `revenue_per_user` в твоих расчетах по периодам.
5. уже оочень много раз обсуждали расчет LTV по источникам. Например, вот здесь представлен верный алгоритм: <https://yandex-students.slack.com/archives/G01B461LV0E/p1608466757337200?thread_ts=1607324407.225000&amp;cid=G01B461LV0E>
В твоем варианте я не вижу, где ты находишь первый источник для каждого пользователя
6. По устройствам, как правило, смотреть не надо, источников в проекте достаточно. Ревьюер теоретически может попросить посчитать и по девайсам, но это бывает не часто. Смотрится абсолютно так же, только группировка не по source, а по первому device
7. посчитать это можно, но я не вижу практической ценности такого расчета. Когортный анализ и нужен, чтобы разбивать пользователей на группы и считать метрики в зависимости от рекламных компаний/изменений в продукте и прочем.
Мы говорим - ок, наш средний CAC между когортами вот такой. И что? В разные временные периоды могли быть совершенно разные механизмы привлечения, затраты на них, что-то менялось в самом продукте. Мы просто не сможем сделать никаких бизнесовых выводов на основе данного показателя. И если уж на то пошло, то средний показателей надо рассчитывать по стоимости привлечения всех пользователей без агрегации. К примеру в 1 когорте к нам пришло 100 000 человек с очень разной ценой привлечения, средняя оказалась 10. А во второй когорте к нам пришел 1 человек с ценой привлечения 100. Согласно твоим расчетам средняя цена привлечения по двум когортам будет 55. О чем нам говорит это число? Ревьюер и показывает, что такой способ подсчета ничего нам не даст.
8. Тут так же отсылаю к моему комменту выше, где приведем полный алгоритм расчета LTV, CAC и ROMI по источникам по тому алгоритму, который указывает ревьюер.
9. аналогично.",,Олег Булыгин
1608928207.384200,1610371372.414400,U01B84HU32R,"<@U0185Q2MK19> спасибо за ответ.
1. Поняла
2. Тут речь идет о среднем количестве покупок по рекламным источникам (вот так я их смотрела: <https://pastebin.com/9P66QzWB>). Я сама не знаю что это и зачем, мне написал ревьюер. Я сказала, что не поняла, но его объяснение потом тоже не поняла и решила спросить у тебя. Общение с ревьюером: <http://joxi.ru/eAOwMnjuk71wKA>
3. Да, по количеству покупок. Попробовала, но вышел какой-то замкнутый круг. Если снова fillna("""") сделать, то будет опять нули в первом, остальное красиво. <http://joxi.ru/Vm6NznWtvXgDNm>
4. Смотри, я revenue_per_user сделала в сводную уже со средним значением. Прикол в том, что если я применяю к сводной со средним mean, то ревьюер ругается за  ""среднее от среднего"". Мне получается лучше сводную в отдельную переменную, а в той таблице к столбцу revenue_per_user применить mean? Как один числом получить средний чек за весь период? Общение с ревьюером: <http://joxi.ru/1A581O6CbZqGV2>. Я переделала ему под mean, но, как видишь, комментарий все еще красный. И он говорит о какой-то колоссальной разнице, но я как не крутила данные везде 4 выходит. 
5. Я переделала свой LTV, но все равно вопрос. Я бы могла скопировать твой код, но мне тогда весь проект переделывать, чтобы подстроить под него и убрать момента, где я уже что-то искала, не суть. Суть вот в чем. У меня отличия в значениях. Если по твоему (код: <https://pastebin.com/GK1ccWnn>, скриншот: <http://joxi.ru/krDv45yU43PXy2>, вот так, то по моему отличия имеются (код: <https://pastebin.com/mLZHU5jH> и скриншот: <http://joxi.ru/5mdDoaZi8KRQ4m>) где-то больше на 5 показателей, где-то меньше на 1 показатель. Знаю, что все это обсуждалось сто раз, но мне бы понять как вообще правильно должно быть. И если я просто скопирую твой и суну, то ничего не пойму и в будущем сама не справлюсь.. По CAC ROMI буду разбираться уже, если вопросы возникнут, то спрошу.
6. По устройствам поняла, спасибо",,Виктория Онучина
1608928207.384200,1610372546.414600,U01B84HU32R,"<@U0185Q2MK19> начала делать дальше и сразу же вопрос. Ревьюеру не понравились мои CAC по рекламным источникам. Он не понял логику (хотя так, вроде, все просто). Но я-то логику поняла и CAC вышли правильно (сравнила с твоим методом). Как быть? Скриншот моего: <http://joxi.ru/DmB94Mku4jVawr>, скриншот твоего: <http://joxi.ru/52awyLdukWVzWr>. Я просто реально не понимаю, там так все запутано у меня в 4 строки? Я сделала месячные затраты на рекламные источники, добавила в новую (new) переменную когорты рекламных источников и все.. Может убрать это new и сделать просто cohorts_source и так понятнее будет?",,Виктория Онучина
1608928207.384200,1610373647.414900,U01B84HU32R,"<@U0185Q2MK19> и последнее про ROMI. Я сравнила с полученными у тебя данными, пересмотрела свое решение, вроде делаю по теории. Но у меня снова (из-за LTV видимо) разные с тобой значения (хотя одни датафреймы). Ну и я все еще не понимаю, как мне корректно ответить ревьюеру, который советует делать другую таблицу для romi (<http://joxi.ru/l2ZwMgDu7abKxA>). <https://pastebin.com/zBmmmgaP> - здесь весь итоговый код по нахождению всего для рекламных источников. Если у тебя будет время запустить и проверить его (там две тепловые таблицы, ltv и romi), то я буду благодарна. Из таблицы я ничего не удаляла, кроме одной строчки с 7 рекламным источником (ревьюер за это не ругал). Остальное все осталось как есть.",,Виктория Онучина
1608928207.384200,1610376494.415400,U0185Q2MK19,"<@U01B84HU32R>
2) первый раз вижу, чтобы просили считать количество покупок в разрезе рекламных источников) У тебя получаются три таблицы (покупки по месяцам). Ты можешь сформировать абсолютно аналогичные таблицы, но не по покупкам, а по уникальным клиентам (агрегация по `nunique`  в visits). И разделив одну на вторую, как раз и получишь относительные показатели (отношение покупок к числу клиентов) в трех таблицах (по дням, неделям и месяцам).
3) это странновато, тогда мне нужен полный код формирование у тебя этой таблицы с нуля, чтобы найти на каком этапе возникает эта проблема
4) все верно, и я выше привел конкретный пример относительно CAC, когда будет сильная разница при подсчете средних по этим двум подходам (среднего просто по всем данным и среднего при какой-то агрегации). Да, как и ранее написал, нужно просто взять mean по столбцу с доходами.
5) первая же ошибка, которая в твоем варианте - ты отбираешь первые источники `agg({'source_id':'first'})` , не сделав предварительно сортировку. То есть ты говоришь ""возьми первый"", но данные не упорядочены, поэтому результат будет неверный. Потому у тебя какие-то странности с подсчетом размер когорт. Почему группируешь по 'first_buy_month' и 'buy_month' при определении размеров когорт? Мы же в разрезе источников все считаем. И почему при определении размера когорты там `.agg({'revenue': 'sum'})`, если размер когорты - это количество клиентов в ней? У тебя подход ведь почти такой же, как в том варианте, который предлагаю я, несколько таких неточностей полностью искажают результат.

Далее ты используешь эту таблицу (cohort_source), в которой есть эта лишняя группировка для вычисления CAC, и ревьюер тебе говорит, что более оптимально присоединять конкретно расчет по размерам когорт (в котором должна быть группировка именно по источнику с агрегацией `.agg({'uid': 'nunique'}))` , как я и писал выше. То есть это так же тянется из расчета LTV, который надо оптимизировать.
Все должно быть просто - вязли затраты по источникам, поделили на размеры когорт по источникам (для этого объединяем эти данные). У тебя вместо таблицы с размером когорт, что-то перегруженное.

На счет ROMI - вспоминаем, как он считается) Это ничто иное, как LTV поделенное на CAC, об этом и говорить ревьюер (что у тебя cac уже есть, осталось посчитать доходы за периоды накопительным итогом). И мы опять возвращаемся к расчету LTV по источникам, который нужно поправить. То есть просто берем эту таблицу: <http://joxi.ru/krDv45yU43PXy2> и делим ее на CAC, который у тебя верно рассчитан.  И если ты посмотришь на мой вариант решения, то там все ровно по тем шагам, на которые тебя наводить ревьюер)",,Олег Булыгин
1608928207.384200,1610391127.416400,U01B84HU32R,"<@U0185Q2MK19> спасибо))
Касательно покупок по рекламным источникам - это я сама себе усложнила ахах
Касательно таблицы с нулями позже обращусь, она не горит, а дела вот с ltv cac romi горят..",,Виктория Онучина
1608928207.384200,1610395457.416600,U01B84HU32R,"<@U0185Q2MK19> я повторно отправила проект и у меня есть вопросы к тебе вновь. По числам, к слову, у меня все вышло, но, думаю, будут вопросы касательно ""перегруженности""
&gt; Почему группируешь по 'first_buy_month' и 'buy_month' при определении размеров когорт? Мы же в разрезе источников все считаем. И почему при определении размера когорты там `.agg({'revenue': 'sum'})`, если размер когорты - это количество клиентов в ней?
Ты, видимо, посмотрел не туда. Я делаю это в cohorts_source, а в size у меня правильная группировка по nunique:
`cohort_sizes_source = payers.groupby('source_id').agg({'uid': 'nunique'}).reset_index()`
`cohort_sizes_source.columns = ['source_id', 'n_buyers']`
Спросишь почему source_id добавляю, ну, я просто не знала как еще и где добавить это. У меня есть структура проекта и просто сунуть твое решение я не могу и выкручиваюсь вот такими обходными путями. Или я делаю все неверно?
&gt; Далее ты используешь эту таблицу (cohort_source), в которой есть эта лишняя группировка для вычисления CAC, и ревьюер тебе говорит, что более оптимально присоединять конкретно расчет по размерам когорт (в котором должна быть группировка именно по источнику с агрегацией `.agg({'uid': 'nunique'}))` , как я и писал выше.
Уже разобрались, что выше у меня, вроде как по теории, правильно, а я все брала из нее. Тогда где перегруженность? Почему я не могу взять n_buyers, которые уже находила? Я соединяла таблицы, как и в теории, чтобы все было воедино и находила вместе.
Может мой материал тяжело было воспринимать, потому что много написано? И мне в будущем лучше четче подписывать все?",,Виктория Онучина
1608928207.384200,1610426499.416900,U0185Q2MK19,"<@U01B84HU32R>, у тебя просто прямо над этим действием написано - `размер когорты по источникам` . Может комменты вводят в заблуждения) Может у ревьюера была та же проблема. У тебя ревьюер, судя по скриншотам проверял работу, где еще не были дописаны выводы (а может и какие-то действия), что тоже сказывается, обычно ревьюеры вообще не проверяют промежуточные варианты, а только итоговый (сразу отправляют на доработку, если чего-то в работе нет из обязательного). Если что-то не доделано, то может итоговый результат неправильно восприниматься)

Мне ориентироваться сложновато, потому что ты выкладываешь куски кода, которые завязаны на другие твои действия (но их результатов у меня нет). Например, в последнем твоем участке кода есть sources, есть столбец first_buy_month в orders, которые высчитываются где-то ранее (мне нужно либо догадываться, как ты это делаешь, либо искать эти действия в переписке до этого, но ты их тоже могла изменять после этого) и пр.

Еще у тебя есть действия, которые очень не рекомендуется делать - ты перезаписываешь результат работы над датафреймам в исходный датафрейм (например, прямо на второй строке ты в исходный orders, что-то мерджишь и помещаешь сам в себя). Если нужно будет сделать что-то именно с исходным orders, то уже ничего не получится. А если запустить ячейку еще раз - то мы вообще можем получить непредсказуемый результат, т.к. будем делать что-то над уже перезаписанным датафреймом (поэтому результат выполнения операций даже у нас может отличаться, если ты до этого делала уже действия с этой таблицей, о которых я не знаю, в т.ч. просто несколько раз запуская эту ячейку).

Все это приводит к тому, что я просто не могу у себя воспроизвести код, который ты даешь.

Итак, к твоему вопросу и этому скриншоту: <http://joxi.ru/DmB94Mku4jVawr>. У тебя рассчитаны затраты. Теперь нужно поделить на размеры когорт.
И я уточняю, где у тебя лежат размеры когорт? Я предположил (исходя из комментария в коде), что в cohort_source. Ты именно эту таблицу используешь в расчетах. Ты говоришь, что не в cohort_source (почему ты тогда с ним работаешь?), а в cohort_sizes_source. Где у тебя на этом скриншоте данная переменная? Почему ты ее не используешь, когда нужна именно она?) Вместо этого ты используешь переменную, в которой есть еще какие-то дополнительные расчеты и группировки. ревьюер говорит - возьми уников и подели на них. (то есть на размеры когорт). Но в cohort_source  у тебя не это, а используешь ее :slightly_smiling_face:",,Олег Булыгин
1608928207.384200,1610441366.417400,U01B84HU32R,"<@U0185Q2MK19> выполняла строго по теории. Вот кусок. Отдельно находила уников (как в теории) и мерджила (ну, как в теории). Потом уже с этим и работала, там было все.",,Виктория Онучина
1608928207.384200,1610441641.417700,U01B84HU32R,"<@U0185Q2MK19> касательно выводов. У меня вот в одном моменте его не было, где жирным написано ДОПИСАТЬ. Сама потом заметила, остальные выводы были, как и итоговый. Подписи, видимо,ьлучше делать над строчками кода, а не под ними, видимо так удобнее, буду знать. Все остальное тоже учту, когда в будущем буду присылать код. Спасибо",,Виктория Онучина
1608928207.384200,1610445443.418000,U01B84HU32R,"<@U0185Q2MK19> тогда у меня вопрос, почему нельзя мерджить в исходный датафрейи, кроме как того, что может получиться каша? Лучше отдельно все делать в переменные и потом джойнить их, когда нужно? И исходные датафрейиы использовать как помощь, а не как основу (то есть необязательно тащить этот orders до конца, можно из него склепать отдельно нужное и использовать?)",,Виктория Онучина
1608928207.384200,1610457561.418400,U0185Q2MK19,"<@U01B84HU32R>, да, правилом хорошего тона является вообще не изменять исходные данные (структурно). Пусть они хранятся как есть, вдруг нам понадобится делать какие-то еще действия именно с их первоначальной формой, а наши изменений это затруднят или вообще сделают невозможным.
Еще мы ведь можем просто допустить какую-то ошибку при обработке, которая вскроется сильно дальше, а если мы уже перезаписали исходную переменную, то придется все откатывать и заново загружать данные в память.
Или мы просто случайно можем несколько раз запустить одну ячейку, внутри которой есть действия перезаписи датафрейма самим собой в измененной форме по какому-то действию и это действие реализуется несколько раз полностью сломав наши расчеты. И опять придется заново загружать данные.

Лучше каждое принципиальное изменение записывать отдельно (в свою переменную). Чтобы было легче контролировать все процессы, легче тестировать, находить у себя же ошибки и не делать зря лишнего, если что-то пойдет не так.",,Олег Булыгин
1608928207.384200,1610480183.419200,U01B84HU32R,"<@U0185Q2MK19> привет, у меня тут теперь средний чек не такой и не сякой. Смотрю на то, что ты давал в другом треде. И не могу понять, почему у меня все еще среднее от среднего. Подробно и, надеюсь, понятно, объясняю где что.
1. Я выделяла месяц с помощью dt.month и в принципе week и day выделяла также. То есть просто числом. они хранятся в моем датафрейме orders.
2. Я делала вот такие сводные таблицы, по котором потом строила графики за месяц, неделю и день соответственно: <http://joxi.ru/n2YwBq4uen7g4r> (в принципе тут похоже на то, что ты давал в треде этом: <https://yandex-students.slack.com/archives/G01B461LV0E/p1608611997355300?thread_ts=1608472259.338700&amp;cid=G01B461LV0E>). Сами таблицы выглядят вот так: <http://joxi.ru/Y2Lw4RGuEdM6pm>
3. Потом я сделала одним числом вот такую штуку: <http://joxi.ru/4AkWQkxCkR0vyA>. Хотела посмотреть единым числом среднее количество по месяцу, недели и дате. То есть я группировала, как у тебя. Потом просто делила суммарно за все периоды выручку за суммарное количество за все периоды покупателей. Таблица первая по месяцам выглядит так (<http://joxi.ru/krDv45yU4BgpV2>), ну а вторая переменная mean выглядит как на скриншоте выше (где print делала). Соответственно по дням и неделям такие же первые таблицы, где uid revenue, и соответственно идентичный метод нахождения среднего в переменной с mean.
Вопрос вот в чем: мне говорят, что я ищу среднее от среднего и так и не поделила просто выручку на просто количество покупателей. И я не понимаю... как. Может ты сможешь помочь? Ревьюер говорит, что я вообще не делила. Но как же так не делила, вот явное просто деление. Критика ревьюера: <http://joxi.ru/Y2Lw4RGuEdMKpm>

Извини, что код не высылаю, но если нужно, то вышлю со всеми изменениями переменных и прочим.",,Виктория Онучина
1608928207.384200,1610512476.420500,U0185Q2MK19,"<@U01B84HU32R>, ты верно построила визуализации в п. 2, чтобы определить, есть ли какая-то временная компонента в динамике (может средний чек больше в декабре? или по пятницам? и в первые дни мясца?).
Но нужно еще посчитать просто одно число - средний чек за все время. _Для этого никаких агрегаций делать не надо (как у тебя в пункте 3)._
Попробуй для себя объяснить, что такое средний чек в месяц? Он уже средний, т.к. мы берем все транзакции и делим на количество. Еще раз приведу пример, который писал ранее:
```у нас есть 3 покупки. на 5, 10 (в январе) и 15 рублей (в феврале. Средний чек за весь период составит 10 рублей. Что делаешь ты - ты считаешь средний чек в январе - 7.5р и средний чек в феврале - 15 рублей. Потом ищешь среднее по месяцам - (15+7.5)/2 = 11.25. Что это за число? Что оно нам дает? Это абсолютно бессмысленное вычисление.```
`orders['revenue'].mean()`  - вот такое действие делала?",,Олег Булыгин
1608928207.384200,1610521185.421200,U01B84HU32R,"<@U0185Q2MK19> нет, такого не делала. Попробую..

И я все ещё не понимаю в какой момент ищу среднее. В третьем пункте я же просто суммирую всю выручку, всех покупателей и делю выручку на покупателей. То есть я не использую уже средние данные, а строю новые. Может вводит в заблуждение, потому что я опять делю на 3 временных рамки все: месяц, неделя и день? 
В третьем пункте я просто даже mean не использую. Может я перемудрила немного с логикой, без понятия, потому что все равно, если складывать, вся выручка и все клиенты будут одинаковые, вроде, хоть ты их по месяцам хоть по неделям смотри, поэтому везде 4. Но среднее от среднего не вижу. 
Я попробую просто одним числом сделать, как ты делал, может прокатит.",,Виктория Онучина
1608928207.384200,1610521871.421500,U01B84HU32R,"<@U0185Q2MK19> до этого у меня правда было среднее от среднего, потому что я делала mean для сводной таблицы (которая в пункте 2). И тогда да, я брала среднее по месяцам, складывала и делила на 12, был бред.
Но сейчас я не беру уже сводную, строю новые, прислала как выглядят в пункте 3 второй скриншот. Так же явно видно, что uid revenue и никакого среднего.

Но да, может я просто перемудрила и незачем было делить на 3 периода третий пункт, достаточно было взять по дням, к примеру я или месяцам, количество-то не поменялось.

Подскажи, если бы я суммарное revenue за 12 месяцев делила на количество месяцев, то у меня было бы среднее на месяц revenue, то есть средний чек в месяц? Или в разбивке по периодам достаточно графиков?

UPDATE: я отправила проект на очередную проверку, там оставила вот так <http://joxi.ru/J2bwyKLuVoMOvA>. Третий пункт я изменила, делю на count, а не sum. Средний чек по месяцам, неделям и дням одним числом. Если он не нужен, ну, удалю потом, от проекта уже голова кругом. Ну и добавила то, как ты советовал, без этого int. К слову об int(). Попросил меня ревьюер посмотреть сколько покупок на одного пользователя за все время, а сказал не округлять: <http://joxi.ru/brRwjkbuO38z9m>. Почему?",,Виктория Онучина
1608928207.384200,1610536119.423400,U0185Q2MK19,"<@U01B84HU32R>,
Ну вот вся суть в этой фразе:

```Но да, может я просто перемудрила и незачем было делить на 3 периода третий пункт, достаточно было взять по дням, к примеру я или месяцам, количество-то не поменялось.```
Как я уже сказал, мы можем смотреть динамику среднего чека, чтобы найти закономерности по времени. Средний чек он потому и средний, что мы делим транзакции на пользователей. А делить еще все это на периоды и брать среднее по этим периодом - это приведет вот к этому:

```у нас есть 3 покупки. на 5, 10 (в январе) и 15 рублей (в феврале. Средний чек за весь период составит 10 рублей. Что делаешь ты - ты считаешь средний чек в январе - 7.5р и средний чек в феврале - 15 рублей. Потом ищешь среднее по месяцам - (15+7.5)/2 = 11.25. Что это за число? Что оно нам дает? Это абсолютно бессмысленное вычисление.```
А на последнем скриншоте ты считаешь вообще не чек,  ты делишь сумму дохода на количество периодов (зачем-то на основе группировки). Это тогда вообще не чек, это просто средний доход за период. И тогда ничего группировать не надо, надо просто общий доход делить на количество периодов.

На счет последнего вопроса: ревьюер сказал, что *можно* не округлять. Нет ничего страшного в формулировке – в среднем пользователь делает полторы покупки в месяц, это ведь усредненный показатель.",,Олег Булыгин
1608928207.384200,1610536300.424000,U01B84HU32R,"<@U0185Q2MK19> ладно, я в упор не вижу, где я применяла mean() к своему среднему. Где я делила, а потом находила среднее. Если я просто делила и использовала int() при выводе. Я именно этот момент не понимаю, где там видно среднее. Но не суть, просто буду знать как искать средний чек и все.

Оставлю просто orders['revenue'].mean()",,Виктория Онучина
1608928207.384200,1610536348.424200,U0185Q2MK19,"<@U01B84HU32R>, ты сумму делишь на количество, чем это отличается от mean?)",,Олег Булыгин
1608928207.384200,1610536494.424400,U01B84HU32R,"<@U0185Q2MK19> но я же не делаю сумму среднего на количество этого среднего, я делю сумму исходных данных revenue в orders на количество (сумму покупателей) исходных данных uid в orders. Как там среднее полцчается-то при агрегацииях sum/count?",,Виктория Онучина
1608928207.384200,1610536672.424600,U0185Q2MK19,"<@U01B84HU32R>, формула среднего арифметического - сложить все наблюдения и поделить на количество.

Если нас интересует средний показатель дохода за неделю, то мы берем суммарный доход и делим на количество недель.
Если средний доход за месяц - берем сумму выручки за месяц и делим на количество месяцев.

Это все среднее арифметическое.

Ты берешь сумму дохода со всем покупателей и делишь на количество периодов. Это средний доход за период.
Если бы ты поделила сумму дохода по транзакциям на количество клиентов, то получила бы то, что называется средним чеком (`mean`).

Если у тебя в знаменателе что-то другое, это не перестает быть средним, просто это среднее другого показателя",,Олег Булыгин
1608928207.384200,1610536792.425000,U01B84HU32R,"<@U0185Q2MK19> то есть вернемся к тому, что я делала (я удалила те коды, которые не нужны, взяла из прошлых проверочных, которые сохраняла, один кусок). У меня выходит почти такое же число за исключением каки-то тысячных.стотысячных значений. Я просто в print использовала int(). Но я потом поняла, что зря просто поделила на много периодов и все. Я везде получила 4, потому что делила сумма дохода на количество покупателей. Просто по-разному из группируя (сумма-то одна и покупателей одно количество). Скриншот проверки:
Поэтому я вообще не согласна, что использовала там среднее от среднего. Но соглашусь с тем, что перемудрила.","[{'name': 'cat-high-five', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Онучина
1610732340.002900,1610732340.002900,U01C12GKE1E,"Суть проекта ""*Рынок заведений общественного питания Москвы""*
Описание проекта.",,Гуменников Алексей
1610732340.002900,1610734280.003000,U01C12GKE1E,"<@UU59EH1B8> привет!
Мне кажется, что подзадачи которые решаются в ходе проекта не решают ту задачу, которая в целом  стоит в проекте.
Подзадачи направлены на формирование статистических данных  в разных разрезах и выявление  некоторых закономерностей, на  основе которых нужно дать рекомендации и их презентовать.
Не понятно как на основе этого инвесторы сделают вывод ""сможете ли вы снискать популярность на долгое время, когда все зеваки насмотрятся на роботов-официантов"".
И инвесторам наверно нет дела до рекомендаций, им нужно указать характеристики кафе которые мы планируем открыть и примерное место его расположения с пояснениями причин такого выбора.
Так же в исходных данных нет ни какой информации с финансовыми и временными характеристиками объектов общественного питания. А без них такой анализ выглядит как-то совсем грустно. Может половина заведений в популярных местах закрывается в течении года.
Я понимаю, что это учебный проект и прощу прощения за свое занудство, но очень хочется четче представлять тот результат который нужно получить.",,Гуменников Алексей
1610732340.002900,1610793081.005800,U01B4EYRJ5U,"тоже задалась вопросом, как те данные и графики, которые мы строим, позволят ответить на вопрос про популярность заведений",,Ольга Соколовская
1610732340.002900,1610795013.006000,U01BB72P2HG,"там можно найти взаимосвязь и факторы влияния. но не могу спойлерить, пока все не сдадут проект:grinning: и роботы не ключевой момент тут, скорее фан))) выводы подойдут для любого заведения.",,Мария Пименова
1610732340.002900,1610795631.006200,U01C12GKE1E,"Заинтриговала, <@U01BB72P2HG>! Ок, приступаю!",,Гуменников Алексей
1610732340.002900,1610795949.006400,U01BB72P2HG,"<@U01C12GKE1E> я роботов рассматривала как фактор допвложений, ты об этом писал:slightly_smiling_face::raised_hands: но по идее это может быть что угодно вместо роботов))))",,Мария Пименова
1611036340.018300,1611036340.018300,U01BBD8EYR1,"*Как рассказать историю с помощью данных. Проект*
*Рынок заведений общественного питания Москвы*
*Предобработка данных*",,Евгения Батухтина
1611036340.018300,1611036708.018400,U01BBD8EYR1,"Пишу функцию, которая обновляет виды объектов для сетевых заведений, так как у той же шоколадницы может быть несколько видов, а я хочу привести к одному. Однако, получаю ошибку. Не могли бы подсказать, в чем дело.

У меня есть датафрейм с названиями, по которым я хочу пройтись. И потом к этому датафрейму я через функцию хочу добавить новый столбец, но получаю ошибку. Функцию проверила, работает корректно.

<http://joxi.ru/RmzPK1gUMQ065A>
<http://joxi.ru/VrwPWXQU4bOBdm>

<https://pastebin.com/FNHRhzGq>",,Евгения Батухтина
1611036340.018300,1611046612.019500,U01B4EYRJ5U,мне это тоже было бы интересно <@U0185Q2MK19>,,Ольга Соколовская
1611036340.018300,1611054859.025200,U0185Q2MK19,"<@U01BBD8EYR1>, <@U01B4EYRJ5U>, дело в том, что такая ошибка будет возникать, если вы применяете apply к Series с аргументом axis. При таком применении аргумент axis не требуется (и просто бессмысленен, т.к. Series одномерный). А вы применяете так, как будто работаете с датафреймом. Вот здесь можно почитать обсуждение: <https://stackoverflow.com/questions/45878720/dataframe-apply-doesnt-accept-axis-argument>",,Олег Булыгин
1611036340.018300,1611055285.029500,U01BBD8EYR1,"<@U0185Q2MK19> так я специально у списка индексы поресетила, чтобы получился датафрейм. То есть reset_index() не обеспечивает создание датафрейма? Нужно именно переобразовать в датафрейм?",,Евгения Батухтина
1611036340.018300,1611055370.030000,U0185Q2MK19,"<@U01BBD8EYR1>, не совсем, дело вот в этом срезе: <https://pastenow.ru/BCFNX>
Когда ты выбираешь конкретный столбец через одинарные квадратные скобки на выходе всегда будет Series",,Олег Булыгин
1611036340.018300,1611073046.031300,U01BBD8EYR1,"<@U0185Q2MK19> поняла, спасибо",,Евгения Батухтина
1608490921.341700,1611125694.060500,U01BHCPLXHS,"<@U0185Q2MK19>, <@U013KK77R2S>, привет! Подскажите, пожалуйста, а если бы в наших данных в этом проекте были бы строки с возвратом товаров, мы бы их удаляли для расчета retention rate? Так как они получаются искажают картину, пользователи возвращаются в последующие месяцы, но не для совершения новых покупок, а для возврата предыдущих. Так?",,Вероника Гром
1608490921.341700,1611140888.061900,U0185Q2MK19,"<@U01BHCPLXHS>, привет!
Да, конечно, возвраты никак не пошли бы в зачет того, что пользователи держатся на нашем сервисе и совершают платежи.
Но я никогда не видел, чтобы данные о возвратах хранились прямо вместе с данными о заказах.",,Олег Булыгин
1608490921.341700,1611163479.077300,U01BHCPLXHS,"<@U0185Q2MK19>, я решаю похожее задание, как в проекте, где как раз такая ситуация, спасибо за ответ! И еще мне нужно ответить на вопросы:
""Сколько в среднем времени проходит между покупками? Уменьшается ли это времени в зависимости от числа покупок?""
Подскажи, как подступиться, сам алгоритм не понимаю. У нас есть столбцы с user_id, order_id, order_date, cost. Я должна сгруппировать по пользователю и как-то из следующей даты заказа вычитать текущую. Не понимаю, как это сделать. И не понимаю, что делать дальше. Опиши, пожалуйста, алгоритм действий, заранее огромная благодарность!:hugging_face::pray:",,Вероника Гром
1608490921.341700,1611220792.001700,U0185Q2MK19,"<@U01BHCPLXHS>,
Да, нужно сгруппировать данные по пользователям и при вычислении разниц делать сдвиг на одну дату.
Вот здесь обсуждение очень похожей задачи:
<https://stackoverflow.com/questions/45241221/python-pandas-calculate-average-days-between-dates/45242882>
Почти тоже самое, только там еще группировка в рамках года, можно аналогично без нее.",,Олег Булыгин
1608490921.341700,1611232259.002100,U01BHCPLXHS,"<@U0185Q2MK19>, спасибо)) по этой ссылке всё получилось! :celebrate:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Вероника Гром
1611036340.018300,1611294606.002400,U01BHCR9XE0,"<@U0185Q2MK19> добрый день, подскажите как правильно делать ""содержание со ссылками на соответствующие разделы проекта""? Делаю по теории, но не получается",,Gaukhar
1611036340.018300,1611295103.002600,U0185Q2MK19,"<@U01BHCR9XE0>, добрый день! Вот тут есть наглядный пример: <https://stackoverflow.com/questions/11948245/markdown-to-create-pages-and-table-of-contents/33433098#33433098>
Чтобы понять, почему именно не получается, желательно увидеть код и скриншоты :slightly_smiling_face:",,Олег Булыгин
1611036340.018300,1611382542.000100,U01AWENQ0R5,"@Олег, привет, подскажи, пожалуйста, правильно ли я написал и применил функцию, которую предложила <@U01BBD8EYR1> ?
<https://pastebin.com/g0861ptW|https://pastebin.com/g0861ptW>
проверяю, вроде результат выдает нужный, но вдруг я криво написал и можно как-то лаконичнее",,Volkhin Roman
1611036340.018300,1611382801.000400,U0185Q2MK19,"<@U01AWENQ0R5>, все ок, но я бы с осторожностью применял такие замены, т.к. в рамках одной сети в теории могут быть разные форматы заведений, желательно это перепроверить и не внести искажения.",,Олег Булыгин
1611036340.018300,1612204125.066300,U01BHCPPL2Y,"Добрый день!
Использовал геокодер для определения районов, случайно вышел за лимит в 1000 запросов и, соответственно, получил бан ключа. На почту (<mailto:paid-api-maps@yandex-team.ru|paid-api-maps@yandex-team.ru>) написал, но не уверен что успеют разблокировать до момента проверки преподавателем (если ещё вообще разблокируют).
Надеюсь преподаватель сможет проверить без перезапуска ячеек с геокодером (либо у него есть свой ключ), иначе будет печально.",,Me_
