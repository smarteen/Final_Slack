thread_ts,ts,user,text,reactions,real_name
,1600949851.000500,UTTGJQS6M,"*#projects — канал для обсуждения проектов.*

В этом канале помогает работать преподаватель. Здесь можно задавать вопросы, возникшие по ходу работы над проектом; предполагаем, что они будут относиться в большей степени к логике, структуре, формулировкам, выводам, а также — к ревью.

Если вы хотите задать вопрос в канале projects, *коротко назовите свой тред*, обозначив сферу вопроса и *тегните нашего преподавателя по проектам.*

Например так:
```Вопрос о прорисовке boxplot на одном графике```

А уже *внутри треда задайте свой вопрос,* опишите способы, которые уже использовали, приложите скриншоты, коды и другие подробности.

_Также вы можете ставить реакцию-галочку, если ваш вопрос в треде решён_ :heavy_check_mark:

Соблюдая такие правила, вы проявляете уважение к другим пользователям, так как не всем удобно пролистывать длинные сообщения, чтобы найти тот самый нужный тред.

&gt; А ещё так мы спасём мир от внезапных спойлеров  :nyancat:

Немного жести:bangbang: *Неправильно оформленные треды подлежат удалению* :bangbang:

Когда вы задаёте вопросы здесь, это помогает в том числе и вашим одногруппникам.
Если у вас возникла трудность с заданием — проверьте переписку в треде, возможно, кто-то уже сталкивался с этой проблемой, и в чате есть полезные советы по её решению.
Удобно: не придётся ждать, когда придёт ответ:)","[{'name': '+1', 'users': ['U01C12EJQ80', 'U01C12EHMPS', 'U01BBD7LHDH', 'U01C12ENW9W'], 'count': 4}]",Маргарита Минеева
,1601441449.023900,U0185Q2MK19,"Всем привет!

Меня зовут Олег и я буду помогать вам в решении вопросов с проектами :slightly_smiling_face:

Немного обо мне:
*Профессиональное:*
За последние 5 лет занимал управленческие должности в научно-производственных организациях космической отрасли, занимался IT-аудитом в банковской сфере. Везде применял инструменты data analysis. data science и process mining для улучшения процессов бизнеса :signal_strength:
Примерно столько же занимаюсь преподаванием различных IT-дисциплин – от Python до SQL :male-student:

*Хобби*:
Совмещаю приятное с полезным в увлечениях инвестициями :moneybag:и только приятное – настольными играми :game_die:

Жду от вас энтузиазма, упорства и взаимопомощи, всем добра :v:","[{'name': 'handshake', 'users': ['U01C12CA716', 'U01C12EJQ80', 'U01C12H494Y', 'U01AWENSUVD', 'U01C12EHMPS', 'U01BHCM2F7W', 'U01C12HNA1E'], 'count': 7}, {'name': '+1', 'users': ['U01AWENUYB1', 'U01B4EXA6S2', 'U01C12DR740'], 'count': 3}, {'name': 'spock-hand', 'users': ['U01BB70DBDY'], 'count': 1}, {'name': 'v', 'users': ['U01B84FNBPX', 'U01375HRT1V'], 'count': 2}]",Олег Булыгин
1601443993.025700,1601443993.025700,U019642UB9D,":pushpin:<@U0185Q2MK19> Добрый день, возникни сложности. Вопрос в части лемматизации. Может быть я как-то неправильно понял задание? Также прошу дать комментарий насчет моей первой функции, правильна ли такая идея? <https://pastebin.com/hm5TPsz9>",,Илья Ревин
1601443993.025700,1601450977.026400,U0185Q2MK19,"<@U019642UB9D>, привет!

По обоим вопросам: я не рекомендую использовать циклы для обработки данных внутри датафрейма. Это всегда медленнее и менее лаконично.
Лучше использовать функции map/apply.

Например, лемматизацию можно сделать так:

```from pymystem3 import Mystem
m = Mystem()
df['lemmas'] = df.purpose.map(m.lemmatize)```
Ну и не думаю, что стемминг тут вообще будет полезен, можно обойтись только лемматизацией.",,Олег Булыгин
1601443993.025700,1601462586.027200,U019642UB9D,"<@U0185Q2MK19> Спасибо, функция map помогла. Даже если моя попытка стемминга оказалась неоправданной, можете, пожалуйста, объяснить, какая ошибка в моей функции? Моя цель была изменить значения ячеек, в которых в одном из всех слов есть хотя бы один корень ""свадьб"" на слово ""свадьба"". (я очень старался над этой функцией и пытался ее реализовать)",,Илья Ревин
1601443993.025700,1601463337.027600,U0185Q2MK19,"<@U019642UB9D>, дело в том, что `return` всегда прерывает исполнение функции. Как только первое совпадение будет найдено, то функция просто завершится.

Я бы в данном случае тоже использовал `map`, примерно так:

```def change_word_by_root(col):
        for word in col.split():
            stemmed_word = russian_stemmer.stem(word)
            if stemmed_word == 'свадьб':
                return 'свадьба'
data['res'] = data['purpose'].map(change_word_by_root)```",,Олег Булыгин
1601485322.029300,1601485322.029300,U01BBD72X1R,Категоризация данных,,Артем Провороцкий
1601485322.029300,1601485392.029400,U01BBD72X1R,"<@U0185Q2MK19> Подскажи, пожалуйста, я вывел леммы из столбца purpose, и перешел к шагу Категоризация данных, чет встал в некий ступор.
1.Подскажешь в каком направлении двигаться и что делать?))
2. В шаге лемматизации нужно только вывести леммы или еще чтото с ними делать?)

леммы вывел так <https://pastebin.com/MfFA65SU>
а потом ручками определил направления",,Артем Провороцкий
1601485322.029300,1601536905.030000,U0185Q2MK19,"<@U01BBD72X1R>, логика такая:
1. выделяем леммы в исходных целях кредита. 
2. При помощи Counter смотрим, какие цели вообще бывают (уже на лемматизированных данных)
3. Определяем самые частые цели (руками)
4. Пишем функцию, которая присваивает каждой строки конкретную категорию (цель). Это понадобится далее, чтобы изучить взаимосвязь целей и сроков возврата
То есть у тебя верный ход мыслей, надо только теперь присвоить каждому кредиту конкретную категорию","[{'name': '+1', 'users': ['U01BBD72X1R'], 'count': 1}]",Олег Булыгин
1601745509.034500,1601745509.034500,U01B84FNBPX,Обработка пропусков: можно ли совсем избавиться от столбца?,"[{'name': 'heavy_check_mark', 'users': ['U01B84FNBPX'], 'count': 1}]",Валентина Тушкова
1601745509.034500,1601746298.034600,U01B84FNBPX,"<@U0185Q2MK19> привет! Подскажи пожалуйста, у нас в датасете в 'days_employed' целая куча пропусков, но еще к тому же и отрицательные значения.  Если NaN еще как-то можно заполнить, то с минусами я вообще не знаю, как поступить, не исказив данные. К тому же я не знаю, откуда эти минусы появились изначально:woman-shrugging: Корректно ли будет просто сделать drop этого столбца? В задании ничего нет про зависимость трудового стажа и возврата кредита, так что кажется на конечный результат анализа это не должно повлиять.",,Валентина Тушкова
1601745509.034500,1601748123.034800,U016DNMFQ21,"<@U01B84FNBPX> привет! Есть мнение, что для решения задачи этот столбец не нужен, так как в вопросах к проекту нет задачи исследовать зависимость чего либо от стажа. Косвенно он мог бы пригодиться при заполнении пропусков, но есть другие варианты как обработать пропуски в других столбцах. 
Я пробовал посмотреть данные столбца повнимательнее, подсчитать количество лет стажа и получал достаточно удивительные результаты. Для себя я так и не смог однозначно объяснить причины возникновения таких данных, кроме вполне очевидных - человеческий фактор, техническая ошибка системы.",,Сергей Лифанов
1601745509.034500,1601749453.037400,U01C12CA716,"А вы не думали над тем как рассчитывается показатель «стаж»? Т.е. само значение не просто вносилось в эту колонку, а было результатом вычисления. Мне кажется тут может быть ответ на вопрос «откуда отрицательные значения?»",,Скребцов Роман Васильевич
,1601784101.038200,U01AWEP1SJK,"df.drop(df.columns[[номера столбцов]], axis='columns') - через это можно","[{'name': '+1', 'users': ['U01B84FNBPX', 'U01C12EJQ80'], 'count': 2}]",Владислав Несоленов
1601745509.034500,1601791204.038300,U0185Q2MK19,"<@U01B84FNBPX>,теоретически, если нам столбец вообще не нужен для анализа, то конечно его вполне можно убрать.

Но в этом учебном проекте лучше показать ревьюеру, что вы умеете работать с аномальными значениями (выдвигать гипотезы об их причинах и делать соответствующие замены). Поэтому я полностью согласен с <@U01C12CA716>
Эти аномальные значения могут быть связаны с техническими проблемами выгрузки. Мы можем только гадать о точных причинах. Возможно, в них стаж хранится в часах, а не в днях. Минусы могут обозначать, что отсчет шел от текущей даты (назад). Но это все догадки :slightly_smiling_face:

Окончательное решение - за тобой :)",,Олег Булыгин
1601745509.034500,1601796411.038500,U01B84FNBPX,"Спасибо Олег! буду думать:) Хотя я всегда за практичность, если данные лишние так и не тратить время на их обработку. Но раз уж ревьюерам это важно.. :slightly_smiling_face:",,Валентина Тушкова
1601745509.034500,1601796624.038700,U01B84FNBPX,"<@U016DNMFQ21> Да вот и я, так и этак пересчитывала и никакого подвоха не нашла:sweat_smile:",,Валентина Тушкова
1601745509.034500,1601800628.047600,U01C12CA716,"Курс направлен не только на то, чтобы научить нас инструменту python, а научить думать аналитически. Поэтому ревьюеру важно понимать как мы мыслим, почему делаем именно так, как мы делаем. Если вы, <@U01B84FNBPX> , считаете что столбец можно просто удалить, то напишите об этом в проектной работе и объясните почему. Кажется так и построен наш учебный процесс. Ревьюер либо примет ваш ответ, либо вернёт на доработку и «подтолкнёт» к правильным выводам :)
<@U016DNMFQ21> , интересная мысль о конвертации в года, надо будет тоже посмотреть :)","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01B84FNBPX'], 'count': 2}]",Скребцов Роман Васильевич
1601745509.034500,1601807223.048000,U016DNMFQ21,"<@U01B84FNBPX> исходя из наблюдений, стало понятно что одним знанием инструментов аналитики обойтись не получится, всегда будет какая-то прикладная часть, которую либо изучать самостоятельно либо выяснять у коллег/заказчика. Чтобы провести хотя бы частотный анализ продаж товара в сезон надо понимать, что помимо месяца года которые обозначает конкретный сезон, условно, может стоять ещё огромное количество внешних и внутренних (с точки зрения системы продаж) факторов, даже не пытаться думать о которых - глюкоза на ветер. Даже если заказчика интересует только это, для себя ведь всегда интересно поковыряться.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Лифанов
1601810552.052300,1601810552.052300,U01B4EZUE4E,Вопрос по поводу корректности данных в столбце “total_income”,,Сергей Афанасьев
1601810552.052300,1601810561.052400,U01B4EZUE4E,"<@U0185Q2MK19>  В столбце о ежемесячном доходе, какие-то огромные цифры. Типа доход студента в 98000 или безработного в 59000. Это так задумано и данные верны или надо найти причину и сделать цифры более реалистичными?",,Сергей Афанасьев
1601745509.034500,1601813610.052600,U01B84FNBPX,":100: <@U016DNMFQ21> , domain knowledge нужен всегда. Так же как и любопытство, поковыряться в данных:)
<@U01C12CA716> так и сделаю, если что доработаю после ревью. Не знаю что-то затормозила на первом проекте.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Валентина Тушкова
1601810552.052300,1601818247.052800,U0185Q2MK19,"<@U01B4EZUE4E>, в данном конкретном случае я не вижу ничего страшного. Эти значения носят не массовый характер. Иногда у студента и безработного могут быть высокие доходы (это не зарплата, а именно доход) :slightly_smiling_face:
Я бы оставил эти значения, как есть","[{'name': '+1', 'users': ['U01B4EZUE4E'], 'count': 1}]",Олег Булыгин
1601443993.025700,1601832557.054800,U01C12CA716,"<@U0185Q2MK19> добрый вечер!
Выполняю проект на домашнем компьютере. Столкнулся с тем, что код

df['lemmas'] = df.purpose.map(m.lemmatize)

на домашнем компьютере выполняется очень долго. При этом если его выполнить в ""тренажере"", то выполняется за доли секунды. Может есть какие-то хитрости о которых я не знаю? Может надо какую-то определенную версию pymystem3 устанавливать, к примеру?",,Скребцов Роман Васильевич
1601443993.025700,1601871194.057000,U0185Q2MK19,"<@U01C12CA716>, привет!

Код точно _абсолютно_ аналогичный? Обычно с такой проблемой сталкиваются, когда операцию создания лемматизатора `m = Mystem()`  помещают в цикл (она долгая). Других причин сходу не вижу:thinking_face:",,Олег Булыгин
1601443993.025700,1601872883.066100,U01C12CA716,"<@U0185Q2MK19> , доброе утро! Да, код точно аналогичный. Ради интереса оставил выполнение на ночь(до этого результата не дожидался, прерывал). Выполнился часов за 5 примерно :rolling_on_the_floor_laughing: была единственная мысль - это то, что мой комп намного «слабее» сервера на котором работает тренажёр, но вроде у меня не такой древний комп :joy:
Но факт того, что обычно с таким не сталкиваются говорит о том, что у меня все же что-то «не так». 
Сегодня вечером или завтра утром запишу на видео что именно и как делаю)",,Скребцов Роман Васильевич
1601892195.066800,1601892195.066800,U01BBD72X1R,"Сводная таблица ""Есть ли зависимость между наличием детей и возвратом кредита в срок?""",,Артем Провороцкий
1601892195.066800,1601892319.066900,U01BBD72X1R,"<@U0185Q2MK19> Подскажи, пожалуйста, как мне можно  посчитать показатели относительно всех групп,  а не показатели относительно недолжников. Те в знаменателе должна быть сумма. Не пойму как это сделать)

<https://pastebin.com/JfnwaJwP>",,Артем Провороцкий
1601897352.068300,1601897352.068300,U01C12EGBU0,Оформление проекта: есть возможность упростить оформление и создание ссылок по всей работе?,,Сергей Ильин
1601897352.068300,1601897458.068400,U01C12EGBU0,"<@U0185Q2MK19> Олег, привет! Интересует возможность сократить усилия на создание ссылок и оглавления в проекте. Нашел дополнительное расширение, но оно не очень функциональное. Хотелось бы, чтобы на базе уже созданных заголовков можно было сделать оглавление со ссылкой на заголовок.",,Сергей Ильин
1601443993.025700,1601899128.068700,U019642UB9D,"<@U0185Q2MK19> Добрый день, сначала работал метод для лемматизации, который вы показали. Но сейчас почему то выдает ошибку ""'int' object has no attribute 'splitlines'"". Что здесь не так? <https://pastebin.com/HfiVUs7G>",,Илья Ревин
1601892195.066800,1601902905.069300,U0185Q2MK19,"<@U01BBD72X1R>, если я правильно понял мысль, то можно же просто поделить на *сумму* индекса 0 и 1 и умножить на 100 :)",,Олег Булыгин
1601897352.068300,1601903051.069500,U0185Q2MK19,"<@U01C12EGBU0>, привет!
Честно, сам я таких инструментов никогда не встречал. Надо смотреть в сторону кастомных расширений Юпитера.

Погуглив обнаружил вот такое: <https://github.com/minrk/ipython_extensions>
Думаю, оно частично решит задачу",,Олег Булыгин
1601443993.025700,1601903345.069800,U0185Q2MK19,"<@U019642UB9D>, привет!
Код по ссылке абсолютно верный. Подозреваю, что перед лемматизацией ты как-то заменил содержимое столбца purpose. Там точно строковые значения до этого действия?

Поэтапно выполни все шаги заново, чтобы понять после каких изменений выдается ошибка",,Олег Булыгин
1601897352.068300,1601903363.070000,U01C12EGBU0,"Спасибо, просмотрю! Просто думал должен быть удобный метод, так как в проектах это требуется, а вручную занимает много времени...","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Ильин
1601443993.025700,1601903930.070200,U0185Q2MK19,"<@U01C12CA716>, в интернетах пишут, что библиотека может плохо работать именно на windows, т.к. заточена под linux и люди также иногда встречают проблемы с производительностью.

Лично у меня винда, никаких проблем никогда не было с ней)
Лучше тогда средой тренажера видимо пользоваться.",,Олег Булыгин
1601904244.070800,1601904244.070800,U01BBD743QB,Сводная таблица зависимости между показателями,,Айнур Мусаева
1601904244.070800,1601904343.070900,U01BBD743QB,"<@U0185Q2MK19> подскажите, пожалуйста, как модифицировать код df.groupby('purpose_group')['debt'].agg(['count','sum','mean']) так, чтобы внутри сводной таблицы данные располагались в порядке возрастания показателя mean (доля просрочек по конкретной цели кредита)?",,Айнур Мусаева
1601892195.066800,1601908081.072400,U01BBD72X1R,"<@U0185Q2MK19> А если в виде кода, как это может выглядеть? Если не сложно) Хотябы на примере..",,Артем Провороцкий
1601904244.070800,1601910484.072600,U01C12EGBU0,"Привет! Я такое делал, в результирующей таблице есть столбец mean, поэтому можно обычной функцией сортировки по этому столбцу воспользоваться.",,Сергей Ильин
1601925042.073600,1601925042.073600,U01C12H494Y,пропуски в total_income,,Влад Простаков
1601925042.073600,1601925655.073700,U01C12H494Y,"<@U0185Q2MK19> , подскажи, пожалуйста. я считаю, что удаление или замена на медианное значение пропусков исказит результат, поэтому хочу заменить пропуски на no_info, что автоматически меняет тип на object и в дальнейшем возникает проблема при замене типов данных в этом столбце на int. Может необходимо оставить тип float для этого столбца? или создать новую таблицу, куда поместить только значения no_info?",,Влад Простаков
1601925042.073600,1601948656.074600,U016DNMFQ21,"Привет! Я думаю стоит посмотреть количество пропусков и посмотреть общее количество. Если я правильно помню, их там достаточно, чтобы не удалять строки. Заменить на медиану можно не все строки разом, а посмотреть выборочно по каким-то столбцам, то есть сгруппировать по значениям, например с целью кредита или образованием, и заполнить пустые только после группировки, и не все, а только в выбранной группировке. Так можно уменьшить величину искажения.",,Сергей Лифанов
1601904244.070800,1601954563.074800,U0185Q2MK19,"<@U01BBD743QB>, Сергей подсказывает совершенно верно, можно просто использовать sort_values для сортировки по mean :slightly_smiling_face:",,Олег Булыгин
1601892195.066800,1601955424.075000,U0185Q2MK19,"<@U01BBD72X1R>,
```children_pivot['ratio'] = children_pivot[1] / (children_pivot[0] + children_pivot[1])```",,Олег Булыгин
1601925042.073600,1601955870.075200,U0185Q2MK19,"<@U01C12H494Y>, согласен с Сергеем. Стоит попробовать сделать замену пропусков на конкретные значения (в разрезе других параметров), либо обосновать почему это не корректно.
Заполнять no_info тут не очень подойдет",,Олег Булыгин
1601962835.075800,1601962835.075800,U01BBD7KBA7,Присвоение категорий после лемматизации,"[{'name': 'heavy_check_mark', 'users': ['U01C12H494Y'], 'count': 1}]",Влад Иванов
1601962835.075800,1601963182.075900,U01BBD7KBA7,"<@U0185Q2MK19> Добрый день! Прошу помощи. Спотыкаюсь на этапе присвоения категорий. После выделения лемм имею столбец с элементами типа 'cписок' (например [покупка, , жилье, \n])
Вручную выделил основные категории, пытаюсь присвоить категории при помощи if-else (см. ссылку).  Ничего пока не получается, возникает сразу несколько вопросов:
1. Стоит ли вообще идти по этому пути или есть более изящный способ, выделить категории?
2. Каким образом можно поменять тип целого столбца с 'list' на 'str', мне кажется именно поэтому не получается реализовать поиск?
3. Возможно и не стоит менять тип данных, и есть возможность выполнить алгоритм перебора каждого элемента списка.
ссылку прикрепляю:
<https://pastebin.com/s9jyXp6R>",,Влад Иванов
1601925042.073600,1601963405.076300,U01C12H494Y,"спасибо <@U016DNMFQ21> , спасибо <@U0185Q2MK19>
<@U0185Q2MK19> теперь не могу понять каким образом сгруппировать, чтобы одновременно увидеть информацию с отсутвующими значениями total_income и другие столбцы.",,Влад Простаков
1601925042.073600,1601968272.076500,U01B84FNBPX,Попробуй так? `df[df['total_income'].isnull()]`,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Валентина Тушкова
1601892195.066800,1601969259.076700,U01BBD72X1R,<@U0185Q2MK19> большое спасибо!,,Артем Провороцкий
1601962835.075800,1601973838.076900,U016DNMFQ21,"<@U01BBD7KBA7> привет!
1) твой способ очень хорош, я думаю стоит его доработать, об этом напишу ниже
2) список(list) получается после лемматизации, когда функция принимает строку, идёт от первого символа до пробела, заносит эту часть строки в список, потом опять идёт до пробела (то бишь разделителя), эту часть заносит в список, и так далее, пока не встретит переход на новую строку (конец строки) и не добавит последнее значение в список от последнего пробела до конца строки, потом получившийся список приводит к леммам (то есть для глаголов выбирает начальную форму, в прилагательных меняет окончания и число, кажется). Более подробно можно почитать на странице проекта pymystem3 на страницах сервисов Яндекса, где-то натыкался, могу найти и скинуть
Прошу прощения за пример, пишу со смартфона:
В коде где if == ""свадьба"": следующий if я бы поставил без отступов, то есть не внутри первого if == ""свадьба"".
А то получается что если i равно ""свадьба"" то мы попадаем в это условие, но так как условие уже выполнено, все следующие нам не подойдут. А если условие не выполнено, i != ""свадьба"" то мы не попадаем во все остальные условия (цели кредита), так как они выполняются только в том случае, если i = ""свадьба"".
if i == ""свадьба"":
    Присвоить значение свадьба
    continue
if i == ""жилье"":
    Присвоить значение жилье
    continue
.........
3) Вместо else можно написать
df['purpose_lemmatized_short'] = 'другое'
Так как если у нас сработало одно из условий, мы благодаря инструкции continue переходим на следующую итерацию, если ни в одно из условий не попали, тогда эта категория будет 'другое'

Ещё можно поискать информацию об операторах Пайтона, есть операторы (их два) которые проверяют наличие значения в множестве (то бишь списке). То есть если свадьба в списке, тогда категория - свадьба.",,Сергей Лифанов
1601904244.070800,1601982972.077100,U01BBD743QB,"<@U01C12EGBU0>, <@U0185Q2MK19> , большое спасибо! :)",,Айнур Мусаева
1601962835.075800,1601985743.077300,U0185Q2MK19,"<@U016DNMFQ21>, отличное объяснение :slightly_smiling_face:

<@U01BBD7KBA7>, отпишись, обязательно о результатах)",,Олег Булыгин
1601925042.073600,1601985805.077500,U0185Q2MK19,"<@U01C12H494Y>, ну а хороший метод заполнения пропусков в разрезе других категорий я упоминал здесь: 

Рекомендую использовать метод transform. Он позволит в одну строку все это сделать. Вот так:
```df['days_employed'] = df['days_employed'].fillna(df.groupby('income_type')['days_employed'].transform('median'))
```
Можно даже по нескольким признакам делать группировку :slightly_smiling_face:","[{'name': '+1', 'users': ['U01AWENUYB1', 'U01BHCM2F7W', 'U01B4EYLV2A'], 'count': 3}]",Олег Булыгин
1601925042.073600,1601999523.077800,U01C12H494Y,<@U0185Q2MK19> не работает ссылка,,Влад Простаков
1601925042.073600,1602000348.078100,U0185Q2MK19,"<@U01C12H494Y>, напрямую указал в тексте)",,Олег Булыгин
1601925042.073600,1602004122.078300,U01C12H494Y,"<@U0185Q2MK19> df['total_income'] = df['total_income'].fillna(df.groupby('education')['total_income'].transform('median'))
как в этом случае понять, что на медиану заменяются только необходимые значения? например, я хочу заполнить только пропуски total_income для 'education' == 'среднее'",,Влад Простаков
1601443993.025700,1602006704.078500,U01BHCQN9D2,"<@U0185Q2MK19> , добрый день!
1. Немного запуталась лемматизацией и категоризацией данных. Не могу сохранить в Counter и не понимаю почему? И надо ли не это?
2. Не получается создать функцию, чтобы категоризовать ""цели кредита"", ошибка : string indices must be integers.Подсмотрела, что можно использовать функцию split(),но тоже ничего не выходит

<https://pastebin.com/17M7QuuF>",,Ксения Идрисова
1601962835.075800,1602007423.078700,U01C12H494Y,"<@U0185Q2MK19> , я создал свою функцию для присвоения категорий, использовал оператор для проверки наличия элемента в списке по совету <@U016DNMFQ21>: <https://pastebin.com/fQjNQHfq>
Добавить значения в новый столбец не получается, я думаю, проблема в вызове этой функции.",,Влад Простаков
1601892195.066800,1602013270.085300,U01BHCQN9D2,"<@U0185Q2MK19> , добрый день!Правильно ли я решила искать зависимость между наличием детей и возвратом кредита с помощью функции?
Функция не работает потому что у меня не настроена лемматизация и категоризация?

<https://pastebin.com/w3pvWjsN>",,Ксения Идрисова
1601443993.025700,1602017234.085700,U01C12EGBU0,"<@U0185Q2MK19> Олег, привет! Могу подтвердить проблему на своей системе с pymystem3 - в тренажере все отлично, а на своей системе Win10 застревает надолго. Я провел эксперимент и в WSL (Ubuntu) у меня проблема не ушла, точно также застревает. Может все же что-то не так с кодом и можно написать производительней? <https://pastebin.com/gwCHfYcS>",,Сергей Ильин
1601962835.075800,1602019287.085900,U01C12CA716,"<@U01C12H494Y>, привет! Обрати внимание на название DataFrame, который ты определяешь в параметрах функции и как ты к нему обращаешься в теле функции",,Скребцов Роман Васильевич
1601962835.075800,1602021121.086300,U01C12H494Y,"<@U01C12CA716> в качестве параметра функции я хочу использовать всю таблицу df, поэтому, я надеюсь передать ее туда через вызов функции. если я правильно понимаю, циклом мы проходим по строкам, поэтому для каждой строки запоминаем значение 11 столбца ('lemmas') и дальше находим какое значение вернуть для записи в новый 12 столбец ('purpose_id'). Подаскажи, пожалуйста, проблема в логике или технически я не до конца разобрался.
<https://pastebin.com/CXV55jSG> (исправил обращение к 11 столбцу, где записаны лемматизированные данные)",,Влад Простаков
1601962835.075800,1602024851.086500,U01BBD7KBA7,"<@U016DNMFQ21> Благодарю за ответ! 'continue' - раньше не использовал, полезная, особенно если большие массивы. С проверкой истинности напутал.
<@U0185Q2MK19> Попытался учесть объяснения, но продолжаю ходить вокруг да около. Как я понимаю т.к. в обоих вариантах в ячейки новых столбцов теперь записываются - одинаковые значения, моя ошибка - именно в присвоении нового значения ячейкам столбца.  Пробовал и просто через ""=="", и через ""return"".  Судя по всему присвоение идет сразу всему столбцу. Код прикрепил: <https://pastebin.com/a7maqnD5>",,Влад Иванов
1601892195.066800,1602042653.086700,U0185Q2MK19,"<@U01BHCQN9D2>, привет!
Мне кажется, здесь более целесообразно было просто использовать pivot_table.
То есть просто посчитать сколько было возвратов и невозвратов в разрезе количества детей.",,Олег Булыгин
1601443993.025700,1602042919.086900,U0185Q2MK19,"<@U01BHCQN9D2>,
1. Counter позволяет просто посмотреть на распределение различных целей, чтобы вручную выбрать те группы, по которым потом проводить категоризацию. Куда-то его сохранять не вижу особого смысла, его достаточно изучить)
2. Цикл в функции не нужен, т.к. apply/map и так применяют все действия к каждому элементу. Посмотри на такой вариант:
```def purpose_category(row):
    if 'автомобиль' in row['purpose_lemmas']:
        return 'автомобиль'
    if 'свадьба' in row['purpose_lemmas']:
        return 'свадьба'
    ....
    ....
df.apply(purpose_category, axis = 1)```
",,Олег Булыгин
1601443993.025700,1602043615.087100,U0185Q2MK19,"<@U01C12CA716>, <@U01C12EGBU0>, можно попробовать ускорить процесс при помощи кеширования: <https://stackoverflow.com/questions/16181419/is-it-possible-to-speed-up-wordnet-lemmatizer>

И еще нашел вот такие рекомендации: <https://habr.com/ru/post/503420/>",,Олег Булыгин
1601962835.075800,1602043735.087400,U0185Q2MK19,"<@U01C12H494Y>, привет!

Посмотри, здесь уже давал аналогичную рекомендацию по этому действию: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1602042919086900?thread_ts=1601443993.025700&amp;cid=G01BPGP5A73>

<@U01BBD7KBA7>, аналогичная рекомендация :slightly_smiling_face:

Отпишитесь о результатах",,Олег Булыгин
1601962835.075800,1602044071.088200,U01C12H494Y,<@U0185Q2MK19> спасибо! все получилось,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Простаков
1602056746.088800,1602056746.088800,U01AWESS539,Категоризация по доходу,,Мария Кузнецова
1602056746.088800,1602057111.088900,U01AWESS539,"<@U0185Q2MK19> Привет! Подскажи, пожалуйста, когда мы создаем категории по доходу, на основе чего мы решаем какое количество категорий будет определяться. Как можно логически обосновать количество категорий в данном случае, учитывая, что у нас нет данных в каких единицах измерения указан годовой доход и в какой стране, чтобы, например отталкиваться от уровня жизни. И второй вопрос корректно ли в данном случае будет использовать функцию qcut? С одной стороны у нас будет достаточно наблюдений в каждой категории, а с другой промежутки выходят немного странные - у них большой разбег, например (20666.999, 98554.0] .",,Мария Кузнецова
1601443993.025700,1602066983.089100,U01BPRJJN2V,"<@U01C12CA716>, <@U01C12EGBU0> была та же проблема. Кеширование помогло. Отработало за 20 секунд. Спасибо <@U0185Q2MK19> за рекомендацию! <https://pastebin.com/0tNrGjD8>","[{'name': '+1', 'users': ['U01C12EGBU0'], 'count': 1}]",Александр Шалапанов
1601443993.025700,1602067146.089300,U01C12CA716,"<@U01BPRJJN2V>, хм... я попробовал быстро, словил ошибку при установке, что поддерживается только 2,7 python. У тебя какая версия?",,Скребцов Роман Васильевич
1601443993.025700,1602067295.089500,U01BPRJJN2V,"<@U01C12CA716>, странно.. У меня 3.7.",,Александр Шалапанов
1601443993.025700,1602067398.089700,U01C12CA716,"<@U01BPRJJN2V>, в любом случае спасибо! Проект я уже отправил на проверку, но вопрос с производительностью еще буду решать, но чуть позже =)",,Скребцов Роман Васильевич
1602056746.088800,1602067505.089900,U01BBD67YSX,"Привет! Я делила доход по квантилям, которые можно вывести, используя метод describe().",,Наталия Шельянова
1602056746.088800,1602069786.090300,U01BBD72X1R,"<@U01AWESS539> раздели функцией quantile([0.25,0.5,0.75]) и в фукнции делай обращение на прямую к квантилю",,Артем Провороцкий
1601443993.025700,1602070193.090500,U01C12CA716,"Разобрался. Я хотел использовать functools32, а не functools. Кеширование помогло! Спасибо <@U01BPRJJN2V>, <@U0185Q2MK19>","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Скребцов Роман Васильевич
1602056746.088800,1602071662.090800,U0185Q2MK19,"<@U01AWESS539>, на какие категории разделить доход - в этом вопросе нет единственно правильного ответа. Вариант, подсказанных коллегами выше - весьма неплохой :)",,Олег Булыгин
1601485322.029300,1602075948.091100,U01BHCQN9D2,"<@U0185Q2MK19> , добрый день! Посмотрите, пожалуйста, что не так? Я хочу создать новый столбец, где бы каждой цели была присвоена своя категория? <https://pastebin.com/fagNJCu6>",,Ксения Идрисова
1601443993.025700,1602076171.091400,U01C12EGBU0,"<@U01BPRJJN2V> <@U0185Q2MK19> Попробовал кэширование, отлично работает, спасибо! Очень элегантное решение получилось, отдельно спасибо за LRU Cache.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Ильин
1601485322.029300,1602131528.091800,U0185Q2MK19,"<@U01BHCQN9D2>, привет!
Все верно, за исключением того, что apply надо применять к датафрейму, а не к Series. Т.е. `df.apply(purpose_category, axis = 1)`",,Олег Булыгин
1601925042.073600,1602133083.092000,U0185Q2MK19,"<@U01C12H494Y>, не совсем понимаю вопрос. Что значить ""только необходимые""?
Данный способ заменяет все пропуски в столбце на среднее в разрезе указанной категории/нескольких категорий.
А если надо заменить пропуски только в одной категорий, а во все остальных оставить (зачем?), то можно просто сделать присвоение с логическим отбором при помощи loc. Уточни свою идею",,Олег Булыгин
1601925042.073600,1602136296.092300,U01C12H494Y,"<@U0185Q2MK19> я наверно не совсем понимаю как работает df['total_income'] = df['total_income'].fillna(df.groupby('education')['total_income'].transform('median')), что значит в разрезе категории?
по идее должны заполниться пропуски в столбце total_income, только для которых заполнен столбец education? или по какому принципу они заполняются в указанном случае?",,Влад Простаков
1601904244.070800,1602144938.093200,U01BBD743QB,"<@U0185Q2MK19>, еще один вопрос про сортировку.
Я делала сводные таблицы в проекте при помощи groupby, но ревьюер попросила добавить сводные таблицы типа pivot.
Вот код и он вроде работает: df.pivot_table(index='family_status', values='debt', aggfunc= ['count', 'sum','mean']), но я что-то не могу сообразить как теперь отсортировать по 'mean'. Метод sort_values(by = 'mean', ascending = False) не работает",,Айнур Мусаева
1601897352.068300,1602149166.093400,U01BBD743QB,"<@U01C12EGBU0>, вы нашли ответ на свой запрос? мне ревьюер написала в качестве пожелания к проекту, что хорошо бы сделать оглавление. если Вы нашли удобный способ, то поделитесь, пожалуйста",,Айнур Мусаева
1601897352.068300,1602149369.093600,U01C12EGBU0,"Привет! Я добавил оглавление вручную и сдал проект, но на будущее решил сразу делать оглавление, а потом заполнять разделы, так можно сэкономить время. Автоматизацию создания оглавления по уже отмеченным заголовкам я не успел ещё посмотреть.",,Сергей Ильин
1602151264.094100,1602151264.094100,U01BBD743QB,Создание легенды для графика,,Айнур Мусаева
1602151264.094100,1602151359.094200,U01BBD743QB,"<@U0185Q2MK19>, подскажи, пожалуйста, как нанести на график наименование осей и заголовок? График сторю так:
df.groupby('income_group')['debt'].mean().plot(kind='bar')",,Айнур Мусаева
1601897352.068300,1602151538.094400,U01BBD743QB,"<@U01C12EGBU0>, то есть вынес названия разделов в начало и сделал их гиперссылками?",,Айнур Мусаева
1601897352.068300,1602151608.094600,U01C12EGBU0,"Да, примерно. Вручную прошел по заголовкам, создал якори в них, назвал, вернулся в оглавление и добавил нужный.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Ильин
1601962835.075800,1602156539.094800,U01BBD7KBA7,<@U0185Q2MK19>  Спасибо! Получилось по рекомендации сделать!,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Иванов
1601925042.073600,1602157793.095000,U0185Q2MK19,"<@U01C12H494Y>, немного не так :slightly_smiling_face:
Данный способ заменяет абсолютно все пропуски в столбце. Но заменяет их не одинаковой средним/модой/медианой, рассчитанной по всему столбцу, а разными в разрезе каких-либо категорий.
Т.е. пропущенный доход студентов заполнится не медианным доходом по всем людям, а медианным доходом других студентов (у которых указан доход). Медианный доход безработных заменится на опять же доход безработных.
Это более корректный метод заполнения. Можно делать группировку даже не по одному признаку, а по любому количеству.","[{'name': '+1', 'users': ['U01BBD7KBA7'], 'count': 1}]",Олег Булыгин
1601904244.070800,1602157935.095200,U0185Q2MK19,"<@U01BBD743QB>, когда у нас получается мультииндекс, то нужно указать оба в круглых скобках. У тебя, подозреваю, будет примерно так:

```df.pivot_table(index='family_status', values='debt', aggfunc= ['count', 'sum','mean']).sort_values(('mean','debt'))```
Проверь, пожалуйста :slightly_smiling_face:",,Олег Булыгин
1602151264.094100,1602158852.095600,U0185Q2MK19,"<@U01BBD743QB>,
в метод plot можно передать дополнительные аргументы:
```title='Заголовок',
xlabel='Подпись по Х',
ylabel='Подпись по Y'```",,Олег Булыгин
1601443993.025700,1602160176.096500,U01BHCNGGAY,"<@U0185Q2MK19>   Добрый день, нужна помощь. При подсчёте числа слов в тексте с помощью Counter получаю ошибку: ""TypeError: unhashable type: 'list'"", что я делаю не так? <https://pastebin.com/FkwUe1z0>",,Dmitriy Shatalov
1602151264.094100,1602160392.096700,U01BBD743QB,"<@U0185Q2MK19> все равно не работает, точнее заголовок добавился, а вот оси никак не хотят

df.groupby('income_group')['debt'].mean().plot(kind='bar', title='ДОХОД ЗАЁМЩИКА_ДОЛЯ ДОЛЖНИКОВ', xlabel = 'доход заемщика', ylabel = 'доля должников по кредиту')",,Айнур Мусаева
1601904244.070800,1602160733.096900,U01BBD743QB,"<@U0185Q2MK19>, большое спасибо! я не учла мультииндекс:confused:","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Айнур Мусаева
1601897352.068300,1602161692.097100,U01BBD743QB,"<@U01C12EGBU0>, я нашла инструкцию, как делать якорь. Выглядит несложно и я вроде все делаю по инструкции, но не выходит каменный цветок:confused:

Может быть, ты можешь поделиться кусочком кода, пожалуйста? Что именно ты пишешь в строке заголовка и в соответствующей строке оглавления?",,Айнур Мусаева
1601897352.068300,1602162002.097300,U01C12EGBU0,"<@U01BBD743QB> да, в оглавлении такая ссылка
[Открытие данных](#step1)
А в заголовке
&lt;a id=""step1""&gt;&lt;/a&gt;
 ### Шаг 1. Откройте файл с данными и изучите общую информацию.","[{'name': '+1', 'users': ['U01BHCQS2RJ'], 'count': 1}]",Сергей Ильин
1601897352.068300,1602162751.098100,U01BBD743QB,"<@U01C12EGBU0> блин, работает! спасибище!",,Айнур Мусаева
1601925042.073600,1602174653.099800,U01C12H494Y,<@U0185Q2MK19> спасибо! теперь понятно,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Простаков
1601443993.025700,1602175975.102600,U01B4EYP47Q,"<@U0185Q2MK19> Добрый вечер! Подскажите , пожалуйста. Начитался Ваших советов, но столбец не обновляется в df. Скорее всего я что-то не понял, но понять бы что...

<https://pastebin.com/ThfHKdrz|https://pastebin.com/ThfHKdrz>","[{'name': 'eyes', 'users': ['U01B84FM5KP'], 'count': 1}]",Антон Бахилин
1602177578.104000,1602177578.104000,U01B84FNBPX,Формат вывода при использовании groupby,"[{'name': 'white_check_mark', 'users': ['U01B84FNBPX'], 'count': 1}]",Валентина Тушкова
1602177578.104000,1602177733.104100,U01B84FNBPX,"Подскажите, почему у меня при применении groupby и последовательно value_counts() так некрасиво выглядит результат?:flushed: Как можно сделать столбцы ровными? Скриншот: <http://joxi.ru/vAWE6njcORzeDm>",,Валентина Тушкова
1602177578.104000,1602182791.104500,U01B84FNBPX,"Сделала сводную табличку с теми же данными, выглядит получше: <http://joxi.ru/ZrJx8Mvink89k2>
Но все-таки интересно, почему groupby получился такой кривой:nerd_face:",,Валентина Тушкова
1602177578.104000,1602188749.107100,U01AWENSUVD,"<@U01B84FNBPX> покажи, пожалуйста, как ты сделала такую табличку)",,Юлия Мальцева
1602190851.108700,1602190851.108700,U01AWENSUVD,Заполнение пропусков с условием,,Юлия Мальцева
1602190851.108700,1602190942.108800,U01AWENSUVD,"Привет, <@U0185Q2MK19>! Нужна помощь. Возможно, я упала в кроличью нору, пытаясь решить несложную задачу (и стремненько задавать вопрос из начала проекта), но возникла следующая проблема:

Я приняла решение заполнять пропуски в total_income, рассортировав значения этого столбца по типу дохода income_type.
Создала переменную, значением которой хочу заполнить пропуски в столбце total_income, где income_type == ‘предприниматель’. Попыталась заполнить эти пропуски. Однако код не заменяет пропуски, и я не понимаю почему, ведь я работаю не с копией датафрейма. А если с копией, то я не понимаю, почему :(

Код: <https://pastebin.com/Jb9EwWsQ>
Ошибка: <http://joxi.ru/GrqndjVcGdpZlm>",,Юлия Мальцева
1602177578.104000,1602191115.109200,U01B84FNBPX,"<@U01AWENSUVD> поделила всех на группы по размеру дохода и запилила сводную таблицу по группам и типу занятости,
вот <https://pastebin.com/pP3eDfNK>",,Валентина Тушкова
1602190851.108700,1602191529.109400,U01B84FNBPX,"Тоже с таким столкнулась. У меня вышел такой же SettingWithCopyWarning, но значения все равно посчитались :thinking_face:",,Валентина Тушкова
1602190851.108700,1602191899.109600,U01B4EYLV2A,"<@U01AWENSUVD> Сегодня писал сюда на эту же тему.) Как оказалось, лаконичное решение уже обсудили здесь: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1601925042073600>",,Сергей Пивоваров
1601443993.025700,1602224146.109900,U0185Q2MK19,"<@U01BHCNGGAY>, для корректной работы этой функции в столбце должны быть строки, а не списки.
Можно вот так: `Counter(m.lemmatize(' '.join(df['purpose'])))`",,Олег Булыгин
1601443993.025700,1602224223.110100,U0185Q2MK19,"<@U01B4EYP47Q>, точно не забываешь записать эти данные в новый столбец?
То есть действие то делается, но ты его не сохраняешь:
`df['loan_category'] = df.apply(purpose_category, axis = 1)`","[{'name': 'cattyping', 'users': ['U01B4EYP47Q'], 'count': 1}]",Олег Булыгин
1602151264.094100,1602224290.110300,U0185Q2MK19,"<@U01BBD743QB>, нужно тогда посмотреть на результат (на ту ошибку, которая появляется). Можно скриншот?",,Олег Булыгин
1602190851.108700,1602224463.110700,U0185Q2MK19,"<@U01AWENSUVD>, Сергей выше дает хорошую рекомендацию)
Попробуйте заполнять пропуски через transform.
А подробнее про ошибку можно почитать здесь: <https://www.dataquest.io/blog/settingwithcopywarning/>

Напишите, получилось ли в итоге :slightly_smiling_face:",,Олег Булыгин
1602177578.104000,1602224867.111000,U0185Q2MK19,"В целом value_counts в связки с groupby не применяется. value_counts это не агрегирующая функция (как sum, min, max, count и пр. Они возвращают *одно* число по группе).
Нужно использовать другие инструменты (в зависимости от задачи).","[{'name': '+1', 'users': ['U01B84FNBPX', 'U01B4EZUE4E'], 'count': 2}]",Олег Булыгин
1601443993.025700,1602224891.111300,U01B84FM5KP,"<@U0185Q2MK19> Добрый день! Подскажите, такая же проблема как у <@U01B4EYP47Q>, в новый столбец сохраняю и в новом столбце все значения None",,Денис Стариченко
1601443993.025700,1602225075.111700,U0185Q2MK19,"<@U01B84FM5KP>, нужно посмотреть на результат и на содержимое столбца lemmas перед этим действием. Пришли, пожалуйста, код/скриншот",,Олег Булыгин
1601443993.025700,1602225335.111900,U01B84FM5KP,<@U0185Q2MK19> ссылка на скриншот <https://yadi.sk/i/du1FthSQiK5qpA>,,Денис Стариченко
1601443993.025700,1602225472.112100,U0185Q2MK19,"<@U01B84FM5KP>, проблема понятна :slightly_smiling_face:
Ты проверяешь вхождение строк в список. Ни в одном из этом списков нет строки ""жил"" и прочих других. Нужно проверять именно на вхождение конкретных слов в списке (""жилье""), либо соединить списки в строки при помощи join и тогда уже будет проверяться наличие подстроки в строке и все сработает.",,Олег Булыгин
1601443993.025700,1602227215.112300,U01B84FM5KP,"<@U0185Q2MK19> спасибо, помогло","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Денис Стариченко
1602151264.094100,1602227641.112600,U01B4F2HH3Q,"Была аналогичная проблема. Решил с помощью set_xlabel и set_ylabel. Названия осей не передавались как параметр. Точнее, если писать не xlabel = '...', а x = '...', то ошибки нет, но и названий на графике тоже.
Ревьювер сказал, что это из-за версии пандас в юпитерхабе.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Лазарев Александр
1602151264.094100,1602228369.113100,U01BBD743QB,"<@U0185Q2MK19>, дело обстоит именно так, как описал Александр.
просто  x = '...' не дает никакого результата, хотя на вебинаре в прошлую субботу Глеб Михайлов делал именно так и все работало :disappointed_relieved: А xlabel = '...' выдает ошибку. Попробовала способ set_xlabel и тоже получила ошибку. Ошибка выглядит так (тут начало и конец окна ошибки)
<http://joxi.ru/DmBKWapfzX7O02>
<http://joxi.ru/YmElROEHJnRl4r>
При этом если передавать только 'title', то все ок и заголовок графика появляется на положенном месте. То есть дело в осях.
<http://joxi.ru/eAO8pJVcpyBgVr>
Честно говоря, уже думаю убрать график вообще. Его смысловая нагрузка невелика. Но понять, в чем дело, хотелось бы",,Айнур Мусаева
1602151264.094100,1602228571.113400,U0185Q2MK19,"<@U01BBD743QB>, да, это связано с не самой актуальной версии pandas на сервисе.
Надо поступить так: сохраняем визуализацию в переменную (например, ax).
Потом к этой переменной применяем функции:
```ax.set_ylabel('1111')
ax.set_xlabel('22222')```
Так должно все работать (нужен импорт matplotlib чтобы был еще)",,Олег Булыгин
1602151264.094100,1602228884.113700,U01BBD743QB,"<@U0185Q2MK19> что такое сохраняем визуализацию? имеешь в виду сохранить в переменной тот кусок, который работает (.plot(title=, kind=))?
и что значит импорт matplotlib? (сорри, но я вообще новичок)
upd: ВСЕ ПОЛУЧИЛОСЬ! СПАСИБО!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Айнур Мусаева
1602243759.115300,1602243759.115300,U01C12HNA1E,"Приветствую всех. Кто знает почему не срабатывает:
```&lt;div class=""alert alert-block alert-info""&gt;
&lt;b&gt;Tip:&lt;/b&gt; Use blue boxes (alert-info) for tips and notes. 
If it's a note, you don't have to include the word ""Note"".
&lt;/div&gt;```
Пишет
```File ""&lt;ipython-input-10-ff882bad48a4&gt;"", line 1
    &lt;div class=""alert alert-block alert-info""&gt;
    ^
SyntaxError: invalid syntax```
",,Владимир Ефимищев
1602243759.115300,1602245830.115400,U0185Q2MK19,"Привет!

Точно не забыл поменять тип ячейки с Code на Markdown?",,Олег Булыгин
1602243759.115300,1602246693.115600,U01C12HNA1E,"<@U0185Q2MK19> благодарю, не подумал об этом :disappointed:
именно так и заработало!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1602190851.108700,1602269830.116200,U01AWENSUVD,"<@U01B4EYLV2A> <@U0185Q2MK19> Получилось, спасибо!",,Юлия Мальцева
1602310995.117000,1602310995.117000,U01AWESS539,Преобразование некорректных значений,,Мария Кузнецова
1602310995.117000,1602311415.117100,U01AWESS539,"<@U0185Q2MK19> Подскажи, пожалуйста, каким способом можно заменить значения в days_employed, которые превосходят возраст клиента, например, 340266 дней, что составляет 932 года. Возможен ли такой вариант: сначала создать новый датафрейм, где подобные значения будут исключены, рассчитать для него медианное значение стажа по возрасту, и потом в первоначальном датафрейме заменить некорректные значения на рассчитанные медианные? Есть ли еще какие-нибудь способы решить эту проблему?",,Мария Кузнецова
1602310995.117000,1602315355.117300,U0185Q2MK19,"<@U01AWESS539> , тут не единственно правильного варианта :slightly_smiling_face:
Но я бы предложил рассмотреть гипотезу, что для этих людей стаж хранится в часах, а не в днях. Если после этого получатся адекватные значения, то можно произвести соответствующую замену.

Твой вариант тоже допустим - только технически я бы предложил его делать немного иначе: заменить все аномальные значения на NaN,  а потом сделать импутацию на медианные в разрезе каких-либо других показателей.",,Олег Булыгин
1602310995.117000,1602315758.117600,U01AWESS539,Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Мария Кузнецова
1602352759.120700,1602352759.120700,U01B4EXA6S2,"Вообще запутался. Сделал новую колонку с лемматизацией из целей. Сейчас хочу чтобы посчитались самые популярные слова через counter. Я вообще не то делаю или то, но не правильно? Когда пытаюсь выполнить counter выдает такую ошибку : unhashable type: 'list' <https://pastebin.com/J5AFCVxW>",,Александр Сурков
1602352759.120700,1602353272.120900,U01B4EXA6S2,<@U0185Q2MK19> помоги)),,Александр Сурков
1602352759.120700,1602354114.121300,U01BBD743QB,"Я тоже не смогла применить каунтер к столбцу, поэтому решила лемматизировать дважды. После того, как создала столбец с леммами, я взяла столбец целей ещё раз и при помощи Join соединила их все как бы в один большой текст. И этот текст ещё раз лемматизировала. Получился список лемм и с ним каунтер отлично сработал",,Айнур Мусаева
1602352759.120700,1602354362.123500,U01B4EXA6S2,"<@U01BBD743QB> привет. Спасибо за совет. Буду пробовать, как ты. Ну и конечно хотелось бы узнать в чем именно ошибка. ",,Александр Сурков
1602364464.126200,1602364464.126200,U01BHCQS2RJ,"<@U0185Q2MK19> Здравствуйте, не понимаю, что делать в разделе ""Категоризация данных"", сводные таблицы?",,Александр Афанасьев
1602352759.120700,1602398040.126300,U0185Q2MK19,"<@U01B4EXA6S2>, привет!

Айнур тут права. Counter технически применяется к набору *строк.*
У тебя после лемматизации получается набор *списков*. Их надо обратно преобразовать в строки для корректной работы Counter.
Т.е. можно сделать так: `Counter(m.lemmatize(''.join(df.purpose)))`",,Олег Булыгин
1602352759.120700,1602398328.127200,U01B4EXA6S2,<@U0185Q2MK19>  а просто изменить тип на str нельзя?,,Александр Сурков
1602364464.126200,1602398457.127400,U0185Q2MK19,"<@U01BHCQS2RJ>, привет!

Нужно добавить столбцы для категорий по нужным признакам.
Абсолютно точно будут категории целей кредита, разумно будет разделить доход людей на категории (условно низкий/средний/высокий, можно выделить и больше), может быть стоит подумать о категоризации  по количеству детей.

Т.е. это не сводные таблицы, это именно добавления столбцов с категориями :)",,Олег Булыгин
1602352759.120700,1602398498.127600,U0185Q2MK19,"<@U01B4EXA6S2>, нет, питон не сможет просто при помощи этой функции преобразовать список в строку. Нужен именно join.",,Олег Булыгин
1602352759.120700,1602398578.128900,U01B4EXA6S2,<@U0185Q2MK19> я так и не смог найти что делает join. Можешь вкратце объяснить?,,Александр Сурков
1602352759.120700,1602398744.129100,U0185Q2MK19,"<@U01B4EXA6S2>, join объединяет элементы списка в единую строку через указанный разделитель. Например, `['первый', 'второй']`  преобразуется в `'первый,второй'`, если указать в качестве разделителя запятую или `'первый второй'`, если пробел.",,Олег Булыгин
1602352759.120700,1602398908.130000,U01B4EXA6S2,<@U0185Q2MK19> благодарю. Понял. Пока вроде получилось.,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19', 'U01B4EXA6S2'], 'count': 2}]",Александр Сурков
1602364464.126200,1602399909.130200,U01BHCQS2RJ,Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1602364464.126200,1602403050.130700,U01BHCQS2RJ,"<@U0185Q2MK19>.еще вопрос: как заменить значения в столбце ""children"", почему-то replase не получается.",,Александр Афанасьев
1602364464.126200,1602403111.131000,U0185Q2MK19,"<@U01BHCQS2RJ>, в этом столбце числа, а не строки) Кавычки вокруг -1 и 1 не нужны",,Олег Булыгин
1602364464.126200,1602403899.131200,U01BHCQS2RJ,<@U0185Q2MK19> Ура! Спасибо снова!,,Александр Афанасьев
1602364464.126200,1602410158.131400,U01BHCQS2RJ,"<@U0185Q2MK19> а, зачем категоризация по количеству детей, такой столбец существует.",,Александр Афанасьев
1602364464.126200,1602414306.131700,U0185Q2MK19,"<@U01BHCQS2RJ>, можно разделить условно на ""Без детей"", ""Малодетные"",  ""Многодетные"". Но т.к. вариативность не очень большая, то можно и не делить)
Тут нет единственно верных действий",,Олег Булыгин
1602364464.126200,1602416596.132000,U01BHCQS2RJ,:+1:Спасибо!,,Александр Афанасьев
1602352759.120700,1602416613.132200,U01B4EX8S30,"<@U0185Q2MK19> привет! я что-то в целом не могу понять, что нужно сделать в пункте с лемматизацией.
Я добавила столбец, в котором у меня цель кредита разбита на леммы:
```df['new_lemmas'] = df.purpose.map(m.lemmatize)```
А что потом нужно сделать с этими леммами? Я так думала, что это способ должен мне помочь выделить конкретные цели кредита, вместо повторяющиихся. Или я что-то не так поняла?",,Виктория Барсукова
1602419138.134100,1602419138.134100,U01B4EX8S30,"Коллеги, привет!
Поделитесь, пожалуйста, методом, которым после того, как выделили леммы, отбирали нужные слова, чтобы сократить список целей на кредит. Пытаюсь использовать str.split, но как-то безуспешно :white_frowning_face:",,Виктория Барсукова
1602419138.134100,1602419227.134600,U01B4EXA6S2,"Привет
Была такая же проблема

<https://yandex-students.slack.com/archives/G01BPGP5A73/p1602398040126300?thread_ts=1602352759.120700&amp;channel=G01BPGP5A73&amp;message_ts=1602398040.126300|https://yandex-students.slack.com/archives/G01BPGP5A73/p1602398040126300?thread_ts=1602352759.120700&amp;channel=G01BPGP5A73&amp;message_ts=1602398040.126300>","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1602419138.134100,1602419293.135600,U01B84FM5KP,Добрый день! Посмотрите ещё здесь <https://yandex-students.slack.com/archives/G01BPGP5A73/p1602042919086900?thread_ts=1601443993.025700&amp;cid=G01BPGP5A73>,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Денис Стариченко
1602419138.134100,1602419321.136500,U01B4EXA6S2,<@U01B4EX8S30> ты писала в моем треде свой вопрос. Вот там же и ответ. Через counter,,Александр Сурков
1602419138.134100,1602419851.136800,U01B4EX8S30,"<@U01B84FM5KP> а, то есть этот метод позволяет нам увидеть, какие категории стоит выделить, но не дает возможности сразу разделить?

<@U01B4EXA6S2> да, я оказывается неверно использовала разделитель в Counter, выводилось что-то непонятное

Спасибо большое!",,Виктория Барсукова
1602419138.134100,1602420153.137100,U01B84FM5KP,<@U01B4EX8S30> через функцию мы сами придумываем на какие категории будем делить полученные леммы,,Денис Стариченко
1602419138.134100,1602420253.139000,U01B84FM5KP,"<@U01B4EX8S30> этот вопрос ещё обсуждался здесь, надеюсь поможет",,Денис Стариченко
1602419138.134100,1602420307.140300,U01B4EXA6S2,"<@U01B4EX8S30> я не уверен, что так правильно, но применил функцию ко всему столбцу lemmas через apply и результат записал в новом столбце. Итог - новый столбец с категориями. ","[{'name': '+1', 'users': ['U01B4EX8S30'], 'count': 1}]",Александр Сурков
1602419138.134100,1602420357.140500,U01B4EX8S30,"<@U01B84FM5KP> да, поняла, спасибо, как-то пропустила этот тред","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Барсукова
1602419138.134100,1602420870.141500,U01B4EXA6S2,Сначала естественно надо написать саму функцию. ,,Александр Сурков
1602438313.142000,1602438313.142000,U01BHCNGGAY,Выделение словарей в данных,,Dmitriy Shatalov
1602438313.142000,1602438561.142100,U01BHCNGGAY,<@U0185Q2MK19> Столкнулся с проблемой при проверке проекта. Ревьюер  указал на необходимость выделения словаря в данных. Не очень понимаю как и зачем это делать с текущими данными.,,Dmitriy Shatalov
1602352759.120700,1602475310.142300,U0185Q2MK19,"<@U01B4EX8S30>, привет! После этого можно применить Counter для наглядного представления того, какие цели и как часто встречаются. Вручную выбрать основные формулировку и написать функцию для классификации (то есть каждой свободно сформулированной цели присвоить конкретную однозначную категорию) чтобы на этом можно было сделать аналитику.

Да, лемматизация поможет выделить конкретные цели, т.к. все слова приведет к одной форме и так будет проще писать функцию для класификации.","[{'name': '+1', 'users': ['U01B4EX8S30'], 'count': 1}]",Олег Булыгин
1602438313.142000,1602475747.142600,U0185Q2MK19,"<@U01BHCNGGAY>, тоже сходу не понимаю, что требуется.
Можешь кинуть скриншот комментария ревьюера и описать, как ты делал категоризацию?",,Олег Булыгин
1602438313.142000,1602487175.143100,U01BHCNGGAY,"<@U0185Q2MK19> Скриншот комментария: <http://joxi.ru/Q2KwqqouvgVob2>
Категоризацию проводил по лемматизированому столбцу с целями кредита и по столбцу с доходами разбив клиентов по квантилям.",,Dmitriy Shatalov
1602352759.120700,1602490888.143600,U01B4EX8S30,"<@U0185Q2MK19> да, спасибо большое! Коллеги подсказали, разобралась","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Виктория Барсукова
1602438313.142000,1602505680.143800,U0185Q2MK19,"<@U01BHCNGGAY>, понял, почти уверен, что ревьюер хочет, что бы ты к категориальным столбцам применил groupby или pivot_table, чтобы наглядно показать сколько уникальных значений в них есть, понять их частотность и сделать по ним какие-то значимые расчеты нужным показателей.",,Олег Булыгин
1602438313.142000,1602506028.144100,U01BHCNGGAY,"<@U0185Q2MK19> к категориальным столбцам было применено pivot_table таким образом: ""df.pivot_table(index='new_purpose', values='debt', aggfunc= ['count', 'sum','mean']).sort_values(('mean','debt'))"" и на основании сводной таблицы уже делались выводы.",,Dmitriy Shatalov
1602438313.142000,1602506520.144400,U0185Q2MK19,"<@U01BHCNGGAY>, нужно сделать примерно такой анализ. И аналогичное действие после стандартизации, чтобы показать, что данные были стандартизированы. Аналогично по другим категориям. Лично я не встречал, чтобы это называли ""словарями"", но пусть будет так)",,Олег Булыгин
1602438313.142000,1602577933.147900,U01BHCNGGAY,"<@U0185Q2MK19>  спасибо, помогло :) хотя в теории, если я правильно понял, под «словарём» предполагается немного иной функционал ",,Dmitriy Shatalov
1602438313.142000,1602578036.148100,U0185Q2MK19,"<@U01BHCNGGAY>, супер)
Я тоже так термин ""словарь"" никогда не употребляю) но у всех свое видение, в любом случае немого доп. практики хуже не сделает :slightly_smiling_face:",,Олег Булыгин
1602585538.149000,1602585538.149000,U019642V4G7,Единый формат значений в days_employed ,,Сослан Чехов
1602585538.149000,1602585620.150500,U019642V4G7,"<@U0185Q2MK19> , привет! 
Застрял на этапе приведения значений days_employed к единому формату, нужна помощь",,Сослан Чехов
1602585538.149000,1602587284.153200,U019642V4G7,"Я выяснил, что для пенсионеров время указано в часах, а для всех остальных значения отрицательные. Теперь не могу понять как перевести время пенсионеров в дни и отрицательные значения перевести в положительные",,Сослан Чехов
1602585538.149000,1602592822.153400,U01B4EZUE4E,"Привет. <@U019642V4G7> Я просто поделил данные с часами на 24 и получились дни. Отрицательные значения можно убрать умножив  их на ""-1"" или применив функцию abs(). Главное применить эти способы к нужным значениям.",,Сергей Афанасьев
1602585538.149000,1602599211.155200,U019642V4G7,"Привет, <@U01B4EZUE4E> ! Логика мне понятна, но я что-то не могу сообразить как это легко провернуть. Написать функцию с условным оператором?",,Сослан Чехов
1602585538.149000,1602600722.167300,U01B4EZUE4E,"Функция не нужна, покуда в pandas можно действия прямо надо столбцами проводить. например, df.loc[(df[‘income_type’] == ‘пенсионер’ ) | (df[‘income_type] == ‘безработный’) , ‘income_type’] = df[‘days_employed’]  / 24
Чтоб минус убрать, просто примени функцию abs() ко всему столбцу.
Пишу с телефона, возможно это нерабочий код, но принцип примерно такой. 
Удачи. <@U019642V4G7> ","[{'name': '+1', 'users': ['U019642V4G7', 'U0185Q2MK19'], 'count': 2}]",Сергей Афанасьев
1602585538.149000,1602601117.168300,U019642V4G7,"Спасибо, вспомнил урок про индексацию и сработало!","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01B4EZUE4E'], 'count': 2}]",Сослан Чехов
1602585538.149000,1602606305.169900,U019642V4G7,"Рано радовался,не сработало, значения остались прежними. <@U0185Q2MK19> , спасай)",,Сослан Чехов
1602585538.149000,1602606660.171000,U019642V4G7,"Сам фильтр корректен, но почему-то деление на 24 не срабатывает",,Сослан Чехов
1602585538.149000,1602613069.171200,U01BHCQPGDS,"<@U019642V4G7> сделай присвоение значений столбцу, например df['a'] = df['a'].abs()",,Евгений Фадеев
1602613833.172600,1602613833.172600,U01B4EXA6S2,"Подскажите пожалуйста, как ось Y преобразовать из долей в нормальные проценты? как то не додумался(",,Александр Сурков
1602613833.172600,1602614778.172800,U01B4F2HH3Q,"Вот <https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#Finer-Control:-Display-Values|вариант>, <@U01B4EXA6S2>",,Лазарев Александр
1602613833.172600,1602614864.173000,U01B4EXA6S2,<@U01B4F2HH3Q> благодарю,,Александр Сурков
1602613833.172600,1602615731.173200,U01B4EXA6S2,"<@U01B4F2HH3Q> я понимаю, что такое формат, но я не понимаю, как его применить к целой оси графика и как сделать чтобы значения перевелись не в 0.8 % а в 8%",,Александр Сурков
1602613833.172600,1602617616.173400,U01B4F2HH3Q,"<@U01B4EXA6S2>
 `vals = children_category_gf.get_yticks();`
`children_category_gf.set_yticklabels(['{:,.2%}'.format(x) for x in vals]);` после объявления названий осей. Вот <https://stackoverflow.com/questions/31357611/format-y-axis-as-percent|источник>",,Лазарев Александр
1602613833.172600,1602618489.173900,U01B4EXA6S2,<@U01B4F2HH3Q> воу как сложно. спасибо,,Александр Сурков
1602585538.149000,1602652475.174100,U0185Q2MK19,"<@U019642V4G7>, привет!
Вот это рабочий вариант:
`df.loc[(df['income_type'] == 'пенсионер') | (df['income_type'] == 'безработный') , 'days_employed'] = df['days_employed']  / 24`
В варианте выше выбран не тот столбец, поэтому и не получалось)","[{'name': '+1', 'users': ['U019642V4G7'], 'count': 1}, {'name': '100', 'users': ['U019642V4G7'], 'count': 1}, {'name': 'avocato', 'users': ['U019642V4G7'], 'count': 1}]",Олег Булыгин
1602613833.172600,1602653729.174300,U0185Q2MK19,"<@U01B4EXA6S2>, эти значения берутся же из датафрейма, на основе которого ты строишь график. Можно просто в самом датафрейме этот столбец/индекс умножить на 100)",,Олег Булыгин
1602585538.149000,1602658083.174500,U01B4EZUE4E,"<@U0185Q2MK19> ох, вот тут нужно как-то прояснить. Значит, в данном случае  в df.loc[] мы до запятой указываем  условие в строке (есть ли в столбце 'income_type' значение 'безработный' или 'пенсионер'), а после запятой указываем, что нужно изменить('days_employed') , если условие верно, а после знака равно, указываем, на что мы должны это изменить ('days_employed' / 24) ? Так? Просто немного запутанно, потому что в теориии индексация работает так: loc[строка, столбец]",,Сергей Афанасьев
1602585538.149000,1602658552.174900,U01BHCQPGDS,"<@U01B4EZUE4E> все верно, после запятой указывается столбец, в котором будут происходить изменения","[{'name': '+1', 'users': ['U01B4EZUE4E', 'U0185Q2MK19'], 'count': 2}]",Евгений Фадеев
1602613833.172600,1602658783.175200,U01B4EXA6S2,<@U01B4F2HH3Q> получилось как написал Александр.,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1602585538.149000,1602661832.175500,U0185Q2MK19,"<@U01B4EZUE4E>, да, т.е. ""по какому-условию"", ""где"", ""на что"")","[{'name': 'heavy_check_mark', 'users': ['U01B4EZUE4E'], 'count': 1}]",Олег Булыгин
1602674794.176300,1602674794.176300,U01AWESS539,Проект 2. Работа с аномальными значениями,,Мария Кузнецова
1602674794.176300,1602675121.176400,U01AWESS539,"<@U0185Q2MK19> Привет! У нас в переменной высоты потолков есть аномальные значения, например, 1 м или 100. В целом  они составляют меньше 1 процента от выборки и по сути являются выбросами. Что будет лучше: просто удалить эти наблюдения, или же заменить их на пограничные, но при этом, соответсвующие дейсвтительности, например, все значения меньше 2.5 метров заменить на 2.5 метра. Подскажи, какой вариант работы с аномальными значениями будет наиболее корректным или в принципе оба допустимы?",,Мария Кузнецова
1602674794.176300,1602677480.176700,U0185Q2MK19,"<@U01AWESS539>, привет!

Можно предположить, что с большими значениями (20+ метров) произошла ошибка на порядок и поделить на 10.
Можно их заменить на какие-то значения в разрезе других признаков (как делали с пропусками).

Ну а вообще согласно п 4.3. условия:
• Уберите редкие и выбивающиеся значения. Опишите, какие особенности обнаружили.
Так что если их не много, то можно и убрать :slightly_smiling_face:",,Олег Булыгин
,1602792875.178300,U01C12HNA1E,"Доброй ночи. Может кто знает? В jupyter устанавливаю опцию pd.set_option('display.max_columns', None)
но при выводе данных столбцы всё равно выводятся по ширине экрана через обратный слэш.
что-то не так делаю?",,Владимир Ефимищев
,1602794020.178400,U01C12HNA1E,"Всем спасибо, разобрался.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1602936372.179600,1602936372.179600,U01BBD7KBA7,"Замена отдельных значений столбца согласно условию, без создания нового столбца",,Влад Иванов
1602936372.179600,1602936545.179700,U01BBD7KBA7,"<@U0185Q2MK19> Прошу помочь с, казалось бы, не очень сложным действием. Пытаюсь выполнить замену значений столбца согласно условию. Не получается. Перебор моих вариантов прикрепляю: <https://pastebin.com/AfhZsH95>
Прошу дать комментарий и натолкнуть на корректное решение! Заранее, спасибо!",,Влад Иванов
1602936372.179600,1602937799.179900,U01C12G1ZJL,"<@U01BBD7KBA7> может быть попробовать через where.
<https://pastebin.com/Xs1gKSzm> как вариант. только под свои условия",,Татьяна Волобуева
1602936372.179600,1602942306.180100,U0185Q2MK19,"<@U01BBD7KBA7>, привет!

Вот тут абсолютно аналогичная проблема (только кейс другой): <https://yandex-students.slack.com/archives/G01BPGP5A73/p1602652475174100?thread_ts=1602585538.149000&amp;cid=G01BPGP5A73>

Это то, что нужно?",,Олег Булыгин
1602936372.179600,1602944235.180400,U01BBD7KBA7,"<@U01C12G1ZJL> <@U0185Q2MK19>, Благодарю!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Иванов
1602936372.179600,1602944394.180600,U01C12G1ZJL,:handshake:,,Татьяна Волобуева
1603028095.181400,1603028095.181400,U01AWESS539,Построение box_plot,,Мария Кузнецова
1603028095.181400,1603028301.181500,U01AWESS539,"<@U0185Q2MK19> Привет! Подскажи, в чем может ошибка при построении boxplot по переменной: я хочу посмотреть на ящик по перменной total_area, в ячейке с кодом просто прописываю ""df['total_area'].boxplot()"", но в результате получаю ошибку : 'Series' object has no attribute 'boxplot'",,Мария Кузнецова
1603028095.181400,1603031268.181700,U01C12EGBU0,"Привет! <@U01AWESS539> Метод применяется к датафрейму. В параметрах метода есть column, где можно указать конкретный столбец, у меня так получалось.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Ильин
1603028095.181400,1603034929.181900,U01AWESS539,<@U01C12EGBU0> Спасибо! все получилось),,Мария Кузнецова
1603040358.182900,1603040358.182900,U01806NPJE7,График по сводной,,Илья Михайлов
1603040358.182900,1603040492.183000,U01806NPJE7,"<@U0185Q2MK19> привет. Изучаю зависимость цены от дня недели. Построил график по сводной, но не смог изменить размерность. Подскажи, пожалуйста, что я не так написал и как изменить размерность в этом случае? Вот код, который выдает ошибку <https://pastebin.com/kYdZ7199> . При этом если убираю range, то все работает. И в целом я вообще в нужно направлении?",,Илья Михайлов
1603040358.182900,1603083407.183500,U0185Q2MK19,"<@U01806NPJE7>, привет!

Параметра range у функции plot нету. Надо бы понять, что ты вообще хотел им получить :slightly_smiling_face:
Может путаешь с таким вариантом: `data_group.plot(kind='bar').set_ylim(0,9000000)` ?
И я бы тут применил не столбчатую диаграмму, а построил бы боксплоты по дням недели.",,Олег Булыгин
1602585538.149000,1603089462.184100,U01C12H494Y,"<@U0185Q2MK19> способом описанным выше получилось разделить на 10 необходимые значения
df.loc[((df['ceiling_height'] &gt; 20) &amp; (df['ceiling_height'] &lt; 40) , 'ceiling_height')] = df['ceiling_height']  / 10
но в последствии появляется warning:
```SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.```
подскажи, пожалуйста, по какой причине он появляется, как избежать этого?",,Влад Простаков
1602585538.149000,1603090195.184300,U01B4EZUE4E,"<@U0185Q2MK19> В догонку вопрос. Мы легко заполняем отсутствующее значение в одном столбце на значение другого или даже выполняем над ними действия. Тогда почему не работает вот такое:
`df.loc[df['floors_total'].isnull(), 'floors_total'] = np.random.randint(df['floor'], 29)`
Мы ставим условие, и если значение отсутствует, то мы хотим получить случайное значение в диапазоне от фактического этажа, до числа 29.
Выдает ошибку: ValueError: low &gt;= high

При этом я абсолютно уверен что в строках с отсутствующим значением точно нет этажа выше 24, а значит 24 не может быть больше или равно 29. nm.random.randint получается берет этаж не из этой строки , а из всех строк по порядку или что? Потому что если ставишь максимальное значение, например 100, все работает.",,Сергей Афанасьев
1603157951.187200,1603157951.187200,U01C12H494Y,Изменение типа данных в столбце на bool,"[{'name': 'heavy_check_mark', 'users': ['U01C12H494Y'], 'count': 1}]",Влад Простаков
1603157951.187200,1603158142.187300,U01C12H494Y,"<@U0185Q2MK19> подскажи, пожалуйста, как сделать так, чтобы тип данных изменился корректно?
у меня получился столбец is_apartment полностью заполненый данными False, True, но имеет тип float. При использовании astype, тип данных меняется, но значения присваиваются неверные.",,Влад Простаков
1602585538.149000,1603167504.187500,U0185Q2MK19,"<@U01C12H494Y>, привет!

Это предупреждение, не ошибка. Про нее можно почитать здесь:
<https://www.dataquest.io/blog/settingwithcopywarning/>
<https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas>

Просто из-за указанной строки она возникать не должна. Скорее всего в коде дальше используются `[ ]` для переназначения элементов внутри датафрейма, лучше это заменить на loc.","[{'name': '+1', 'users': ['U01C12H494Y'], 'count': 1}]",Олег Булыгин
1602585538.149000,1603167640.187800,U0185Q2MK19,"<@U01B4EZUE4E>, в правой части твоей строки питон никак не догадается, что нам нужно значение конкретной строки) мы явно указываем, что надо рассматривать весь столбец.
К сожалению, так просто такие действия не сделать)","[{'name': 'disappointed', 'users': ['U01B4EZUE4E'], 'count': 1}]",Олег Булыгин
1603157951.187200,1603168484.188100,U0185Q2MK19,"<@U01C12H494Y>, надо бы посмотреть код, не понимаю, как при всех True/False тип может быть float.

Что будет если попробуешь преобразовать их в 1 и 0? Например, так:
```df['is_apartment'] = df['is_apartment'].map({True: 1, False: 0})```
",,Олег Булыгин
1603157951.187200,1603170463.188300,U01C12H494Y,"<@U0185Q2MK19> в этом столбце много пропусков, которые я решил заменить на 'False' и потом хотел изменить тип данных  на bool. В предыдущем посте неправильно написал, тип был object.
Попробовал сделать вот так, вроде бы получилось <https://pastebin.com/uH7MJmb9>
Можно так оставить, или слишком много всего намешано?",,Влад Простаков
1603157951.187200,1603170585.188500,U0185Q2MK19,"<@U01C12H494Y>, немного переусложнено, но допустимо. Я бы в таком случае просто заменил пропуски на 0 (не апартаменты), а True на 1. Это 2 строки кода)",,Олег Булыгин
1603157951.187200,1603174302.188800,U01C12H494Y,<@U0185Q2MK19> спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Простаков
1603179483.191800,1603179483.191800,U01BBD67YSX,"<@U0185Q2MK19> подскажи, пожалуйста, я вывела топ-10 населенных пунктов с наибольшим кол-вом объявлений.
data['locality_name'].value_counts().head(10)
Как добавить в эту таблицу столбец со средней ценой за метр (он уже посчитан)?",,Наталия Шельянова
1603194903.192200,1603194903.192200,U01BBD743QB,Редкие и выбивающиеся значения,,Айнур Мусаева
1603194903.192200,1603195131.192300,U01BBD743QB,"<@U0185Q2MK19>, добрый день! внеси, пожалуйста, ясность в задание. Предположим, я построю boxplot для разных столбцов: площадь, цена, высота потолков и тп (кстати, есть ли какой-то принцип для определения того, по каким столбцам стоит строить boxplot).

Дальше мне нужно очистить данные от всех редких значений? то есть сделать такой срез, чтобы значения всех столбцов во всех строках не выбивались?
и дальше уже делать задания на основе этого нового датафрейма?
или я упрощаю и нужно делать что-то более изысканное?",,Айнур Мусаева
1603179483.191800,1603198600.193200,U0185Q2MK19,"Мне кажется, надо немного изменить подход.

Для решения такой задачи идеально подойдет groupby. Группируем данные по населенным пунктам и применяем агрегирующие функции к нужным столбцам (mean для расчета средней площади и count для подсчета количество строк).

Попробуй так, напиши, получилось ли)",,Олег Булыгин
1603194903.192200,1603198943.193400,U0185Q2MK19,"В целом ты все описываешь верно.

Нужно:
1. найти выбросы в столбцах
2. предположить, почему они могли возникнуть
3. принять решения, что с ними делать
Удаления выбросов - не единственный путь.
Иногда их стоит заменить (например, если мы видим, что это явная ошибка и знаем, как ее исправить).
Иногда их стоит оставить (если выбросы ""естественные"" - это реальные наблюдения, которые нас самом деле сильно отличаются от остальных).

То есть плюсом к твоим действиям еще нужно подумать и убедить ревьюера, что ты делаешь правильно)

Боксплоты можно строить ко всем столбцам с числовыми значениями, распределение которых мы хотим изучить (в т.ч. для поиска аномалий).","[{'name': '+1', 'users': ['U01BBD743QB'], 'count': 1}]",Олег Булыгин
1603179483.191800,1603200745.193600,U01BBD67YSX,"<@U0185Q2MK19>, спасибо, получилось! Правда, строка кода получилась длинная: groupby, agg, sort_values, head.",,Наталия Шельянова
1603224875.197200,1603224875.197200,U01C12HNA1E,"<@U0185Q2MK19> при печати боксплота  df.boxplot('price_per_meter', by='floor_status', figsize=(10,10)) - он строится :)
но выходит сообщение
```/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)```
понимаю что типы колонок у меня разные, но как это  исправить - непонятно.",,Владимир Ефимищев
1603179483.191800,1603262165.197300,U0185Q2MK19,"<@U01BBD67YSX>, отлично) это норм, не такая уж и длинная, к такому стоит привыкать)",,Олег Булыгин
1603224875.197200,1603266165.197500,U0185Q2MK19,"Это не ошибка, а предупреждение, т.е. все будет работать как надо.
Его вроде пофиксили в последних версиях matplotlib. На сервисе стоит не последняя версия, поэтому так)

Если все работает как надо - не обращай внимания. Можно отключить вывод этого предупреждения командой
```np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) ```",,Олег Булыгин
1603194903.192200,1603267006.197800,U01BBD743QB,"<@U0185Q2MK19> , спасибо! я попыталась действовать в описанной тобой логике.
нашла в столбце ""высота потолка"" скопление на уровне 24-28 м., предположила, что это ошибка в 10 раз и попыталась исправить ее методом where. похоже, я что-то не так сделала, потому что в итоге у меня все высоты поделились на 10:rolling_on_the_floor_laughing:
подскажи, пожалуйста, в чем я не права?
<https://pastebin.com/dRtBetKU>

спасибо!",,Айнур Мусаева
1603194903.192200,1603267338.198000,U0185Q2MK19,"<@U01BBD743QB>, вот тут я на другом кейсе показывал, как изменить значения по условию при помощи loc:

<https://yandex-students.slack.com/archives/G01BPGP5A73/p1602652475174100?thread_ts=1602585538.149000&amp;cid=G01BPGP5A73>

Попробуй по аналогии, если не получится - пиши, пришлю код в явном виде)",,Олег Булыгин
1603224875.197200,1603281326.198300,U01C12HNA1E,"Да, работает как надо. Вечером отключю вывод. Спасибо.",,Владимир Ефимищев
1603301339.198800,1603301339.198800,U01AWENSUVD,*Заполнение пропусков*,,Юлия Мальцева
1603301339.198800,1603301378.198900,U01AWENSUVD,"Привет,<@U0185Q2MK19> и коллеги!
Не совсем понятно по условию – есть пропуски, которые логично заменить на другие значения. Далее по условию «Для других типов данных нет подходящего значения на замену. В этом случае правильно оставить эти значения пустыми. Отсутствие значения — тоже важный сигнал, который не нужно прятать» – значит ли это, что можно оставить пропуски там, где замена неуместна, и работать с данными в таком виде?

Если нет, и нужно, чтобы все пропуски были заменены, возникает следующий вопрос – как заменить пропуски в колонках locality_name и ceiling_height? Не понимаю, за какую зависимость можно зацепиться в этих случаях.",,Юлия Мальцева
1603304098.199400,1603304098.199400,U01BHCNGGAY,"пропуски в ""kitchen_area""",,Dmitriy Shatalov
1603304098.199400,1603304237.199500,U01BHCNGGAY,"<@U0185Q2MK19> , нужна помощь, пытаюсь написать код для замены пропусков в столбце 'kitchen_area', но не выходит. Логика следующая:
- нахожу долю кухонной площади от общей
- группирую по кол-ву комнат и доле кухонной площади от общей, и нахожу медианной значение
- пытаюсь написать код который бы в зависимости от кол-ва комнат заменял бы пропущенное значение на медианную долю умноженную на общую площадь, но не получается. <https://pastebin.com/ESdy2ks5>",,Dmitriy Shatalov
,1603313263.199700,U01C12HNA1E,заработало!,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1603301339.198800,1603317431.199800,U01BBD72X1R,"<@U01AWENSUVD> Доброй ночи :slightly_smiling_face:
В высоте потолков я пропуски заменил на 0 и потом всеравно убирал выбросы и эти значения не попали в выборку.
Пропусков в названии города всего 0,21% от них проще избавиться, они не повлияют на анализ.
Но может коллеги, что-то лучше подскажут :slightly_smiling_face: Удачи",,Артем Провороцкий
1603301339.198800,1603341658.200000,U0185Q2MK19,"<@U01AWENSUVD>, оставить пропуски тоже может быть верным решением, главное это обосновать :slightly_smiling_face:
Артем говорит правильно, пропуски в городах можно вообще убрать, т.к. непонятно как анализировать квартиры, которые даже не понятно, где находятся. Тем более пропусков очень мало.

А вот высоту потолков вполне себе можно попробовать восстановить. Может быть такое, что высота потолков в среднем больше центре? Мне кажется, может :slightly_smiling_face: Это можно учесть. Может у тебя есть какие-то свои догадки по этому поводу и ты обоснуешь заполнение в разрезе каких-то других категорий.",,Олег Булыгин
1603304098.199400,1603342850.200600,U0185Q2MK19,"<@U01BHCNGGAY>,fillna тут применить не получиться, т.к. этот метод ожидает одно число, а ты передаешь Series.

Попробуй вот так:
```df.loc[(df['kitchen_area'].isna()) &amp; (df['rooms'] == 1), 'kitchen_area'] = df.loc[(df['kitchen_area'].isna()) &amp; (df['rooms'] == 1), 'total_area'] * one_room```
Аналогично для других категорий :)","[{'name': '+1', 'users': ['U01BHCNGGAY'], 'count': 1}]",Олег Булыгин
1603194903.192200,1603352223.201000,U01BBD743QB,"<@U0185Q2MK19>, так вроде бы все получилось. Большое спасибо! а не напишешь вкратце, почему метод where здесь не подходит, пожалуйста?",,Айнур Мусаева
1603194903.192200,1603367222.201300,U0185Q2MK19,"<@U01BBD743QB>,отлично)
Я не говорил, что where не подойдет) способов на самом деле очень много, можно почитать здесь: <https://pythonexamples.org/pandas-dataframe-replace-values-in-column-based-on-condition/>

Лично мне кажется loc более удобным",,Олег Булыгин
1602936372.179600,1603376626.201600,U01BHCQS2RJ,<@U0185Q2MK19> Спасибо! А можно ли решить через query()?,,Александр Афанасьев
1603304098.199400,1603385830.201800,U01AWENSUVD,"Попыталась развить эту идею, код работает, но я не совсем уверена в корректности реализации: <https://pastebin.com/rKEmNy45>
<@U0185Q2MK19> , посмотри, пожалуйста :)","[{'name': '+1', 'users': ['U01BHCNGGAY'], 'count': 1}]",Юлия Мальцева
1603301339.198800,1603385855.202000,U01AWENSUVD,<@U0185Q2MK19> <@U01BBD72X1R> благодарю!,,Юлия Мальцева
1602936372.179600,1603427182.202400,U0185Q2MK19,"<@U01BHCQS2RJ>, query предназначен именно для отбора данных по критерию. Для замены вряд ли можно корректно применить. Вот тут на разные способы можно посмотреть: <https://kanoki.org/2019/07/17/pandas-how-to-replace-values-based-on-conditions/>",,Олег Булыгин
1603304098.199400,1603427281.202700,U0185Q2MK19,"<@U01AWENSUVD>, вполне себе ок :slightly_smiling_face: если категорий много - хороший способ автоматизации","[{'name': 'conga_party_parrot', 'users': ['U01AWENSUVD'], 'count': 1}]",Олег Булыгин
1602936372.179600,1603437093.203000,U01BHCQS2RJ,<@U0185Q2MK19> Спасибо!,,Александр Афанасьев
1603442145.203700,1603442145.203700,U01BHCQN9D2,"Добрый день, <@U0185Q2MK19>!

Помогите разобраться с категоризацией этажей. Пытаюсь написать функцию, но что-то не выходит. И вообще, с функции и циклы мне не даются, интуитивно делаю. Что можно почитать, подскажите, пожалуйста?)

<https://pastebin.com/ffEN643L>",,Ксения Идрисова
1603442145.203700,1603446380.204100,U01BBD72X1R,"Привет <@U01BHCQN9D2>

floor_category(row):
    if row['floor'] == 1:
        return 'первый'
    if row['floor'] == row['floors_total']:
        return 'последний'
    else:
        return 'другой'

Т.е. если значения в столбце floor == 1, возвращаем 'первый'.
Далее если значения в столбце floor == значениям в столбце floors_total, возвращаем 'последний.
Во всех остальных случаях возвращаем 'другой'

Потом завернем нашу написанную функцию в apply и создадим новый столбце, данный этап у тебя написан верно.

df['floor_category'] = df.apply(floor_category, axis=1)","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01B84H5TB7'], 'count': 2}]",Артем Провороцкий
1603442145.203700,1603447629.204700,U01BBD72X1R,"А еще есть такой канал на ютубе Be geek, он недавно выпустил небольшой курс по Python  с нуля и неплохо рассказывает по функции, циклы","[{'name': '+1', 'users': ['U01BHCQS2RJ'], 'count': 1}]",Артем Провороцкий
1603442145.203700,1603447730.205000,U01BHCQN9D2,<@U01BBD72X1R> Спасибо!!!,,Ксения Идрисова
1603442145.203700,1603448442.205200,U01C12EGBU0,"<@U01BHCQN9D2> Также по циклам могу порекомендовать бесплатную часть Яндекс Практикума по Python разработчик, там в тренажёре очень неплохо всему учат.","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Ильин
1603458353.210300,1603458353.210300,U01B4EXA6S2,"Про столбец locality_name. 
Привет <@U0185Q2MK19> В этом столбце есть 49 строк с пропущенной геопозицией.  То есть чисто теоретически последующие строки которые заполняются автоматически( с удаленностью от центра и озёр и тд) не могут быть заполнены, тк нет точки от которой нужно считать это расстояние. Но там есть значения. Не могу понять природу их появления в исходных данных. При чем они выглядят натурально.",,Александр Сурков
,1603459537.212000,U01AWEP1SJK,"Привет <@U0185Q2MK19>, такой вопрос - перевожу first_day_exposition в тип datetime, после кода df[df['ceiling_height']&lt;2.1] = df['ceiling_height'].median() тип автоматически переводится в object и код ломается, не подскажешь в чем может быть проблема?",,Владислав Несоленов
,1603468108.212400,U01AWEP1SJK,"все, я разобрался","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владислав Несоленов
1603469345.214800,1603469345.214800,U01BHCQS2RJ,"<@U0185Q2MK19> добрый вечер! Что делать с пропусками в столбцах ""расстояние до парков/водоемов/аэропортов"", там их огромное количество, а рзумной замены я не вижу?",,Александр Афанасьев
1603483207.218100,1603483207.218100,U01C12HNA1E,"<@U0185Q2MK19> и всем кто знает. Можно ли автоматизировать построение boxplot в цикле 'for' так, чтобы ещё и set_ylim автоматически менялся под данные столбца.",,Владимир Ефимищев
1603483207.218100,1603484980.218200,U01BBD67YSX,"<@U0185Q2MK19>, присоединяюсь к вопросу + как автоматизировать построение гистограмм.",,Наталия Шельянова
1603458353.210300,1603515949.218500,U0185Q2MK19,"Теоретически это может быть просто техническая проблема, которая привела к утере данных.

Как показывает опыт, некоторые ревьюеры не требует заполнения этих пропусков (т.к. мы не можем хоть с какой-то уверенностью восстановить эти показатели на основе других), а некоторые - требуют в тренировочных целях. Тогда стоит заполнить медианами в разрезе выбранных тобой признаков.","[{'name': '+1', 'users': ['U01B4EXA6S2'], 'count': 1}]",Олег Булыгин
1603469345.214800,1603516556.218800,U0185Q2MK19,"<@U01BHCQS2RJ> , привет!

Я тоже разумной способа заполнения этих данных не вижу и оставил бы все как есть в реальном проекте. Но ревьюер может попросить у тебя их заполнить в тренировочных целях. Тогда я бы взял медианные значения в разрезе населенного пункта.",,Олег Булыгин
1603483207.218100,1603516841.219000,U0185Q2MK19,"<@U01C12HNA1E>, <@U01BBD67YSX>
На примере гисторамм:
если все визуализации одинаковые по параметрам - просто в цикле перебираем столбцы и применяем к каждому нужный метод для построения  графика. Примерно так:

```for column in df[['total_area', 'rooms', 'ceiling_height']]:
    df[column].hist()
    plt.show()```

б) если у визуализации параметры разные, то можно сделать так:
```d = {'m_price': 30,
'rooms': 30}

for key, value in d.items():
    flats_info[key].hist(bins=value)```
Т.е формируем словарь из столбцов-параметров (тут для гистограммы) и так же в цикле применяем это к каждому столбцу",,Олег Булыгин
1603483207.218100,1603523326.219300,U01C12HNA1E,"да, именно разные, спасибо","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1603483207.218100,1603540288.220300,U01AWESS539,"<@U0185Q2MK19> Привет! А подскажи по этой же теме
я построила с помощью цикла сравнительные боксплоты по двум выборкам, но мне необходимы разные заголовки к графикам и подписи по оси у, не понимаю как для этого модифицировать цикл
```for column in cdf[['total_area','price_for_m2','rooms','ceiling_height']]:
    ax = sns.boxplot(y=column, x='Location', data=cdf)
    plt.show()```
",,Мария Кузнецова
1603469345.214800,1603540667.220600,U01BHCQS2RJ,<@U0185Q2MK19> спасибо!,,Александр Афанасьев
1603483207.218100,1603555489.220800,U01AWESS539,"Все, разобралась)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Мария Кузнецова
1603556745.222500,1603556745.222500,U01BHCQN9D2,"Всем привет, делаю срез методом query(), но у меня получается пустая таблица. Что может быть не так? Ссылка: <https://pastebin.com/SJMTFh33>",,Ксения Идрисова
1603483207.218100,1603557362.222600,U01BBD67YSX,"<@U01AWESS539> , можешь рассказать, как сделала? у меня такой же вопрос.",,Наталия Шельянова
1603483207.218100,1603557545.222800,U01AWESS539,"<@U01BBD67YSX> я переделала цикл, включив  словарь, и сделала как писали здесь
<https://yandex-students.slack.com/archives/G01C0NUJEEL/p1603551687444400?thread_ts=1603550806.443400&amp;cid=G01C0NUJEEL>","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Мария Кузнецова
1603556745.222500,1603559151.223000,U01BPRJJN2V,<@U01BHCQN9D2> ошибка в  условии по last_price 1.088701e+07 больше чем  6.800000e+06,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Шалапанов
1603483207.218100,1603560214.223200,U01BBD67YSX,<@U01AWESS539> Спасибо!,,Наталия Шельянова
1603556745.222500,1603606224.224100,U01BHCQN9D2,<@U01BPRJJN2V> спасибо!,,Ксения Идрисова
1603614645.225900,1603614645.225900,U019642UB9D,"<@U0185Q2MK19> Добрый день, хочу построить график по зависимости стоимости от расстояния до центра СПБ. Столкнулся с такими проблемами: 1) при сортировке по километрам сортировки не происходит, цифры также остаются в разнобой.  2) Не строится график, выдает ошибку ""no numeric data to plot"".
Pastebin почему-то не работает у меня, поэтому мой код здесь - <https://justpaste.it/9js05>",,Илья Ревин
1603614645.225900,1603623576.226400,U01C12EGBU0,"Привет! Может, потому что apply с format переводит числовые значения в строчку, а строчка не сортируется? Попробуй закомментировать apply с форматом.",,Сергей Ильин
1603614645.225900,1603624311.226800,U019642UB9D,"<@U01C12EGBU0> Спасибо, это и вправду помогло. А цифры хорошо округлились методом astype('int')","[{'name': '+1', 'users': ['U01C12EGBU0', 'U0185Q2MK19'], 'count': 2}]",Илья Ревин
1603625316.229900,1603625316.229900,U01B84FM5KP,"<@U0185Q2MK19> Добрый день. При выполнении кода выдаёт ошибки (предупреждения), нужна помощь - с чем может быть связано? Проверка каждого пункта проходила без ошибок, ошибка появилась при перезапуске всего проекта. Ссылка на скриншот <https://yadi.sk/i/FWWRtcGUOOvBfw>",,Денис Стариченко
1603625316.229900,1603629722.230000,U01B84FNBPX,"Это вроде бы не ошибка, а только предупреждение, код-то все равно выполняется. Вот здесь Олег давал ссылку про это: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1602224463110700?thread_ts=1602190851.108700&amp;cid=G01BPGP5A73>",,Валентина Тушкова
1603625316.229900,1603630385.230300,U01B84FM5KP,"<@U01B84FNBPX> Да, но это предупреждение теперь светится под каждым пунктом кода, складывается впечатление, что всё не работает",,Денис Стариченко
1603625316.229900,1603632910.230500,U01B84FNBPX,"<@U01B84FM5KP> под каждым? :thinking_face: TBH, я не все поняла в той статье, но если кратко, то: 1) даже если код работает, стоит убедиться, что точно не появилось неожиданных значений, т.е не игнорировать этот warning; 2) найти в каком месте в коде возниклa проблема _""chained assignment""_.  Перезапусти ячейки по очереди и посмотри под какой ячейкой появляется первый warning - возможно тут легче будет понять причину? Также в статье одна из рекомендаций как пофиксить - применить .loc для присваивания значений, думаю для 'ceiling_height' это должно сработать.",,Валентина Тушкова
1603625316.229900,1603637355.230700,U01B84FM5KP,"<@U01B84FNBPX> спасибо, да, по статье я тоже понял, что можно попробовать пофиксить применив .loc...к сожалению, это не помогло","[{'name': 'confused', 'users': ['U01B84FNBPX'], 'count': 1}]",Денис Стариченко
1601925042.073600,1603648768.231000,U01BB741JAW,"<@U0185Q2MK19> по непредвиденным обстоятельствам я только сейчас смогла приступить к еще первому проекту)подскажите плиз по поводу:

```df['days_employed'] = df['days_employed'].fillna(df.groupby('income_type')['days_employed'].transform('median'))```
Можно даже по нескольким признакам делать группировку.

Вы имеете ввиду, что двойную группировку можно сделать внутри groupby? Попробовала несколькими способами, и всё равно ничего не получилось. Спасибо!",,Яна Болдакова
1603658145.236400,1603658145.236400,U01BHCQS2RJ,"Добрый вечер!<@U0185Q2MK19> и все, кто знает, помогите, пож., на гистограмме времени продажи получился пик на медианном значении. Видимо это как раз 3 с лишним тыс. пропусков, кот. я заменил медианой. Как тогда с ними поступать?",,Александр Афанасьев
1601925042.073600,1603690870.236800,U0185Q2MK19,"<@U01BB741JAW>, да :slightly_smiling_face:
Надо столбцы передавать в списке, т.е. так:

```df['days_employed'].fillna(df.groupby(['столбец 1', 'столбец 2'])['days_employed'].transform('median'))```
","[{'name': '+1', 'users': ['U01BB741JAW'], 'count': 1}]",Олег Булыгин
1603625316.229900,1603691134.237000,U0185Q2MK19,"<https://yandex-students.slack.com/archives/G01B461LV0E/p1603691035358600?thread_ts=1603552576.340500&amp;cid=G01B461LV0E>

Вот здесь это тоже обсуждаем.

Если все работает как надо - не предавай значения.

Либо переписывать все переприсвоения через loc и менять не исходный датафрейм, а каждый раз создавать новые","[{'name': 'ok_hand', 'users': ['U01B84FM5KP'], 'count': 1}, {'name': '+1::skin-tone-3', 'users': ['U01B84FNBPX'], 'count': 1}]",Олег Булыгин
1603658145.236400,1603692104.237300,U0185Q2MK19,"Возможно, стоит заменить не просто на медиану, а на медиану в разрезе каких-то признаков? :slightly_smiling_face:",,Олег Булыгин
1603658145.236400,1603696330.237700,U01BHCQS2RJ,"<@U0185Q2MK19> спасибо, попробовал заменить медианой по годам и месяцам размещения, - все равно пики, но поменьше, зато несколько.",,Александр Афанасьев
1603658145.236400,1603697238.238000,U01BHCQS2RJ,"Хотя, если уменьшить количество корзин, выглядит лучше. Так и оставить?",,Александр Афанасьев
1603719807.239400,1603719807.239400,U01C12HQH5W,Не отрисовывается boxplot в цикле.,,Татьяна Зайцева
1603719807.239400,1603719976.239500,U01C12HQH5W,"<@U0185Q2MK19> привет! помоги, пожалуйста, понять в чем дело. Отрисовываю графики распределения (гистограмму и боксплот) в цикле. Все отрисовывается, за исключением последних двух боксплотов, график для них пустой. Для первых трех боксплотов все ок. Код по ссылке <https://pastebin.com/rWH4uWmn>",,Татьяна Зайцева
1603719807.239400,1603720330.239700,U01C12HQH5W,и скриншот,,Татьяна Зайцева
1603658145.236400,1603720721.240100,U0185Q2MK19,"Ну это ведь ожидаемое поведение, когда мы делаем замены :slightly_smiling_face:

Вообще распределение надо изучить до импутации пропусков. А когда мы заменяем средними - понятно, что будут такие пики, в этом ничего страшного нет.",,Олег Булыгин
1603658145.236400,1603721199.240300,U01BHCQS2RJ,Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1603719807.239400,1603721991.240500,U0185Q2MK19,"<@U01C12HQH5W>,привет!

Когда работаем с датафреймом, то лучше применять методы датафрейма:

```for dim in plot_dict:
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(19, 2))
    ax1 = data[dim['column']].hist(bins=30, range=(0, dim['range']), ax=ax1)
    ax2 = data[dim['column']].plot(kind='box', ax=ax2)```
Попробуй так)",,Олег Булыгин
1603719807.239400,1603725176.240800,U01C12HQH5W,<@U0185Q2MK19> спасибо! все получилось :thumbsup:,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Татьяна Зайцева
,1603793308.243100,U01C12DR740,Не могу присвоить новой переменной первый столбец из сгруппированной таблицы,,Станислав Саламатов
1603793450.243200,1603793450.243200,U01C12DR740,"<@U0185Q2MK19>, подскажи, пожалуйста, как присвоить только первый столбец  df_stil_pivot_location в df_stil_pivot_location_to_10 <https://pastebin.com/fDdgVp0W>",,Станислав Саламатов
1603793450.243200,1603793556.244700,U01B4EXA6S2,"Мне кажется тебе надо сбросить индекс через .reset_index()
Скорее всего у тебя первый столбец ушёл в индекс и ты его не находишь ",,Александр Сурков
1603793450.243200,1603793571.245200,U01B4EXA6S2,Добавь эту команду в конце группировки ,"[{'name': '+1', 'users': ['U01C12DR740', 'U0185Q2MK19'], 'count': 2}]",Александр Сурков
1603793450.243200,1603793903.245400,U01C12DR740,"<@U01B4EXA6S2> , спасибо! Помогло!",,Станислав Саламатов
1604000623.247500,1604000623.247500,U01AWESS539,"Нулевые значения в звонках, трафике и SMS",,Мария Кузнецова
1604000623.247500,1604000688.247600,U01AWESS539,"<@U0185Q2MK19> Привет! У меня возник вопрос рассмотрения нулевых значений звонков, трафика, смс. С одной стороны, у меня была идея оставить эти данные как есть с нулевыми значениями, так как они отображают реальность пропущенных звонков, неиспользование интернета и смс. А с другой я вижу, что они искажают медиану и среднее, можно ли их просто заменить на NaN, чтобы они не оказывали влияние на распределение переменных? Или подобное введение пропусков тоже будет некорректно?",,Мария Кузнецова
1604000623.247500,1604037470.247800,U0185Q2MK19,"<@U01AWESS539>, привет!
В данном случае это все же реальные значения, поэтому заменять их на пропуски не надо. Тем более все эти цифры нам понадобятся далее для расчета использованных минут/гб/смс сверх тарифа по каждому пользователю для расчета доходов.",,Олег Булыгин
1604059185.249900,1604059185.249900,U019642UB9D,"<@U0185Q2MK19> Добрый день, в каком формате загружать проект на проверку, если делаешь его не на сайте практикума? .ipynb? И еще вопрос, не будет ли у ревьюера проблемы с просмотром работы, если я использую расширение <http://localhost:8888/tree#nbextensions_configurator|Nbextensions> и модули оттуда?",,Илья Ревин
1604059185.249900,1604064632.250000,U0185Q2MK19,"Привет! Да, ipynb.

Проблемы быть могут. Если делаешь проект локально, то рекомендуется установить себе практикумовское окружение в Анаконду и использовать только его (у вас где-то в доп. материалах есть информация, как это сделать). Так ты сразу будешь понимать что сработает у ревьюера.

Проблемы могут возникнуть даже из-за разных версий библиотек.",,Олег Булыгин
1604059185.249900,1604070507.250200,U019642UB9D,"<@U0185Q2MK19> Да, сделал так. В окружении практикума нет расширения <http://localhost:8888/tree#nbextensions_configurator|Nbextensions>.(Просто прошлый ревьюер рекомендовал использовать его, мне понравилось, и теперь хочу реализовать его в след проекте.) Значит, я не могу его использовать? Или могу, но должен об этом упомянуть в шапке проекта?",,Илья Ревин
1604059185.249900,1604076275.250500,U0185Q2MK19,"<@U019642UB9D>, сделать можно, обязательно нужно упомянуть.
В таких случаях нужно быть готовым, что конкретных проверяющий может попросить  отказаться от функционала, который выходит за рамки окружения. Но скорее всего так не будет.",,Олег Булыгин
1604082142.256100,1604082142.256100,U01B4F01FTQ,"<@U0185Q2MK19> Добрый вечер! Подскажите,пожалуйста, как применить конструкцию try-except при загрузке наборов данных, указав при этом относительный и абсолютный путь ? Абсолютный у меня: 'C:\Users\fio\Проект 3 Определение перспективного тарифа для телеком компании\users.csv'. Какой будет абсолютный и как это собрать вместе ?",,Видов Константин
1604082217.256900,1604082217.256900,U019642V4G7,"Заполнение пропусков.

Я заполняю пропуски в столбцах floors_total и kitchen_area
```flats['ceiling_height'] = flats['ceiling_height'].fillna(flats.groupby('floors_total')['ceiling_height'].transform('median')) 

flats['living_area'] = flats['living_area'].fillna(flats.groupby('rooms')['living_area'].transform('median'))```
Однако, после заполнения все равно остаются пустые строки:
```kitchen_area            23502 non-null float64
floors_total            23613 non-null float64
RangeIndex: 23699 entries```
<@U0185Q2MK19>, подскажи, что я делаю не так?",,Сослан Чехов
1604082217.256900,1604090329.264300,U01B4EXA6S2,"Скорее всего причина такая, что ты создаёшь группы с каждым этажом, потом из каждого этажа считается медиана, и уже пропущенные значение в этих группах с этажами заполняешь этими значениями. Вот скорее всего какой нибудь из этажей имеет все значения NaN и пропуски заполняются NaN. Я оставшиеся пропуски заполнял просто медианой. ","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1604082217.256900,1604128064.264600,U0185Q2MK19,"Александр все говорит верно, просто в некоторых группах вообще не указаны нужные значения.",,Олег Булыгин
1604082142.256100,1604128516.264800,U0185Q2MK19,"<@U01B4F01FTQ>, привет!

Наверное, не совсем понимаю вопрос. Нужно, чтобы пробовался относительный путь, если он не срабатывает, то абсолютный?

Если да, то примерно так должно быть:

```try:
  df = read_csv('относительный путь')
except:
  df = read_csv('абсолютный путь')```
",,Олег Булыгин
1604082142.256100,1604133205.265000,U01B4F01FTQ,"Все верно, спасибо! Еще не подскажешь как относительный путь собрать из этого 'C:\Users\fio\Проект 3 Определение перспективного тарифа для телеком компании\users.csv'. ?? И, если я правильно понимаю, если прописан относительный путь, то файл можно будет загрузить вне зависимости от того где находится сам скрипт ?",,Видов Константин
1604082217.256900,1604137727.265200,U019642V4G7,"да, спасибо за совет, вроде поправил",,Сослан Чехов
1604082142.256100,1604149454.265500,U0185Q2MK19,"Абсолютный путь будет работать вне зависимости от директории запуска)
Можно разбить строку по разделителю при помощи split (/) и достать нужный элемент.

Самое то - использовать регулярные выражения, но это уже в рамках самостоятельного изучения)",,Олег Булыгин
1604153169.266700,1604153169.266700,U01BBD72X1R,"Функция для задачи:
*Вычтите бесплатный лимит из суммарного количества звонков, сообщений и интернет-трафика; остаток умножьте на значение из тарифного плана;*",,Артем Провороцкий
1604153169.266700,1604153227.266800,U01BBD72X1R,"<@U0185Q2MK19> помоги плз)
Написал функцию, но когда заворачиваю ее в apply, выдает ошибку
KeyError: ('mg_per_month_included', 'occurred at index 0')

<https://pastebin.com/31tikgG2>",,Артем Провороцкий
1604153169.266700,1604156998.267300,U01BBD72X1R,"Ошибку нашел, в опечатке:man-facepalming:
Минус час из жизни)","[{'name': '+1', 'users': ['U0185Q2MK19', 'U01C12DS52L'], 'count': 2}]",Артем Провороцкий
1604224984.268100,1604224984.268100,U01BBD7KBA7,Округление series'a,,Влад Иванов
1604224984.268100,1604225119.268200,U01BBD7KBA7,"Привет, прошу помочь найти ошибку и понять почему не удается округлить целиком столбец используя такой метод. После использования функции столбец не записывается с новыми значениями в датафрейм. Возможно есть какой то более изящный метод округления в большую сторону целого столбца, <@U0185Q2MK19>
<https://pastebin.com/pUCdhTMY>",,Влад Иванов
1604227501.270200,1604227501.270200,U019642UB9D,"<@U0185Q2MK19> Добрый день, пытаюсь вычесть из числа потраченных сообщений, число включенных в тариф. Но никак не выходит. В чем моя проблема? Скриншот:  <https://pastenow.ru/ae99faca7ae96f3643451b9b7a966e47> Выдает ошибку 'Passing list-likes to .loc or [] with any missing labels is no longer supported'
Может быть есть более простой способ, чем мой?",,Илья Ревин
1604232792.271400,1604232792.271400,U01BBD72X1R,"Коллеги, а у вас при выполнении проекта по статистике, значений свыше тарифа по ultra нет? Или у меня только так и нужно искать ошибку)",,Артем Провороцкий
1604232792.271400,1604232946.271500,U01BBD72X1R,"<@U0185Q2MK19> Подскажи, плз, так и должно быть или нет?)",,Артем Провороцкий
1604224984.268100,1604240359.271800,U0185Q2MK19,"<@U01BBD7KBA7>, никогда не нужно использовать к датафреймам циклы, если можно без этого обойтись :slightly_smiling_face:

Можно так:
```import numpy as np
df['duration'].apply(np.ceil) ```
",,Олег Булыгин
1604232792.271400,1604241200.272000,U0185Q2MK19,"Бегло перепроверил, по мегабайтам есть точно те, кто выходит сверхлимита в месяц по ультра",,Олег Булыгин
1604232792.271400,1604241242.272200,U01BBD72X1R,"<@U0185Q2MK19> Спасибо, буду разбираться",,Артем Провороцкий
1604227501.270200,1604241884.272400,U0185Q2MK19,"<@U019642UB9D>, никогда не нужно применять к датафреймам циклы, когда можно обойтись без этого.

Я бы предложил тебе сделать более универсальное решение. Алгоритм, может быть такой:

1. формируем сначала объединенный датафрейм абсолютно со всей информацией (данные по всем пользователям за каждый месяц, где сразу есть потраченные мб, минуты, смс и ограничения тарифа).
2. В этом датафрейме считаем перерасход по каждой услуге каждого пользователя в каждом месяце. Это просто делаем вычитанием значений по столбцам, примерно так:
```costs['minutes_overrun']  = costs['minutes'] - costs['minutes_included']
costs['messages_overrun'] = costs['messages'] - costs['messages_included']
costs['mb_used_overrun']  = costs['mb_used'] - costs['mb_per_month_included'] ```

3. считаем доход примерно по такой функции:
```def get_revenue(row):
    revenue_by_min = 0
    revenue_by_messages = 0
    revenue_mb = 0

    if row['minutes_overrun'] &gt; 0:
        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']

    if row['messages_overrun'] &gt; 0:
        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']

    if row['mb_overrun'] &gt; 0:
        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']

    return revenue_by_min + revenue_by_messages + revenue_mb```
Циклы тут не нужны нигде)",,Олег Булыгин
1604224984.268100,1604246006.273000,U01BBD7KBA7,"<@U0185Q2MK19>, Благодарю!","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Иванов
1604227501.270200,1604262724.273200,U019642UB9D,"<@U0185Q2MK19> Добрый день, вариант предложенный вами довольно понятен, спасибо. Но я столкнулся в ходе выполнения со следующей проблемой. На скриншоте показан код и столбцы моего объединенного дф. Я поменял названия на одно, чтобы выполнить вычитание. Что в логике моих действий не так?
Выдает ошибку:
```TypeError: '&lt;' not supported between instances of 'str' and 'int'```
<https://pastenow.ru/4d35ef82b6367618cad9f7ce7ad114ab>",,Илья Ревин
1604227501.270200,1604290217.274100,U0185Q2MK19,"<@U019642UB9D>, в логике самих действий все верно, но в первую очередь надо проверить типы столбцов, над которыми проводим вычисления. Они должны быть числовыми, а не строковыми (object). Ошибка весьма вероятно связана именно с этим",,Олег Булыгин
1604227501.270200,1604300644.274300,U019642UB9D,"<@U0185Q2MK19> Да, я тоже связал эту ошибку с наличием (object). Но я проверил, у меня там все столбцы int и float. На всякий случай я пробовал еще int перевести в float. Не помогло. С чем еще может быть связана ошибка?",,Илья Ревин
1604232792.271400,1604323224.274900,U01C12G1ZJL,<@U01BBD72X1R> у меня с перерасходом Мб по ultra больше сотни юзеров. но по звонкам и сообщениям никто не вышел за лимит,,Татьяна Волобуева
1604227501.270200,1604378384.275200,U0185Q2MK19,"<@U019642UB9D>, явно какая-то проблема с объединением таблиц, но только по этому скриншоту судить сложно. Посмотри на столбцы в итоге, у тебя там очень много одинаковых, так быть не должно. У тебя точно исходные таблицы сгруппированны по пользователям и месяцам? Пришли, пожалуйста, группировки таблиц звонков, смс и интернета.",,Олег Булыгин
1604227501.270200,1604383163.275500,U019642UB9D,"<@U0185Q2MK19> Вот прикладываю скриншот группировки по пользователям и месяцам. <https://pastenow.ru/40d99526ef8d20c9bdc09030fafa67e8>.
Также, вот код как я объединял таблицы: <https://pastebin.com/fuQCZEmz>",,Илья Ревин
1604232792.271400,1604394772.276400,U01BBD72X1R,"<@U01C12G1ZJL> Да у меня в итоге была проблема в функции, поправил и так же) Проект уже закрыл, спасибо)","[{'name': '+1', 'users': ['U01C12G1ZJL'], 'count': 1}]",Артем Провороцкий
1604227501.270200,1604405781.282000,U0185Q2MK19,"<@U019642UB9D>, а почему ты используешь сводные таблицы вместо группировок? По ним я у тебя не понимаю логику объединения.

Попробуй так:

```user_calls = calls.groupby(['user_id', 'месяц'])\
                  .agg({'duration':'sum', 'id':'count'})\
                  .reset_index()\
                  .rename(тут можно переименовать столбцы для удобства)

user_messages = messages.groupby(['user_id', 'месяц'])\
                        .agg({'id':'count'})\
                        .reset_index()\
                        .rename()
user_internet = internet.groupby(['user_id', 'месяц'])\
                        .agg({'mb_used':'sum'})\
                        .reset_index()\
                        .rename()```
И потом уже все это дело объединяем именно по месяцу и пользователю. Например, вот так:
`df = user_calls.merge(user_messages, on=['user_id', 'месяц'], how='outer')`

В твоем варианте это просто не получится. Попробуй так, напиши о результатах :slightly_smiling_face:","[{'name': '+1', 'users': ['U01C12EJQ80'], 'count': 1}]",Олег Булыгин
1604227501.270200,1604479280.284300,U019642UB9D,"<@U0185Q2MK19> Спасибо, все получилось в итоге. У меня началась ошибка с группировки, поэтому и запутался потом.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Илья Ревин
1604486272.285500,1604486272.285500,U01BBD743QB,объединение таблиц,,Айнур Мусаева
1604486272.285500,1604486518.285600,U01BBD743QB,"<@U0185Q2MK19>, добрый день!
помоги, пожалуйста, не накосячить при объединении таблиц)
в данный момент я соединила инфо о юзерах, инфо о тарифах и инфо о звонках.  пока все было просто и контрольные цифры сходятся (суммарная длительность всех звонков всех пользователей до и после объединения). Но как теперь мне присоединить инфо о сообщениях и трафике, чтобы нигде не возникло дублирования?
<https://pastebin.com/zhrD460a>",,Айнур Мусаева
1604492402.286000,1604492402.286000,U01375HRT1V,[*] или зацикливание в Юпитере,,Елена Моисеева
1604492402.286000,1604492478.286100,U01375HRT1V,"<@U0185Q2MK19> привет!
У меня второй раз за два дня перестает выполняться любой код - даже import pandas as pd в первой строке
и пишет [*]
Так может быть от того что я написала плохую функцию и все зациклила _ниже_ по коду?",,Елена Моисеева
1604495222.287300,1604495222.287300,U01AWEP1SJK,"Всем привет, можно дать пример как прописывается код equal_var для сравнения 2х дисперсий, я не совсем понял",,Владислав Несоленов
1604486272.285500,1604500247.287600,U0185Q2MK19,"<@U01BBD743QB>, посмотри, пожалуйста, вот на этот мой коммент: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1604405781282000?thread_ts=1604227501.270200&amp;cid=G01BPGP5A73>

Не надо группировать данные по тарифу в изначальных таблицах.

А потом присоединяем tariffs и users при помощи `left join` :
```df = df.merge(users, on='user_id', how='left')
df = df.merge(tariffs, on='tariff', how='left')```
Напиши, получилось ли)",,Олег Булыгин
1604492402.286000,1604503410.287900,U01C12EJQ80,"*<https://app.slack.com/team/U01375HRT1V|Елена Моисеева>* Привет, у мены что-то похожее было, когда проект выполняла локально, в тренажере работало все нормально.

Если предположить, что код выполняется последовательно и ты работаешь через Яндекс.Практикум в Jupiter, возможно попробовать написать в тех.поддержку.
Если локально - рекомендовала бы смотреть запускаешь ли ты сначала Jupiter Notebook(practicum) в Anaconda.

Пусть все получится:cat-high-five:","[{'name': 'cat-high-five', 'users': ['U01375HRT1V'], 'count': 1}]",Динара Шарафутдинова
1604492402.286000,1604503474.288200,U0185Q2MK19,"<@U01375HRT1V>, привет!

Если ты ниже по коду запустила ячейку и ее исполнение подвисло/идет очень долго, то да, если после этого  запустить ячейки выше, то они так же не исполнятся.

Надо искать проблемный участок, на котором это происходит.",,Олег Булыгин
1604495222.287300,1604503641.288400,U0185Q2MK19,"Привет!

Уточни, пожалуйста, вопрос. Что значить ""как прописывается код""?
Это аргумент, который передается в функцию ttest_ind, по умолчанию равен False.",,Олег Булыгин
1604495222.287300,1604508714.289800,U01AWEP1SJK,"привет, только что понял что хочет от меня ревьюер, спасибо) вопросов нет:see_no_evil::grin:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Владислав Несоленов
1604508980.291200,1604508980.291200,U019E4BGBP0,"<@U0185Q2MK19> , привет!) 

Помоги , пожалуйста, я никак не могу понять , как посчитать количество звонков для каждого абонента и смс ?? 
Я уже всю голову сломала.. 
длительность звонков посчитала с помощью сводной Таблицы 

df.pivot_table(index = 'user_id' , values = 'duration', aggfunc = 'sum')",,Угловская Вера
1604520684.296400,1604520684.296400,U01BHCQS2RJ,"Добрый вечер <@U0185Q2MK19> и коллеги, не понимаю: в 4-м шаге нужно считать среднее количество, дисперсию, стандартное отклонение и строить гистограммы нужно для ""минут"", ""сообщений"", ""Gb"" и выручке от одного абонента или только по выручке?",,Александр Афанасьев
1604508980.291200,1604521417.296900,U019E4BGBP0,"<@U0185Q2MK19> , все я нашла вроде решение!) ","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Угловская Вера
1604492402.286000,1604525118.298500,U01375HRT1V,"Спасибо <@U0185Q2MK19>
А как остановить зацикливание? Обновление страницы не помогает, то же самое - верхняя строка после обновления уже не может запуститься ",,Елена Моисеева
1604508980.291200,1604550557.298800,U0185Q2MK19,"Для количества можно применять не sum, а count)",,Олег Булыгин
1604492402.286000,1604550658.299000,U0185Q2MK19,"<@U01375HRT1V>, меню Kernel -&gt; Restart. Это действие выгружает все действия из памяти (как бы ""сбрасывает"" программу). И ячейки можно запускать заново","[{'name': 'cat-high-five', 'users': ['U01375HRT1V'], 'count': 1}]",Олег Булыгин
1604520684.296400,1604551640.299300,U0185Q2MK19,"Привет!

Именно по количеству минут, гб и смс.",,Олег Булыгин
1604520684.296400,1604552602.300600,U01BHCQS2RJ,"Доброе утро! А, в следующем шаге строить гипотизы по выручке?",,Александр Афанасьев
1604520684.296400,1604552708.300800,U01BHCQS2RJ,Сппсибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}, {'name': 'clap', 'users': ['U01BHCQS2RJ'], 'count': 1}]",Александр Афанасьев
1604520684.296400,1604560501.301000,U0185Q2MK19,"Да, все верно)","[{'name': '+1', 'users': ['U01BHCQS2RJ'], 'count': 1}]",Олег Булыгин
1604564225.302300,1604564225.302300,U01B4EZUE4E,Подсчет выручки в датафрейме с мультииндексом.,,Сергей Афанасьев
1604564225.302300,1604564241.302400,U01B4EZUE4E,"<@U0185Q2MK19> Добрый день. Когда создавал общую таблицу с мегабайтами, сообщениями и звонками по месяцам, применил мультииндекс. Где верхние индекс это мегабайты, минуты и сообщения, а нижний это месяца.
```MultiIndex([('megabytes',  1),
            ('megabytes',  2),
            ('megabytes',  3),
            ('megabytes',  4)...```
И так далее. Это казалось неплохой идеей. Так оно и было, вплоть до момента, когда начал считать выручку. Проблема в том, как теперь написать условия проверки. Если написать `df['minutes] &gt; 0` то, он не даст адекватного ответа, ведь `df['minutes]`  сам по себе является датафреймом где есть еще 12 столбцов с месяцами.  Если сделать функцию с циклом перебора столбцов типа, `def revenue (row): for i in range(1,13): if (row['megabytes_extra', i] &gt; 0) | (row['messages_extra', i] &gt; 0) | (row['minutes_extra', i] &gt; 0): return True else: False`
, а потом передать её датафрему с аргументом axis=1, все выдается как True, что неверно, так как есть месяца, где некоторые абоненты не пользовались услугами вообще.",,Сергей Афанасьев
1604564225.302300,1604564327.302700,U01B4EZUE4E,,,Сергей Афанасьев
1604564225.302300,1604564498.303100,U01B4EZUE4E,Стоит ли бросить эту затею и создать таблицу без мультиндекса или все-таки есть какой-то способ создать функцию которая корректно сможет брать нужные значения и считать их?,,Сергей Афанасьев
1604564225.302300,1604568794.303700,U01C12HNA1E,"Привет. Сам изначально сводную таблицу группировал по-другому, в одном столбце все месяцы делал, вроде проще получалось",,Владимир Ефимищев
1604564225.302300,1604568983.303900,U01C12HNA1E,,,Владимир Ефимищев
1604564225.302300,1604579474.304400,U0185Q2MK19,"<@U01B4EZUE4E>, я бы поддержал Владимира в его варианте группировки. Твой вариант сильно все переусложняет.

Посмотри мой коммент: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1604405781282000?thread_ts=1604227501.270200&amp;cid=G01BPGP5A73>
Там описан вполне рабочий и несложный вариант",,Олег Булыгин
1604564225.302300,1604579650.304800,U01B4EZUE4E,"<@U0185Q2MK19> и <@U01C12HNA1E>, спасибо)","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Сергей Афанасьев
1604583820.307800,1604583820.307800,U01BHCQS2RJ,"Добрый вечер, объясните, пож., кто может, по поводу 4 шага: нужно для каждой из двух данных гипотез выдвигать подгипотезы (Н1 и Н0) и каждую проверять? Или как?",,Александр Афанасьев
1604583820.307800,1604639076.308200,U0185Q2MK19,"Для каждого пункта нужна сформулировать нулевую и альтернативную гипотезы, да",,Олег Булыгин
1604486272.285500,1604639485.308500,U01C12H494Y,"<@U0185Q2MK19> почему-то при соединении таблиц вот этим способом:
df = df.merge(users, on='user_id', how='left')
появляются дубликаты столбцов, типа *city_x, city_y, city*
подскажи, пожалуйста, как сделать так, чтобы их не было?",,Влад Простаков
1604486272.285500,1604640051.308900,U0185Q2MK19,"<@U01C12H494Y>, если в исходных таблицах если колонки с одинаковыми названиями, то так будет в любом случае. Надо понимать, что у тебя лежит в df :)",,Олег Булыгин
1604583820.307800,1604640181.309100,U01BHCQS2RJ,Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1604486272.285500,1604640595.309300,U01C12H494Y,"<@U0185Q2MK19> понял, спасибо! надо было просто все заново запустить",,Влад Простаков
1604486272.285500,1604658956.309500,U01BBD743QB,"<@U0185Q2MK19> , добрый день! кажется, получилось, большое спасибо. я как-то упустила из вида, что можно объединять больше чем по одному столбцу и пыталась обойтись только user_id :confused:","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Айнур Мусаева
1604750949.310800,1604750949.310800,U01BHCQN9D2,"Добрый день, <@U0185Q2MK19>! подскажите, пожалуйста, пытаюсь объединить таблицы методом merge()
t= df_users.merge(df_internet,on='key') Система выдает такую ошибку: The kernel appears to have died. It will restart automatically. В тех.поддержки не смогли помочь",,Ксения Идрисова
1604750949.310800,1604751381.310900,U01BHCQPGDS,"В описании проекта на этот случай был абзац ""*Примечание*. Если объединение таблиц методом `merge` приводит к ошибке `dead kernell`, примените метод `join` — это облегчит нагрузку на Jupyter Notebook."". Попробуйте `join`",,Евгений Фадеев
1604750949.310800,1604751452.311100,U01BHCQN9D2,"Точно, спасибо большое!",,Ксения Идрисова
1604750949.310800,1604753865.312000,U01B4EXA6S2,"Join тоже не помогает
На втором присоединении уже тухнет",,Александр Сурков
1604750949.310800,1604754346.312200,U01BHCQPGDS,"Я бы проверил содержимое таблиц, тип объединения и по каким ячейкам. Возможно значения сильно множатся или цикл объединения уходит в бесконечность, получается слишком много данных, поэтому ядро тухнет",,Евгений Фадеев
1604750949.310800,1604759207.312400,U01BHCQN9D2,"У меня получилось, правда лишние столбцы взялись откуда-то(",,Ксения Идрисова
1604750949.310800,1604759296.314000,U01B4EXA6S2,"<@U01BHCQN9D2> я правильно понимаю, сначала надо обработать данные(удалить все выбросы и тд), а уже потом объединять?",,Александр Сурков
1604750949.310800,1604759535.314200,U01BHCQN9D2,<@U01B4EXA6S2> я сразу объединила,,Ксения Идрисова
1604750949.310800,1604759596.314400,U01BHCQPGDS,"<@U01B4EXA6S2> я сначала обработал данные, выбросов правда не увидел. Привел все к нужным типам, добавил недостающие по условию задачи данные, сделал группировки и дальше делал merge. Все работает вроде правильно",,Евгений Фадеев
1604750949.310800,1604759858.314600,U01BHCQN9D2,"<@U01BHCQPGDS>, а как объединяли merge() создавали новый столбец или по id?",,Ксения Идрисова
1604750949.310800,1604760046.314800,U01BHCQPGDS,"<@U01BHCQN9D2> объединил по user_id и дате сразу. Затем в каждой таблице добавил столбец с месяцем использования и провел группировки. И главное не забыть до merge сделать группировку по дням, тк пользователи могли за один день делать несколько звонков/сообщений/сессий",,Евгений Фадеев
1604750949.310800,1604761018.315100,U0185Q2MK19,"Еще такая ошибка часто возникает как раз из-за того, что забыли сгруппировать данные до объединения (т.е. есть дублирующие значения в столбцах, по которым объединяем).

Поэтому обязательно надо делать группировку по user_id и месяцам в изначальных таблицах.",,Олег Булыгин
1604750949.310800,1604761726.315300,U01BHCQN9D2,"<@U01BHCQPGDS>, спасибо за ответ, а как вы по датам объединили , они же не будут совпадать?",,Ксения Идрисова
1604750949.310800,1604762142.315500,U01BHCQPGDS,"<@U01BHCQN9D2> почему не будут? Выше уже писал, что до объединения таблиц сделал методом groupby группировку по user_id и дате, использовал функцию суммы для длительности звонков и интернета, а подсчет количества (count) - для смс.  Потом важно выбрать правильный метод объединения таблиц для метода merge, чтобы сохранить данные из всех таблиц. Таким образом у вас будут по каждому дню данные для каждого юзера",,Евгений Фадеев
1604750949.310800,1604762185.315700,U01BHCQN9D2,"<@U01BHCQPGDS> поняла,спасибо!","[{'name': 'raised_hands', 'users': ['U01BHCQPGDS'], 'count': 1}]",Ксения Идрисова
1604227501.270200,1604809857.316000,U019E4BGBP0,"<@U0185Q2MK19>, можешь пожалуйста подсказать, что я тут делаю не так ?? я хочу посчитать перерасход минут",,Угловская Вера
1604227501.270200,1604815167.316300,U0185Q2MK19,"<@U019E4BGBP0>, привет!

На мой взгляд для этой задачи не нужны никакие функции, достаточно просто действий над столбцами датафрейма.

После того, как у тебя получится общая таблица со всеми данными (это обсуждали здесь: <https://yandex-students.slack.com/archives/G01BPGP5A73/p1604405781282000?thread_ts=1604227501.270200&amp;cid=G01BPGP5A73>)
у тебя будет столбец с расходом минут/смс/гб каждого пользователя в конкретном месяце и столбец с лимитом по тарифу. Просто вычитаем из одного столбца другой, там где расход больше лимита и получаем перерасход), примерно так:

```costs['minutes_overrun']  = costs['minutes'] - costs['minutes_included']
costs['messages_overrun'] = costs['messages'] - costs['messages_included']
costs['mb_used_overrun']  = costs['mb_used'] - costs['mb_per_month_included'] ```
",,Олег Булыгин
1604823495.317400,1604823495.317400,U01B4EXA6S2,"Привет <@U0185Q2MK19> . подскажи пожалуйста. Не сходятся контрольные суммы до объединения и после. В сводной одна цифра и как объединяю, цифры уменьшаются. Не могу понять где ошибка код <https://pastebin.com/fK6HyqUH> и скрин <https://pastenow.ru/9aa6c7f4c15e817f512536788711dc12>",,Александр Сурков
1604823495.317400,1604826553.317700,U0185Q2MK19,"Привет!
1. Объединение надо делать и по user_id и по месяцам.
2. Тип объединения должен быть outer (аргумент функции merge)",,Олег Булыгин
1604823495.317400,1604826770.319300,U01B4EXA6S2,"<@U0185Q2MK19>  объединял по юзерам и месяца, а проблема как раз оказалась в outer. благодарю, все сошлось теперь","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1604823495.317400,1604830698.319600,U01BHCQPGDS,"<@U01B4EXA6S2> в условие есть замечание ""*Обратите внимание*: «Мегалайн» всегда округляет вверх значения минут и мегабайтов. Если пользователь проговорил всего 1 секунду, в тарифе засчитывается целая минута."". Судя по значению минут - ты не округлял их. Я почти в самом конце у себя это заметил, проверь и у себя тоже)",,Евгений Фадеев
1604823495.317400,1604830798.320500,U01B4EXA6S2,<@U01BHCQPGDS> спасибо. Вообще про это забыл ,,Александр Сурков
1604227501.270200,1604892866.320700,U019E4BGBP0,"<@U0185Q2MK19> Спасибо большое! На самом деле в этом треде были все ответы на мои вопросы , но я искала путь сложней зачем-то , наверное чтобы опять пропустить дедлайн:sweat_smile:","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Угловская Вера
,1604904271.321300,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 1.* Изучите общую информацию
• Общие вопросы
• Вопросы по датасету
",,Маргарита Минеева
,1604904298.321600,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Приведите к нижнему регистру названия столбцов
",,Маргарита Минеева
1604904346.321900,1604904346.321900,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Преобразуйте данные в нужные типы. Опишите, в каких столбцах заменили тип данных и почему
",,Маргарита Минеева
1604904372.322200,1604904372.322200,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Обработайте пропуски при необходимости
",,Маргарита Минеева
,1604904401.322500,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 2.* Подготовьте данные
• Посчитайте суммарные продажи во всех регионах и запишите их в отдельный столбец
",,Маргарита Минеева
,1604904418.322800,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Посмотрите, сколько игр выпускалось в разные годы. Важны ли данные за все периоды?
",,Маргарита Минеева
1604904433.323100,1604904433.323100,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Посмотрите, как менялись продажи по платформам. Выберите платформы с наибольшими суммарными продажами и постройте распределение по годам.
",,Маргарита Минеева
1604904448.323400,1604904448.323400,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Возьмите данные за соответствующий *актуальный период.*
",,Маргарита Минеева
1604904463.323700,1604904463.323700,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Какие платформы лидируют по продажам, растут или падают? Выберите несколько потенциально прибыльных платформ.
",,Маргарита Минеева
1604904478.324000,1604904478.324000,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Постройте график «ящик с усами» по глобальным продажам игр в разбивке по платформам. Опишите результат.",,Маргарита Минеева
1604904493.324300,1604904493.324300,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Постройте диаграмму рассеяния и посчитайте корреляцию между отзывами и продажами. Сформулируйте выводы.
",,Маргарита Минеева
,1604904508.324600,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Соотнесите выводы с продажами игр на других платформах.
",,Маргарита Минеева
,1604904521.324900,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 3.* Проведите исследовательский анализ данных
• Посмотрите на общее распределение игр по жанрам. Что можно сказать о самых прибыльных жанрах? Выделяются ли жанры с высокими и низкими продажами?
",,Маргарита Минеева
1604904531.325200,1604904531.325200,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 4.* Составьте портрет пользователя каждого региона
• Определите для пользователя каждого региона (_NA, EU, JP_)
",,Маргарита Минеева
1604904545.325500,1604904545.325500,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 5.* Проверьте гипотезы
• Средние пользовательские рейтинги платформ _Xbox One_ и _PC_ одинаковые;
• Средние пользовательские рейтинги жанров _Action_ и _Sports_ разные.
",,Маргарита Минеева
,1604904555.325800,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 5.* Поясните гипотезы
• Как вы сформулировали нулевую и альтернативную гипотезы;
• Какой критерий применили для проверки гипотез и почему.
",,Маргарита Минеева
,1604904559.326000,UTTGJQS6M,":bar_chart: Сборный проект-1
*Шаг 6.* Напишите общий вывод",,Маргарита Минеева
1604910850.326200,1604910850.326200,U01BBD743QB,чек-бокс в проекте,,Айнур Мусаева
1604910850.326200,1604910957.326300,U01BBD743QB,"<@U0185Q2MK19> , добрый день! в предыдущих проектах после задания был чек-бокс. подскажи, пожалуйста, в этом проекте его нет или это у меня некорректно отображается страница?",,Айнур Мусаева
1604910850.326200,1604911367.326500,U01C12HNA1E,"Айнур, добрый день. У меня чек-бокса не было уже в проекте по статистике.","[{'name': 'heavy_plus_sign', 'users': ['U01C12EJQ80'], 'count': 1}]",Владимир Ефимищев
1604910850.326200,1604911589.326700,U01BBD743QB,ого! у меня был. все страньше и страньше)),,Айнур Мусаева
1604910850.326200,1604911686.326900,U01C12HNA1E,обычно он дублирует само задание,,Владимир Ефимищев
1604910850.326200,1604912543.327200,U01C12EJQ80,"<https://app.slack.com/team/U01BBD743QB|Айнур Мусаева>, *<https://app.slack.com/team/U01C12HNA1E|Владимир Ефимищев>,* Привет, да, у меня аналогично с Владимиром. У меня был пустой лист с 1 строкой ""In"".",,Динара Шарафутдинова
1604913250.331500,1604913250.331500,U01B4EXA6S2,"<@U0185Q2MK19> привет. Не совсем понимаю задание на 3м шаге в из статистического анализа. Необходимо сделать отдельный срез для каждого тарифа и уже по каждому отдельному срезу искать среднее дисперсию и ст отклонение и строить гистограмммы. Или все таки надо это сделать для общей выборки где оба тарифа вместе?
",,Александр Сурков
1604910850.326200,1604913770.331600,U01BBD743QB,"Большое спасибо, коллеги! Значит, бывают разные варианты. Видимо, не нужно об этом беспокоиться)",,Айнур Мусаева
1604904372.322200,1604919485.331800,U019642UB9D,"<@U0185Q2MK19> Добрый день, почему метод .unique() показывает, что есть NaN, а .query('column == ""nan""') - не показывает? Странно еще то, что в некоторых колонках у меня показало, а в некоторых - нет.",,Илья Ревин
1604227501.270200,1604920530.333200,U019E4BGBP0,"<@U0185Q2MK19>  

Подскажи , пожалуйста, как применять эту функцию лучше ? Через apply ? 



считаем доход примерно по такой функции:
```def get_revenue(row):```
```    revenue_by_min = 0```
```    revenue_by_messages = 0```
```    revenue_mb = 0```
```    if row['minutes_overrun'] &gt; 0:```
```        revenue_by_min = row['minutes_overrun'] * row['rub_per_minute']```
```    if row['messages_overrun'] &gt; 0:```
```        revenue_by_messages = row['messages_overrun'] * row['rub_per_message']```
```    if row['mb_overrun'] &gt; 0:```
```        revenue_mb = (row['mb_overrun'] / 1024) * row['rub_per_gb']```
```    return revenue_by_min + revenue_by_messages + revenue_mb```
Циклы тут не нужны нигде)",,Угловская Вера
1604913250.331500,1604921718.333600,U01B84FNBPX,Привет! Я делала два среза и отдельно по каждому считала.,,Валентина Тушкова
1604913250.331500,1604923497.334700,U01B4EXA6S2,<@U01B84FNBPX> понял. Спасибо.),,Александр Сурков
1604904372.322200,1604923572.334900,U0185Q2MK19,"<@U019642UB9D>, привет!
NaN - это не строковое значение, а самостоятельный отдельный объект. Как, например, None. Сравнивать с ним нужно по-другому для корректного результата.
Вот здесь приведены варианты: <https://stackoverflow.com/questions/26535563/querying-for-nan-and-other-names-in-pandas>

В целом лучше искать NaN через встроенный функционал panda (isnull или isna), а не через query","[{'name': '+1', 'users': ['U01BHCQS2RJ'], 'count': 1}]",Олег Булыгин
1604227501.270200,1604923613.335200,U0185Q2MK19,"<@U019E4BGBP0>, да, все верно. Через apply и не забыть указать axis=1 :slightly_smiling_face:",,Олег Булыгин
1604913250.331500,1604923748.335400,U0185Q2MK19,"Подтверждаю, надо делать в разрезе тарифов)",,Олег Булыгин
1604913250.331500,1604923792.335900,U01B4EXA6S2,<@U0185Q2MK19> спасибо:ok_hand:,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1604910850.326200,1604924436.336100,U0185Q2MK19,"Будьте готовы к тому, что у вас больше никаких заготовок и чекбоксов может не быть, все оформлять самостоятельно)","[{'name': 'heavy_plus_sign', 'users': ['U01BBD743QB'], 'count': 1}]",Олег Булыгин
1604925776.339800,1604925776.339800,U01B84FNBPX,"<@U0185Q2MK19> привет, нужен совет. Я считала выручку по каждому клиенту с помощью apply() - <https://pastebin.com/9JWPp7cp>. Как можно было сделать то же самое менее ресурсозатратно? Ревьюер посоветовал делать расчеты и выборки с помощью `.loc` но что-то до меня не доходит, как это может выглядеть:thinking_face:

И вопрос в догонку: что такое векторизованные операции и где почитать про них?",,Валентина Тушкова
1604925776.339800,1604925975.340500,U01B4EXA6S2,<@U01B84FNBPX> <https://yandex-students.slack.com/archives/G01BPGP5A73/p1604241884272400?thread_ts=1604227501.270200&amp;channel=G01BPGP5A73&amp;message_ts=1604241884.272400|https://yandex-students.slack.com/archives/G01BPGP5A73/p1604241884272400?thread_ts=1604227501.270200&amp;channel=G01BPGP5A73&amp;message_ts=1604241884.272400> скорее всего оно,,Александр Сурков
1604925776.339800,1604927566.340800,U01B84FNBPX,"<@U01B4EXA6S2> Спасибо! 1 и 2 пункт согласна, но в 3 же тоже функция почти как у меня. Получается все равно надо делать df.apply(get_revenue) чтобы посчитать доход по каждой строке?",,Валентина Тушкова
1604925776.339800,1604927775.342900,U01B4EXA6S2,<@U01B84FNBPX> ну вообще вроде да. Я так же делал как в сообщение. У меня тоже через функцию и apply последняя операция ,,Александр Сурков
1604904372.322200,1604937850.343300,U019642UB9D,<@U0185Q2MK19> Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Илья Ревин
1604227501.270200,1604957863.346400,U01B4EYP47Q,"<@U0185Q2MK19> Привет! Подскажи, пожалуйста ! Делаю аналогичную функцию , но выдаётся ошибка “mb_overrun”, “occurred at index 0”. Как правильно понять ошибку и исправить ее?",,Антон Бахилин
1604925776.339800,1604980989.346600,U0185Q2MK19,"Вот тут как раз обсуждается такой подход и что так более быстро: <https://stackoverflow.com/questions/27041724/using-conditional-to-generate-new-column-in-pandas-dataframe>

Хотя я бы не сказал, что на наших данных это как-то будет заметно и критично.

А про векторизацию можно почитать здесь: <https://www.geeksforgeeks.org/vectorization-in-python/>
На самом деле все массивы numpy (а соответственно Series и датафреймы) работают на основе векторизации. Все операции над ними применяются к каждому элементу массива без использования цикла (это и есть векторизация). Именно поэтому почти всегда использование циклов при работе с датафреймами неоправданно.",,Олег Булыгин
1604227501.270200,1604984148.347300,U0185Q2MK19,"<@U01B4EYP47Q>, привет!

Первое, что приходит в голову - что столбца `mb_overrun` нету в данных, к которому ты применяешь эту функцию (может опечатка в названии).

Если точно есть, то нужно смотреть на сам датафрейм и на функцию, чтобы найти расхождения",,Олег Булыгин
1604925776.339800,1605007359.347700,U01B84FNBPX,Спасибо <@U0185Q2MK19>! Ссылки прямо то что надо. Теперь все понятно:happy-cat:,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Валентина Тушкова
1605024673.350500,1605024673.350500,U01BHCQPGDS,"<@U0185Q2MK19> подскажи пожалуйста, приняли последний проект и там ревьювер написал 'Советую познакомиться с функцией dsiplay(), может улучшить презентативность отчета.'. Можешь что-нибудь по этому рассказать? Толкового ничего чет пока не нашел в интернете",,Евгений Фадеев
1605024673.350500,1605032044.350600,U01B4F2HH3Q,"В <https://www.notion.so/35d9c2f32ffa42f3b17010737aedca4b|ноушене> есть.
Не применяйте print() для вывода таблиц. Лучше импортируйте в начале проекта метод display из библиотеки IPython.display и примените его:
`from IPython.display import display`
`display(df)`",,Лазарев Александр
1605024673.350500,1605032348.350800,U01BHCQPGDS,"<@U01B4F2HH3Q> спасибо, посмотрю!",,Евгений Фадеев
1605034214.352600,1605034214.352600,U01C12HNA1E,"<@U0185Q2MK19> и коллеги, вопрос такой
в сборном проекте есть такое указание
""Возьмите данные за соответствующий *актуальный период.* Актуальный период определите самостоятельно в результате исследования предыдущих вопросов. Основной фактор — эти данные помогут построить прогноз на 2017 год.
Не учитывайте в работе данные за *предыдущие годы*.""
у меня осталось примерно 3000 строк из 17000 - это нормально?",,Владимир Ефимищев
1605034864.353300,1605034864.353300,U01BBD7KBA7,"Построение графиков в цикле, с участием переменной из внешнего списка",,Влад Иванов
1605034864.353300,1605035123.353400,U01BBD7KBA7,"Добрый день, коллеги и <@U0185Q2MK19>!
Пытаюсь построить графики в цикле, так что бы значение по которому строится гистограмма, бралось из другого отдельного списка. Придумал такой метод, ссылку прикрепляю: <http://pastebin.com/Gdy4peh3|pastebin.com/Gdy4peh3> . Хочу  не только получить уже рабочий (вероятно более правильный) метод построения графиков в цикле, но и разобраться почему в данном случае не получается построить набор графиков по моей логике. Заранее спасибо! :man-shrugging:",,Влад Иванов
1605024673.350500,1605071715.353600,U0185Q2MK19,Ну и вот эту статью рекомендую почитать: <https://habr.com/ru/post/485318/>,,Олег Булыгин
1605034214.352600,1605073315.353900,U0185Q2MK19,"Привет!

А как ты определял актуальный период? Актуальный период явно не должен быть больше среднего времени жизни платформы (при этом можно исключить первые пики), но и только последние пару лет тоже маловато.",,Олег Булыгин
1605034864.353300,1605073707.354100,U0185Q2MK19,"<@U01BBD7KBA7>,привет!

Почитай, пожалуйста, вот этот тред: <https://stackoverflow.com/questions/57297077/use-variable-in-pandas-query>

Надо так:

```for i in df_top8_platforms.index:
    platform_name = i
    df.groupby(['platform', 'year_of_release'])['name'].agg(['count']).query('platform == @platform_name').plot.bar()
    print(i) ```",,Олег Булыгин
1605034864.353300,1605074030.354400,U01BBD7KBA7,<@U0185Q2MK19> Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Влад Иванов
1605034214.352600,1605074992.354700,U01C12HNA1E,"так и определял, взял ТОП, получилось 6 платформ по продажам, время их жизни от 7 до 11 лет. Правда в качестве актуального периода  взял половину - 5 лет, так как обычно последние 3-5 лет уже спад идёт. Выходит, что лучше шире взять?",,Владимир Ефимищев
1605034864.353300,1605078228.354900,U01BB70DBDY,"<@U0185Q2MK19>, а можно имя переменной(платформы) как-то в title вставить? `.plot(kind='bar', grid=True, figsize=(12, 5), title='Продажи по годам по платформе @name')`  вот так не работает :(",,Виктория Токмакова
1604508980.291200,1605080033.358600,U019E4BGBP0,"<@U0185Q2MK19> привет!) 

Подскажи , пожалуйста, почему дисперсия может быть намного больше чем стандартное отклонение ?? 
Считаю дисперсию для звонков вот так : 

pd.var(df[‘duration’])  

Дисперсия равняется ~44028.27282
",,Угловская Вера
1605089293.359400,1605089293.359400,U01C12HQH5W,"Проверка альтернативной гипотезы ""Средняя выручка тарифа Смарт меньше средней выручки тарифа Ультра""",,Татьяна Зайцева
1605089293.359400,1605089516.359500,U01C12HQH5W,"<@U0185Q2MK19> привет! Помоги, пожалуйста разобраться. При проверке альтернативной гипотезы тест показал, что гипотезу отвергаем, а значит средняя выручка тарифа Смарт больше средней выручки тарифа Ультра. Но если посчитать отдельно средние выручки, то у Ультра значительно больше, чем у Смарт. Ревьюер принял проект, но этот вопрос остался для меня загадкой. Ссылка на код <https://pastebin.com/Lv58JQDk>",,Татьяна Зайцева
1604904346.321900,1605090754.359900,U01BHCQS2RJ,"<@U0185Q2MK19> , привет! При изменении типа данных возникла проблема, - откуда-то вылезает 1970-й:confused:",,Александр Афанасьев
1605034864.353300,1605093892.360200,U0185Q2MK19,"<@U01BB70DBDY>, @ - это чисто функционал query :slightly_smiling_face:
Можно использовать f-строку:
`.plot(kind='bar', grid=True, figsize=(12, 5), title=f'Продажи по годам по платформе {name}')`","[{'name': 'cat-high-five', 'users': ['U01BB70DBDY', 'U01C12HNA1E'], 'count': 2}]",Олег Булыгин
1604508980.291200,1605093936.360400,U0185Q2MK19,"<@U019E4BGBP0>, дисперсия - это всегда просто квадрат СКО. Поэтому оно и будет всегда намного больше :slightly_smiling_face:
Если выходит не квадрат СКО, то в расчетах что-то не то",,Олег Булыгин
1605034214.352600,1605094132.360600,U0185Q2MK19,"<@U01C12HNA1E>, нет, это норм. Обычно берут побольше, но и 5 лет вполне адекватно.
Все ок.",,Олег Булыгин
1605034214.352600,1605094236.360800,U01C12HNA1E,":+1:
Отлично, правда уже слегка расширил диапазон, до среднего значения по всем ТОПам.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1605089293.359400,1605094805.361000,U0185Q2MK19,"<@U01C12HQH5W>, привет!

Объясни, почему тут применяешь односторонний тест?
Почему не просто:

```if (results.pvalue &lt; alpha):
    print('Отвергаем альтернативную гипотезу')
else:
    print('Не получилось отвергнуть альтернативную гипотезу')```
Проблема не с вычислениями, а с интерпретацией результатов.
Если мы отвергаем нулевую гипотезу, то мы можем утверждать, что есть статистическая разница между средними (Нулевая гипотеза всегда формулируется исходя из *равенства* средних.).
В какую она сторону - можно проверить через t-статистику (results.*statistic*).",,Олег Булыгин
1604904346.321900,1605095243.361200,U0185Q2MK19,"<@U01BHCQS2RJ>, привет!
А зачем указываешь шаблон для времени, в исходных данных же просто год?
`df['year_of_release'] = <http://pd.to|pd.to>_datetime(df['year_of_release'], format='%Y')`",,Олег Булыгин
1604904346.321900,1605095513.361400,U01BHCQS2RJ,,,Александр Афанасьев
1604904346.321900,1605095559.361800,U01BHCQS2RJ,"Пробовал, все равно 1970!",,Александр Афанасьев
1604904346.321900,1605095572.362000,U0185Q2MK19,"<@U01BHCQS2RJ>, точно данные заново загрузил, а не делал действия уже над тем, что у тебя получилось?)",,Олег Булыгин
1604904346.321900,1605095637.362200,U01BHCQS2RJ,Выполнял <https://jupyterhub.praktikum-services.ru/user/user-0-36693028/notebooks/64748e92-ab07-4228-8d8f-24863d019c8f.ipynb#|Restart &amp; Run All>,,Александр Афанасьев
1604904346.321900,1605095704.362400,U0185Q2MK19,"<@U01BHCQS2RJ>, пришли тогда, пожалуйста, скриншот исходного датафрейма и всех действий которые ты делаешь для преобразования с выводом результата",,Олег Булыгин
1604904346.321900,1605096024.362700,U01BHCQS2RJ,,,Александр Афанасьев
1604904346.321900,1605096630.363200,U0185Q2MK19,"<@U01BHCQS2RJ>, с кодом абсолютно точно все в порядке.
По порядку запуска ячеек видно, что между этими преобразованиями и предыдущими действиями происходило что-то еще (10 &gt; 21). Видимо это и влияет на результат.

Если я в первой и единственной ячейке запускаю такой код:

```df = pd.read_csv('/datasets/games.csv')
df['year_of_release'] = pd.to_datetime(df['Year_of_Release'], format='%Y')
df.year_of_Release```
То получаю корректное преобразование float в datetime. Я бы даже сказал, что преобразование в datetime тут избыточно , т.к. у нас кроме года ничего нет и можно просто перевести в int. Но в любом случае все должно работать",,Олег Булыгин
1604904346.321900,1605097527.363500,U01BHCQS2RJ,"<@U0185Q2MK19>, спасибо! А пропуски в ""Year_of_Release"", я так думаю, можно удалить, все равно не понятно чем заполнять?",,Александр Афанасьев
1604904346.321900,1605097731.363800,U0185Q2MK19,"<@U01BHCQS2RJ> да, либо удалить, либо ставить и не трогать, пока это не мешает расчетам.",,Олег Булыгин
1604904346.321900,1605097801.364000,U01BHCQS2RJ,<@U0185Q2MK19> Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1604904372.322200,1605119931.364700,U01AWESS539,"<@U0185Q2MK19> привет! Подскажи, пожалуйста, с таким вопросом: в оценке пользователей у нас  есть значения «tbd». Как я поняла, это значит что оценка ещё в процессе подсчета, могу ли я заменить это на пропущенные значения? Просто в дальнейшем мне необходимо привести данные этого столбца к типу float. Или же данные значения я могу заменить, например исходя из оценки критиков, предполагая что оценки критиков и игроков редко значительно отличаются?",,Мария Кузнецова
1604904372.322200,1605127318.364900,U01BHCQS2RJ,"<@U0185Q2MK19> добрый вечер, а чем заменять пропуски, - медианой для жанра-года?",,Александр Афанасьев
1605129515.366700,1605129515.366700,U01BBD67YSX,"Построение графика «ящик с усами» по глобальным продажам игр в разбивке по платформам.
Добрый день, коллеги и <@U0185Q2MK19>! Пытаюсь построить ящик с учами только для топовых платформ:
top_platform = ['PS2', 'X360', 'PS3', 'Wii', 'DS', 'PS']
plot = games.boxplot('total_regions_sales', by='platform' in @top_platform)

Но выдается ошибка. Что я делаю не так?",,Наталия Шельянова
1604904372.322200,1605157458.367000,U0185Q2MK19,"<@U01AWESS539>, привет! Я бы заменил их на NaN. Не стал бы делать смелые предположения, что оценка критиков и пользователей равна. Мы можем получить сильное смещение",,Олег Булыгин
1604904372.322200,1605157509.367200,U0185Q2MK19,"<@U01BHCQS2RJ>, привет!
Я не думаю, что их заменять - осмысленное решение. Вряд ли мы можем делать уверенные предположения о том, что можем прогнозировать год или жанр на основе имеющихся у нас данных.",,Олег Булыгин
1605129515.366700,1605158119.367500,U0185Q2MK19,"<@U01BBD67YSX>, привет!

Ты как-то странно передаешь аргументы в метод :slightly_smiling_face:

Можно вот так:

`plot = df[df.Platform.isin(top_platform)].boxplot('total_regions_sales', by='platform')`",,Олег Булыгин
1604904372.322200,1605160530.367900,U01BHCQS2RJ,"<@U0185Q2MK19> привет! Спасибо, так и думал, но смутило большое количество пропусков.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1604904372.322200,1605163057.372800,U01AWESS539,<@U0185Q2MK19> спасибо! Я ещё заменяла пропуски в оценке критиков на основе медианы согласно группе уровню продаж  (категоризовала на несколько групп по продажам). Это тоже не совсем верное предположение что продажи и оценки критиков взаимосвязаны? И лучше оставить пропуски не заменяя?,,Мария Кузнецова
1605089293.359400,1605171732.373100,U01C12HQH5W,"<@U0185Q2MK19> да, проблема явно с моим пониманием) Сначала сформулировала нулевую гипотезу ""Средние выручки тарифов Смарт и Ультра равны"" и проверила тестом, как ты указал. Результаты теста : нет,  средние выручки не равны. Затем я проверила альтернативную гипотезу ""Средняя выручка тарифа Смарт меньше средней выручки тарифа Ультра"". В теории не рассматривается случай гипотезы ""Среднее одной ГС больше(меньше) среднего другой ГС"", поэтому я проверила альтернативную гипотезу по методу односторонней гипотезы. Видимо, это не верно) Буду благодарна за пример того, как нужно было проверить альтернативную гипотезу:wink:",,Татьяна Зайцева
1604904433.323100,1605174981.373500,U01BBD72X1R,"<@U0185Q2MK19> Привет.
Пытаюсь построить распределение по годам.
Выдает ошибку.
<https://pastebin.com/dL4NKiCf>
<https://pastenow.ru/AO0WQ>",,Артем Провороцкий
1604904372.322200,1605186060.373900,U0185Q2MK19,"<@U01AWESS539>, лично я бы так не делал. Могут быть нишевые  инди игры, у которых небольшие продаж, но высокие рейтинги. Могут быть очень высокобюджетные и продаваемые игры, которые в итоге не понравились аудитории. Я бы пропуски тут не заполнял",,Олег Булыгин
1605089293.359400,1605186992.374200,U0185Q2MK19,"<@U01C12HQH5W>, тут несколько тезисов:

1) Нулевая гипотеза всегда формулируется исходя из равенства средних
2) Любой стат-тест делает проверку именно на то, нужно ли нам отвергнуть нулевую гипотезу, либо мы не можем это сделать. А
3) Альтернативная гипотеза это просто противоположность нулевой. Если мы отвергаем нулевую гипотезу, то берем в работу альтернативную. Никакие дополнительные проверки для нее не делаются.
4) Односторонний тест можно делать, когда мы уверены в том, в какую сторону разница будет (рассматриваем неравенство только в одну сторону).

Если ты проверила такую гипотезу, как написала, и получила результат, что мы можем отвергнуть ее, то мы и пишем в выводе: средние выручки различаются. В какую сторону - можно судить по знаку t-статистике.",,Олег Булыгин
1604904433.323100,1605187147.374400,U0185Q2MK19,"<@U01BBD72X1R>, привет!

Пришли, пожалуйста, скриншот датафрейма без применения к нему plot.

Я в коде проблем не вижу, он у меня без проблем отрабатывает. Значит что-то не то с данными",,Олег Булыгин
1605089293.359400,1605187339.375600,U01C12HQH5W,<@U0185Q2MK19> спасибо за подробный ответ! Теперь картина выглядит для меня намного яснее :+1:,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Татьяна Зайцева
,1605190798.376000,UTTGJQS6M,"Друзья, всем привет!

Для Сборного проекта созданы жесткие треды выше, <https://yandex-students.slack.com/archives/G01BPGP5A73/p1604904271321300|начиная с этого треда> :bar_chart:

Когда вы задаёте вопросы здесь, это помогает в том числе и вашим одногруппникам.
Если у вас возникла трудность с заданием — прежде всего проверьте переписку в канале (пролистайте сообщения наверх), возможно, кто-то уже сталкивался с этой же проблемой, и в чате есть вопрос и полезные советы по его решению.
Удобно: не придётся ждать, когда придёт ответ и задавать повторяющийся вопрос — канал не будет сильно загружен :relieved:

Если вы хотите задать вопрос по проекту Статистический анализ данных и раньше, *коротко назовите свой тред:* название спринта и сфера вопроса и *тегните нашего преподавателя по проектам.*
А уже *внутри треда задайте свой вопрос,* опишите способы, которые уже использовали, приложите скриншоты, коды и другие подробности.
Также вы можете ставить реакцию-галочку, если ваш вопрос в треде решён_ _:heavy_check_mark:
<!channel>",,Маргарита Минеева
1604904493.324300,1605213687.376400,U01BHCQS2RJ,"<@U0185Q2MK19>, привет! У меня для платформы ""XOne"" получился коэф. корреляции между продажами и пользовательскими отзывами -0,0689, - такое возможно?",,Александр Афанасьев
1604904448.323400,1605214071.381100,U01AWESS539,"<@U0185Q2MK19> не до конца понимаю как определить актуальный период, я подсчитала среднюю продолжительность жизни платформы она составила около 8 лет. Актуальным периодом будет считаться среднее число лет когда были наибольшие продажи в течение данных 8 лет? ",,Мария Кузнецова
1604904493.324300,1605241887.381400,U0185Q2MK19,"На сколько я помню, в задании не надо считать корреляцию по конкретным платформам. Но в любом случае, не вижу ничего страшного в таком значении",,Олег Булыгин
1604904448.323400,1605242104.381600,U0185Q2MK19,"<@U01AWESS539>, привет!

Тут нет четкого подхода. В целом, конечно, актуальный период не может быть больше среднего периода жизни платформ. Ну и желательно пики не включать в него. Я бы сказал, что стоит думать о диапазоне от 6 до 10. Конкретный выбор - это уже твое обоснование :slightly_smiling_face:",,Олег Булыгин
1604904493.324300,1605246640.381800,U01BHCQS2RJ,"Доброе утро! ""Посмотрите, как влияют на продажи внутри одной популярной платформы отзывы пользователей и критиков. Постройте диаграмму рассеяния и посчитайте корреляцию между отзывами и продажами.""",,Александр Афанасьев
1604904493.324300,1605246753.382000,U01BHCQS2RJ,Или я не так понял и нужно строить по всем сразу?,,Александр Афанасьев
1604904493.324300,1605246880.382200,U0185Q2MK19,"<@U01BHCQS2RJ>, нет, все верно, это я запамятовал формулировку, все верно :slightly_smiling_face:

Значение похоже на правду :slightly_smiling_face:",,Олег Булыгин
1604904493.324300,1605246956.382400,U01BHCQS2RJ,Спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Афанасьев
1604904433.323100,1605252469.382600,U01BBD72X1R,"<@U0185Q2MK19> разобрался, были названия столбцов в верхнем регистре, а в датафреме в нижнем.
Спасибо:))","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Артем Провороцкий
1604904463.323700,1605257541.382800,U01BBD743QB,"<@U0185Q2MK19> , добрый день! Поясни, пожалуйста, на этом этапе мы продолжаем работать с топ-платформами (у меня их получилось 6) или возвращаемся к полному датафрейму? Ну с учетом того, что надо отсечь неактуальные данные
Спасибо!",,Айнур Мусаева
1604904545.325500,1605269548.383500,U01C12HNA1E,"<@U0185Q2MK19> и коллеги, вопрос, поступило замечание:
""Прежде чем произвести проверку гипотезы через T-критерий Стьюдента произведи проверку дисперсии выборок, чтобы понять с каким параметром использовать метод проверки. Проведи проверку равенства дисперсий для обоих гипотез.""
Строим np.var(x, ddof=1) по выборкам и сравниваем значения?",,Владимир Ефимищев
1604904463.323700,1605272012.383900,U0185Q2MK19,"<@U01BBD743QB>, привет!
Корректнее смотреть на все данные (_за актуальный период_), т.к. ""потенциально прибыльные"" платформы - это те, рост который только начинается",,Олег Булыгин
1604904545.325500,1605273677.384200,U0185Q2MK19,"<@U01C12HNA1E>, все верно. От этого зависит нужно ли применять критерий Уэлча (*equal_var=False*).

Но я придерживаюсь точки зрения, что его можно применять вообще всегда, даже без проверки, вот тут можно почитать обоснование: <https://daniellakens.blogspot.com/2015/01/always-use-welchs-t-test-instead-of.html>","[{'name': 'heavy_check_mark', 'users': ['U01C12HNA1E'], 'count': 1}]",Олег Булыгин
1604904463.323700,1605273815.384500,U01BBD743QB,"<@U0185Q2MK19> спасибо, я тоже исходила из этих соображений. А что ты думаешь по поводу исключения 2016 года из актуального периода? В задании специально отмечено, что данные по нему могут быть неполными, и похоже, что так оно и есть",,Айнур Мусаева
1604904463.323700,1605274154.384700,U0185Q2MK19,"<@U01BBD743QB>, я бы не стал его исключать. Он не перестают быть актуальным из-за того, что по нему не все данные :slightly_smiling_face: Просто надо делать поправку на это при выводах.",,Олег Булыгин
1604904545.325500,1605274848.384900,U01C12HNA1E,"Понял, спасибо.","[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Владимир Ефимищев
1604750949.310800,1605353210.385600,U01BHCQN9D2,"<@U0185Q2MK19> , Добрый день! Проверяла данные и увидела, что потеряла пользователей при объединение таблиц. Только не могу понять , где именно? Ссылка: <https://pastebin.com/JaCeMJDC>",,Ксения Идрисова
1604750949.310800,1605354567.385800,U01BHCQPGDS,"<@U01BHCQN9D2> попробуйте немного поменять последовательность. Я сначала, как и вы, объединяю через how = 'outer' звонки, смс и интернет. А потом к получившемуся df через how='left' добавляю информацию о пользователях on='user_id' и еще раз через how='left' информацию о тарифах on='tariff', тем самым просто добавляя недостающую информацию. А у вас стоит объединение по умолчанию, а оно идет через inner join",,Евгений Фадеев
1604750949.310800,1605354636.386000,U01BHCQPGDS,"Перед добавлением информации о пользователях и тарифах в получившийся df, произвел группировку по пользователям user_id и по месяцу и просуммировал все это",,Евгений Фадеев
1604750949.310800,1605356063.386200,U01BHCQN9D2,"<@U01BHCQPGDS> Спасибо! Но у меня после объединения таблиц со звонками, смс и интернета – 622251 пользователей, а всего в таблице с юзерами - 624750
То есть 2499 пользователей не пользуются ни звонками, ни смс, ни интернетом. И при объединении таблиц, они у меня теряются. Может ли такое быть?",,Ксения Идрисова
1604750949.310800,1605356092.386400,U01BHCQN9D2,Или у меня ошибка где-то в другом месте7,,Ксения Идрисова
1605129515.366700,1605356330.386600,U01BBD67YSX,<@U0185Q2MK19> Спасибо! Взлетело! ),"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Наталия Шельянова
1604750949.310800,1605357345.386800,U01BHCQPGDS,"<@U01BHCQN9D2> возможно ошибка в другом месте. У нас же всего 500 пользователей и 2 тарифных плана, как может получиться такое большое количество? Правильно ли вы подготовили все таблицы к слиянию? Нужно было каждую по отдельности сгруппировать по юзеру и дате совершения звонков и тд., просуммировать все значения, а только потом делать слияние",,Евгений Фадеев
1604750949.310800,1605359129.387000,U01BHCQN9D2,о боги я считаю количество sum() :catshake:,,Ксения Идрисова
1604750949.310800,1605359329.387200,U01BHCQN9D2,"<@U01BHCQPGDS> извините, что потратила ваше время))) Надо быть внимательнее",,Ксения Идрисова
1604750949.310800,1605361644.387500,U0185Q2MK19,"<@U01BHCQN9D2>, удалось разобраться?)",,Олег Булыгин
1604750949.310800,1605361805.387800,U01BHCQN9D2,"<@U0185Q2MK19>, вроде бы да. Заново сгруппировала pivot_table (как-то этот мне понятнее) и склеила таблицы, вроде бы ничего не потеряла. Но откуда-то взялся лишний стоблец с непонятными данными - ""*month_y*""",,Ксения Идрисова
1604750949.310800,1605361892.388000,U0185Q2MK19,"<@U01BHCQN9D2>, это происходит потому, что в объединяемых таблицах были столбцы с одинаковыми названиями. Поэтому при группировке они остаются, но к ним добавляется суффикс.
Но у нас тут такого быть не должно, потому что нам надо объединять данные по id И по месяцу.",,Олег Булыгин
1604750949.310800,1605362024.388200,U01BHCQN9D2,<@U0185Q2MK19> я так и сделала <https://pastebin.com/z6Wuh2CL>,,Ксения Идрисова
1604750949.310800,1605362029.388400,U01BHCQPGDS,"<@U01BHCQN9D2> да нормуль, мы все тут собрались учиться)",,Евгений Фадеев
1604750949.310800,1605362212.388600,U0185Q2MK19,"<@U01BHCQN9D2>, датафреймы объединяются по столбцам. А после groupby столбцы уходят в индексы :slightly_smiling_face: Поэтому надо делать reset_index после каждого объединения",,Олег Булыгин
1604750949.310800,1605364231.388800,U01BHCQN9D2,"<@U0185Q2MK19> попыталась добавить reset_index() после объединения и у меня к лишнему ""*month_y*"" добавились ""*level_0*"" и ""*index*"":grinning::cry:",,Ксения Идрисова
1604750949.310800,1605364369.389000,U01BHCQPGDS,"<@U01BHCQN9D2> добавь еще параметр reset_index(drop=True), станет симпатичнее",,Евгений Фадеев
1604750949.310800,1605364386.389200,U0185Q2MK19,"<@U01BHCQN9D2>, ой, извиняюсь, опечатался, я имел ввиду после группировки, а не объединения.
Т.е. по такому типу:

```user_calls = calls.groupby(['user_id', 'month'])\
                  .agg({'duration':'sum', 'id':'count'})\
                  .reset_index()\
                  .rename(columns={'duration':'month_calls_duration','id':'calls_total_in_month'})

user_messages = messages.groupby(['user_id', 'month'])\
                        .agg({'id':'count'})\
                        .reset_index()\
                        .rename(columns={'id':'sms_total_in_month'})
user_internet = internet.groupby(['user_id', 'month'])\
                        .agg({'mb_used':'sum'})\
                        .reset_index()\
                        .rename(columns={'mb_used':'mb_total_in_month'})```
И потом объединяем",,Олег Булыгин
1604750949.310800,1605364552.389500,U01BHCQN9D2,"<@U0185Q2MK19> я делала пивот и добавляла reset_index , вот так: internet = df_internet.pivot_table(index = ['user_id','month'], values = 'mb_used', aggfunc = 'sum').reset_index()",,Ксения Идрисова
1604750949.310800,1605364605.389700,U01BHCQN9D2,Надо переделывать на groupby?,,Ксения Идрисова
1604750949.310800,1605421098.389900,U0185Q2MK19,"<@U01BHCQN9D2>, не обязательно, но я все равно не понимаю, на каком этапе у тебя появляются эти столбцы.

Например:

```dfinternet = internet.pivot_table(index = ['user_id','month'], values = 'mb_used', aggfunc = 'sum').reset_index()
dfsms = internet.pivot_table(index = ['user_id','month'], values = 'id', aggfunc = 'count').reset_index()
df = dfinternet.merge(dfsms, on=['user_id','month'], how = 'outer')
df = df.merge(users, on='user_id', how='left')

df = df.merge(tariffs, on='tariff', how='left')
df```
Тут почти все шаги, только еще звонки добавить надо.
И по результатам никаких ""лишних"" столбцов нет",,Олег Булыгин
1605089293.359400,1605442214.390200,U01BB741JAW,"<@U0185Q2MK19> Привет! Подскажи пожалуйста по поводу results.*statistic,* почему то на просторах интернета ничего дельного не смогла найти. Меняла местами вот эти значения, и из этого сделала вывод, что results.*statistic* показывает отношение первого параметра ко второму, и в этом конкретном случае мы можем сделать вывод, что выручка по Smart меньше чем выручка по Ultra? А вот как читать это значение: -40.2636712666809. Это на 40 % больше?",,Яна Болдакова
1605445158.395700,1605445158.395700,U01BB741JAW,"3 проект. <@U0185Q2MK19> и другие сведущие, помогите кто чем может))вопрос по пункту 3. Опишите распределения.",,Яна Болдакова
1605445158.395700,1605445165.395800,U01BB741JAW,"Вообще не понимаю как подойти к этому вопросу. <@U0185Q2MK19> Нужно применить какие то методы для определения этих распределений? Или тут имеются ввиду распределения из прошлого спринта, Пуассона и т.д.? Еще вопрос по поводу подсчета дисперсии, я использовала метод `variance_ultra = np.var(ultra['duration'], ddof=1)`, это правильно? после по этой дисперсии рассчитала стандартное отклонение `standard_deviation_ultra = np.sqrt(variance_ultra)`, но не понятно зачем, если оно итак уже есть в `ultra['duration'].describe().` В общем еще вчера мне казалось,что проект почти закончен, а сегодня я перечитала задание, и кажется, что я вообще не понимаю, что нужно делать)",,Яна Болдакова
1604904433.323100,1605450005.396100,U011CBW61JB,"<@U0185Q2MK19> <@U01BBD72X1R> объясните, пожалуйста, что в данном коде означают обратные слеши после query?",,Yana Starikova
1604904545.325500,1605456045.396300,U01AWESS539,"<@U0185Q2MK19> подскажи почему при расчете p-value получаю значение nan? За актуальный период принимала период с 2008 по 2016. На каком шаге искать ошибку?
UPD: Кажется разобралась, необходимо предварительно исключить пропущенные значения, тогда все считается. Это будет верным решением проблемы?",,Мария Кузнецова
1604904433.323100,1605458245.396900,U01BHCQPGDS,<@U011CBW61JB> это просто перенос строки,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Евгений Фадеев
1604904478.324000,1605473652.397100,U011CBW61JB,"<@U0185Q2MK19>, привет! подскажи, пожалуйста, почему не работает код построения боксплотов по платформам: <https://pastebin.com/MEWa4q1D>
Вижу, что в ошибке сказано про кортеж (tuple is not callable), но синтаксис ведь правильный? Или ограничения по оси y не должны быть кортежем? Как тогда это правильно записать? График строится, но без ограничения по оси",,Yana Starikova
1605089293.359400,1605501270.397400,U0185Q2MK19,"<@U01BB741JAW>, привет!

Нет, это не отношение. Фактически это значение самого стат-критерия. В случае критерия Стьюдента оно действительно может показывать примерную разницу средних (не отношение, а разницу), правда больше по знаку, чем по реальному значению, а сам знак меняется в зависимости от порядка поданных аргументов в метод этого критерия. Если посмотреть формулу критерия Стьюдента, то там в числителе среднее одной выборки вычитается от средней другой выборки и все это делится на стандартную ошибку.  По знаку будет понятно, средняя какой выборки больше, но это не является разницей средних как таковой. В небольших выборках значение критерия будет примерно совпадать со средним, а если количество элементов в выборках в тысячах измеряется, то уже нет.

В общем на него можно смотреть только чтобы понять средняя какой из выборок больше/меньше (только на знак). Как-то более осмысленно его интерпретировать не стоит.",,Олег Булыгин
1605445158.395700,1605502396.397700,U0185Q2MK19,"<@U01BB741JAW>, нет, распределения нужно оценить чисто визуально при помощи гистограмм. Строим гистограммы, смотрим какой вид они имеют, пишем выводы.

И да, можно использовать describe, либо просто сделать отдельную табличку с нужными показателями в разрезе тарифов, например:

```df.groupby('tariff')\
  .agg({'mb_total':['median','mean','var','std']})```
",,Олег Булыгин
1604904545.325500,1605504240.398000,U0185Q2MK19,"<@U01AWESS539>, да, все верно, проверяем гипотезы, исключая пропуски",,Олег Булыгин
1604904478.324000,1605505951.398200,U0185Q2MK19,"<@U011CBW61JB>, привет!

Это не ошибка, это предупреждение (то есть на работу кода никак не влияет). На самом деле это просто баг библиотеки: <https://github.com/DHI/mikeio/issues/88>.
Ограничения по оси есть (у себя воспроизвел, все ок). Если у тебя не срабатывает - пришли, пожалуйста скриншот и убедись, что перед этим сделала импорт `import matplotlib.pyplot as plt`",,Олег Булыгин
1605089293.359400,1605515968.398700,U01BB741JAW,Теперь все понятно)спасибо!,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Яна Болдакова
1604904372.322200,1605527348.406100,U01B4EXA6S2,"<@U0185Q2MK19>  привет
Появилась мысль насчёт столбца rating. Понял что некоторые пропуски можно заполнить. Названия игр дублируются в зависимости от платформы, те получается название одно и тоже а платформа разная. Так вот если брать какую то игру с несколькими платформами, то на одной платформе у неё может быть пропуск в rating, а на другой платформе rating может быть заполненным. И тут я встал в тупик. Пытаюсь придумать как сделать так, чтобы заполнить пропущенные значения взяв заполненное значение игры из одной платформы и вставить его в пропущенное из rating этой же игры. ",,Александр Сурков
1604904372.322200,1605531411.406300,U0185Q2MK19,"<@U01B4EXA6S2>, логика может быть такая:
1. пишем функция для ее дальнейшего использования в apply
2. в этой функции делаем проверку, если в строке стоит NaN у рейтинга
3. Если там NaN, то берем срез у датафрейма с таким же названием игры
4. И в этом срезе берем значение по столбцу рейтинга, который не NaN (если такой есть)
5. Заменяем у текущей строки NaN на это значение
6. Применяем функцию через apply к датафрейму",,Олег Булыгин
1604904372.322200,1605531555.407000,U01B4EXA6S2,<@U0185Q2MK19> спасибо :ok_hand:,"[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Александр Сурков
1604904463.323700,1605589150.407300,U01C12H494Y,"<@U0185Q2MK19> подскажи, пожалуйста, как каждую платформу выделить определенным цветом, а цвета вынести в легенду?
<https://pastebin.com/6RfSGkNK>",,Влад Простаков
1604904463.323700,1605590202.407500,U0185Q2MK19,"<@U01C12H494Y>, рекомендую использовать в этом случае seaborn, так буде проще. Примерно так можно:

```ax = df.groupby(['Platform', 'Year_of_Release']).agg({'NA_sales': 'sum'}).reset_index()
sns.barplot(data=ax, x='Year_of_Release', y='NA_sales', hue=""Platform"", orient='v')```
","[{'name': 'white_check_mark', 'users': ['U01C12H494Y'], 'count': 1}]",Олег Булыгин
1605613656.410600,1605613656.410600,U0156SASFFB,"<@U0185Q2MK19> Вопрос по 4 шагу (Статистически анализ данных - Выбор тарифа), ревьюер не принимает мою проверку нулевой гипотезы, ссылаясь на неверную формулировку. Но в чем конкретно неверность не могу понять(( Нид хелп!",,Иван Симанов
1605613656.410600,1605615369.410800,U017YK5CLLV,"<@U0156SASFFB> Нулевая гипотеза гласит о равенстве средних, что тебе пытается сказать ревьюер. У тебя пороговое значение p.value &lt;0.05, а это является статистически значимым результатом, что говорит о разнице средних. А значит мы отвергаем нулевую гипотезу и не отвергаем альтернативную гипотезу. То есть ревьюер пытается сказать, что ты за нулевую гипотезу принял разность средних",,Олег Михеев
1605613656.410600,1605616314.413500,U0185Q2MK19,"<@U0156SASFFB>, Олег подсказывает абсолютно правильно. Нулевая гипотеза всегда предполагает равенство средних. Альтернативная противоположна ей. У тебя, судя по всему, все наоборот.",,Олег Булыгин
1605613656.410600,1605616592.413700,U0156SASFFB,"<@U0185Q2MK19> т.е. if (results.pvalue == alpha):
    print(“Отвергаем нулевую гипотезу“)
else:
    print(“Не получилось отвергнуть нулевую гипотезу“)?",,Иван Симанов
1605613656.410600,1605623841.413900,U017YK5CLLV,"<@U0156SASFFB> У тебя всё верно было, кроме интерпретации. 0 ведь меньше 0,05, согласись? И программа тебе говорит, что нужно отвергнуть нулевую гипотезу, а значит нельзя отвергнуть альтернативную гипотезу. То есть средние двух выборок статистически различаются, ведь так?",,Олег Михеев
1605613656.410600,1605624156.416400,U0156SASFFB,"<@U017YK5CLLV> различаются, о чем я в интерпретации и указываю. Т е я полагаю, моя фраза «статистически не значимая» а корне не верна и нужно написать обратное?",,Иван Симанов
1605613656.410600,1605624781.416600,U017YK5CLLV,"<@U0156SASFFB> фраза ""различие можно получить случайно, что нам продемонстрировало p-значение"", видимо, сбила с толку не одного меня. Надо переформулировать предложение","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Олег Михеев
1605613656.410600,1605624913.416800,U017YK5CLLV,"<@U0156SASFFB> Да, твоя последняя ремарка имеет место быть","[{'name': 'fire', 'users': ['U0156SASFFB'], 'count': 1}]",Олег Михеев
1604904463.323700,1605673677.417300,U01B84FM5KP,"<@U0185Q2MK19> подскажи, как для использования seaborn в твоём примере увеличить размер отображаемой картинки?",,Денис Стариченко
1604904463.323700,1605674314.417500,U0185Q2MK19,"<@U01B84FM5KP>, можно вот так:

`sns.set(rc={'figure.figsize':(12,9)})`  - регулируем числами размер по сторонам)",,Олег Булыгин
1604904493.324300,1605723525.417900,U01BHCQPGDS,<@U0185Q2MK19> у меня ревьювер просит изучить и построить не по одной платформе...,,Евгений Фадеев
1604904493.324300,1605769904.418100,U01C12EJQ80,"*<https://app.slack.com/team/U01BHCQPGDS|Евгений Фадеев>* Скорее всего из-за следующего задания в этом шаге: ""Соотнесите выводы с продажами игр на других платформах"".  Строила диаграмму для каждой платформы из своего топа, а для корреляции была рекомендация её визуализировать.",,Динара Шарафутдинова
1604904493.324300,1605777132.418300,U0185Q2MK19,"<@U01BHCQPGDS>, обычно ревьюера удовлетворяет подход - изучить корреляцию по одной платформе и отдельно - ""по всем остальным"" (то есть вместе). Но если просит сравнить прямо с конкретными другими - сделай, хуже не будет :)",,Олег Булыгин
1605796891.420400,1605796891.420400,U019642V4G7,"Сборный проект 1. Влияет ли рейтинг ESRB на продажи в отдельном регионе?

Не могу понять с чем связаны пропуски в рейтинге ESRB. Если собрать все пустые значения рейтинга ESRB в отдельную группу, то получается довольно большое количество игр с высокими продажами.
<@U0185Q2MK19>",,Сослан Чехов
1604904531.325200,1605806116.420700,U013LGCHQS1,"Как делать сортировку? Через groupby например ,или через диаграмму?",,Артем Горобцов
1604904372.322200,1605819515.422300,U01AWENSUVD,"<@U0185Q2MK19> Привет! Попыталась реализовать описанную тобой функцию, но застряла(
Она отрабатывает без ошибок, но не производит вообще никакого эффекта
<https://pastebin.com/97JuQ2W8|https://pastebin.com/97JuQ2W8>",,Юлия Мальцева
1604904433.323100,1605823630.422500,U01AWENSUVD,"<@U0185Q2MK19> у меня какая-то очень ироничная ситуация – не отрабатывает выполнение среза с операндом “и”, при этом “костыль” в виде последовательного применения .query работает отлично. Ошибка “SyntaxError: Python keyword not valid identifier in numexpr query”. Гугол не помог.",,Юлия Мальцева
1605796891.420400,1605826409.423100,U01BB70DBDY,"Я тоже не смогла связать ни с чем пустые значения для их замены. Описала это все словами и заменила на что-то типо ""no_rating"". Может это не оптимально, но вроде приняли.",,Виктория Токмакова
1605796891.420400,1605827554.423300,U01BB741JAW,"Да, эти значения нужно обязательно заменить на что то типа: не определено. Судя по рейтингу в Японии, где не определенные на первом месте, я сделала вывод, что в Японии своя организация, которая определяет рейтинги. И поэтому в рейтинге ESRB так много пропущенных значений",,Яна Болдакова
1604904531.325200,1605827717.423500,U01BB741JAW,"Я делала через groupby, можно через pivot, кому как удобно. Графики я тоже построила для наглядности. Если хочешь, чтобы Олег увидел твое сообщение, его нужно меншануть в этом треде)","[{'name': '+1', 'users': ['U0185Q2MK19'], 'count': 1}]",Яна Болдакова
1605796891.420400,1605849619.423700,U0185Q2MK19,"Полностью согласен. Иногда еще используют подход, когда восстанавливают рейтинг, если есть такая же игра на другой платформе и у нее рейтинг указан. Но это все равно  не поможет избавится от всех пропусков (и вообще способо сомнительный, т.к. я допускаю, что на разных платформах у одной игры могут быть разные рейтинги).",,Олег Булыгин
1604904372.322200,1605851726.424000,U0185Q2MK19,"<@U01B4EXA6S2>, <@U01AWENSUVD>, копаясь в вопросе обнаружил, что очень часто бывают ситуацию, когда рейтинг у одной и той же игры на разных платформах разный. Что ставит под сомнения такой подход :slightly_smiling_face:
Но если что, можно так:

```def rating_check(row):
    if pd.isna(row['rating']):
        name1 = row['name']
        df1 = df.query('name == @name1')[df.rating.notna()]
        if len(df1) &gt; 0:
            return df1['rating'].iloc[0]
    else:
        return row['rating']```
","[{'name': 'heart', 'users': ['U01AWENSUVD'], 'count': 1}]",Олег Булыгин
1604904433.323100,1605851890.424200,U0185Q2MK19,"<@U01AWENSUVD>, надо не `&amp;&amp;`, а `and` :slightly_smiling_face:
Вот тут есть примеры: <https://pythonexamples.org/pandas-dataframe-query/>","[{'name': 'heart', 'users': ['U01AWENSUVD'], 'count': 1}]",Олег Булыгин
1605796891.420400,1605857508.424700,U01BBD72X1R,"Это может быть связано тоже с тем, что рейтинг игр ESRB был создан в 1994 году, а у нас дата фрейм начинается с 1985, соответственно тогда и никто не мог поставить его)",,Артем Провороцкий
1604904531.325200,1605859547.424900,U011CBW61JB,"<@U0185Q2MK19> Олег, привет! пыталась автоматизировать процесс построения пивотов для выделения топ 5 по определенному критерию по разным показателям. Скажи, пожалуйста, что нужно поменять, чтобы цикл правильно принимал столбцы и все работало: <https://pastebin.com/eKNYWRU2>",,Yana Starikova
1604904493.324300,1605859671.425100,U011CBW61JB,"<@U0185Q2MK19> Привет! я бы хотела вывести все таблицы корреляции по каждой платформе в формате тепловой карты, но ничего не выводится, помоги пожалуйста: <https://pastebin.com/1Eg7Xxjs>",,Yana Starikova
1605796891.420400,1605866278.425500,U01C12HNA1E,"Артём мы ведь берём актуальный период, в который уже включены игры с 1994 года, больше склонен с Яной, ESRB создана для США и Канады.",,Владимир Ефимищев
1605796891.420400,1605866913.425700,U01BBD72X1R,"В таком случае, согласен",,Артем Провороцкий
1605796891.420400,1605867190.425900,U019642V4G7,"Спасибо всем за ответы
не стал заполнять рейтинг у одинаковых игр на разных платформах, помню был случай, когда вышел battlefield online и игроки консолей соревановались с игроками на PC на одних серверах, причем у консольщиков была возможность автонаведения прицела. Естественно, рейтинг резко упал на PC.

Пришлось просто написать про то, что в Японии свой рейтинг и, возможно, отличные от западных регуляторные ограничения, посмотрим, примут ли.",,Сослан Чехов
1605796891.420400,1605867395.426100,U019642V4G7,"о, только что приняли, ура!","[{'name': 'cool-doge', 'users': ['U0185Q2MK19', 'U01DVNLSSBZ'], 'count': 2}]",Сослан Чехов
1604904531.325200,1605874006.426400,U0185Q2MK19,"<@U011CBW61JB>, привет!

Если я правильно понял задачу, то можно так:

```regions_sales = df[['na_sales', 'eu_sales', 'jp_sales']]
def rating(df, criteria):
    for i in regions_sales:
        display(df.pivot_table(index=criteria, values= i, aggfunc={'sum'}))
rating(df, 'genre')```",,Олег Булыгин
1604904493.324300,1605874223.426700,U0185Q2MK19,"<@U011CBW61JB>, просто примени функцию display :slightly_smiling_face:

```for i in uniqueplatforms:
    platform_name = i
    platform_data = games_data_actual.query('platform == @platform_name')
   display(platform_data[['total_sales', 'critic_score', 'user_score']].corr().style.background_gradient(cmap='coolwarm'))```
",,Олег Булыгин
1604904545.325500,1605879407.428800,U01B4EYP47Q,"<@U0185Q2MK19> <@U01AWESS539> а как их в данном случае исключить ? Можно конкретно в проверке гипотезы или заранее все строки с Nan удалить? Подскажите, пожалуйста , а то что-то запутался ",,Антон Бахилин
1604904545.325500,1605887376.429000,U0185Q2MK19,"<@U01B4EYP47Q>, у функции есть специальный аргумент, который позволяет решить эту проблему: *nan_policy*
Рекомендую в документации ознакомиться: <https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html>",,Олег Булыгин
1604904545.325500,1605887429.429400,U01B4EYP47Q,<@U0185Q2MK19> Огромное спасибо ,"[{'name': 'ok_hand', 'users': ['U0185Q2MK19'], 'count': 1}]",Антон Бахилин
1604904493.324300,1605940389.431100,U011CBW61JB,"<@U0185Q2MK19> спасибо! Выручай опять) После проверки ревьюера изменила только актуальный период и перевела оценки критиков и год в целое значение, но теперь почему то не строятся скаттер плоты <https://pastebin.com/ujST4sfC>",,Yana Starikova
1604904493.324300,1605940464.431400,U011CBW61JB,"<@U0185Q2MK19> ошибка говорит, что x как будто не числовой тип, но это ведь не так: <https://pastebin.com/tTbgANBc>",,Yana Starikova
1604904531.325200,1605950982.431800,U0185Q2MK19,"<@U013LGCHQS1>, ответ Яны помог разобраться?
И да, просьба тегать меня при вопросах, иначе может быть сложно отследить обращение)",,Олег Булыгин
1604904493.324300,1605955359.432000,U0185Q2MK19,"<@U011CBW61JB>, покажи, пожалуйста, весь диапазон значений critic_score, который есть. Например, при помощи unique()",,Олег Булыгин
1604904531.325200,1605957464.432200,U013LGCHQS1,"<@U0185Q2MK19> а почему мне должна помогать разбираться Яна, а не Вы? Почему был проигнорирован мой вопрос? У меня много вопросов и сложностей возникает с проектом, но задавать их не имеет смысла получается?",,Артем Горобцов
1604904531.325200,1605957784.432400,U0185Q2MK19,"<@U013LGCHQS1>, просто вам Яна подсказала абсолютно верно, я мог просто продублировать ее ответ.
Все вопросы задавать смысл имеет, и я на все отвечаю. Часто коллеги подсказывают друг другу и делятся опытом - это абсолютно нормальная коммуникация и позволяет еще быстрее получить обратную связь по вопросу.

Только просьба тегать меня в своих сообщениях, иначе я просто не увижу уведомления о вопросе.",,Олег Булыгин
1604904531.325200,1605957832.432600,U013LGCHQS1,<@U0185Q2MK19> откуда мне знать правильно ли мне подсказала Яна?,,Артем Горобцов
1604904531.325200,1605958123.432800,U0185Q2MK19,"<@U013LGCHQS1>, можно просто последовать совету и посмотреть на результат. Если цель достигнута - все ок. Тем более у любой задачи есть много способов решения. Если есть какие-то сомнения или все равно не получается реализовать поставленную задачу - можно уточнить вопрос, в т.ч. тегнув меня.
Если посмотреть на другие треды, то можно увидеть, как мы вместе с коллегами всегда поэтапно разбираемся в каких-то вопросах (и обучающиеся так же помогают друг другу).",,Олег Булыгин
1604904493.324300,1605978682.433600,U011CBW61JB,<@U0185Q2MK19> вот: <https://pastebin.com/C6gbgPLC>,,Yana Starikova
1604904493.324300,1605978734.433800,U011CBW61JB,"<@U0185Q2MK19> ты имеешь в виду, что это из-за пропусков? Но раньше они тоже были, и все работало, и когда я их исключаю в срезе, результат все равно такой же",,Yana Starikova
1604904493.324300,1605979364.434000,U011CBW61JB,"<@U0185Q2MK19> А сейчас вообще до всех изменений код вставила и ничего не работает, что раньше работало:sweat:",,Yana Starikova
1604904493.324300,1606024593.434200,U0185Q2MK19,"<@U011CBW61JB>, я постарался воспроизвести твою проблему, делаю все аналогичные действия с такими же типами:
<https://pastenow.ru/ARITI>
Результат получаю корретный.

Судя по твоему комментарию о том, что после изменения порядка ячеек все перестает работать - у тебя есть какие-то действия *до* указанного, по которым происходят изменения в данных, которые все ломают (вполне вероятно, что на каком-то этапе ты перезаписываешь переменные с одинаковым именем другой информацией).
Попробуй запустить код построения визуализации полностью изолированно - оставь только те действия, которые нужны для его построения и больше ничего (приведение типов, расчет общих продаж). И сразу станет понятно - проблема в каких-то сторонних действиях или внутри текущих.",,Олег Булыгин
1604904493.324300,1606026002.435600,U011CBW61JB,"<@U0185Q2MK19> Я уже пробовала запускать его сразу же после прочтения датафрейма, вообще без других действий, и результат тот же:weary:",,Yana Starikova
1604904493.324300,1606026876.435800,U0185Q2MK19,"<@U011CBW61JB>, пришли, пожалуйста, сам ноутбук в личку, постараюсь разобраться подробнее",,Олег Булыгин
1612535673.063000,1612535673.063000,U01BHCQS2RJ,"<@U0185Q2MK19>, привет, я строил график воронки, как в тренажере(fig = go.Figure(go.Funnel(..) и не смог добавить заголовок, а ревьюер требует. Кроме того я сформулировал нулевую гипотезу: ""в качестве нулевой гипотезы ""контрольные группы А и А (246 и 247) не имеют различий"", иначе говоря ""группы равны"""", - он написал, что формулировка ""группы равны"" - некорректна. Помоги пожалуйста!",,Александр Афанасьев
1612535673.063000,1612536897.064100,U0185Q2MK19,"Привет!
Если строил визуализацию в plotly, то можно так добавить заголовок: `fig.update_layout(title_text='Some_title')`

На счет гипотезы: ее корректнее будет сформулировать так:
```Доли уникальных посетителей, побывавших на этапе воронки, равны. ```
Мы проверяем именно равенство долей, а не групп.",,Олег Булыгин
1612535673.063000,1612538008.064300,U01BHCQS2RJ,"<@U0185Q2MK19>, спасибо!!! И ещё вопрос: можно ли в качестве возражения пртив уровня стат. значимости 0,1 сказать, что это значительно повысит вероятность получить ложный результат и, в нашем случае, повлечет необоснованные затраты?",,Александр Афанасьев
1612535673.063000,1612539325.064900,U01BHCQS2RJ,"<@U0185Q2MK19> не понял:frowning:, а где про это почитать?",,Александр Афанасьев
1612535673.063000,1612539374.065100,U0185Q2MK19,"<@U01BHCQS2RJ>, ты точно имеешь ввиду 0.1, а не 0.01? Больше 0.05 вряд ли когда-то имеет брать смысл, это чрезмерно мягкий критерий.

Да, извиняюсь, изначально неверно понял вопрос.

Твоя мысль верна. Тут как раз идея в том, что ты должен предложить конкретный пороговый уровень значимости, который будет более адекватным. Либо стандартный 0.05, либо на него сделать поправку, про которые было в этом уроке: <https://praktikum.yandex.ru/learn/data-analyst/courses/2bb03488-4558-4da8-a823-dcbb35e43d7c/sprints/317/topics/74747132-c98a-431c-bb78-0450405c50a7/lessons/b434be98-470b-48c1-84fa-34892eaf5134/|https://praktikum.yandex.ru/learn/data-analyst/courses/2bb03488-4558-4da8-a823-dcbb35e[…]-0450405c50a7/lessons/b434be98-470b-48c1-84fa-34892eaf5134/>",,Олег Булыгин
1612535673.063000,1612539553.065600,U01BHCQS2RJ,"<@U0185Q2MK19>, это в задании : ""Какой уровень значимости вы выбрали при проверке статистических гипотез выше? Посчитайте, сколько проверок статистических гипотез вы сделали. При уровне значимости 0.1 каждый десятый раз можно получать ложный результат. Какой уровень значимости стоит применить? Если вы хотите изменить его, проделайте предыдущие пункты и проверьте свои выводы.""",,Александр Афанасьев
1612535673.063000,1612539630.065800,U01BHCQS2RJ,"<@U0185Q2MK19>, спасибо, буду разбираться)",,Александр Афанасьев
